[{"path":"index.html","id":"welcome","chapter":"Welcome ","heading":"Welcome ","text":"","code":""},{"path":"index.html","id":"about-this-course","chapter":"Welcome ","heading":"About This Course","text":"recent years, mass spectrometry-based proteomics become essential tool life sciences, enabling quantitative, systems-level insights protein expression, post-translational modifications, cellular signaling dynamics. complexity volume proteomics data continue increase, demand robust, transparent, reproducible computational methods never greater.5-day intensive training course - r4proteomics - designed equip researchers, bioinformaticians, data scientists practical skills theoretical grounding necessary analyze proteomics data using R programming language Bioconductor ecosystem. combination guided tutorials, hands-exercises, real-world case studies, participants build fluency core statistical computational methods widely used proteomics research translational applications.curriculum begins foundational programming R progresses quality control, normalization, differential analysis proteomics data, culminating advanced topics functional enrichment, longitudinal modeling, integration public datasets.course ideal professionals seeking deepen expertise computational proteomics within pharmaceutical, biotechnology, academic research environments. Participants leave solid methodological framework also ready--use code templates workflows applicable projects.learn:Day 1: R fundamentals RStudio basics (Slides)Day 2: Understanding proteomic data quality control (Slides)Day 3: Data preprocessing differential expression analysis (Slides)Day 4: Functional analysis, longitudinal studies, public datasets (Slides)Day 5: Real-world applications case studies (Slides)","code":""},{"path":"index.html","id":"prerequisites","chapter":"Welcome ","heading":"Prerequisites","text":"Basic computer literacyInterest biological data analysisNo prior R programming experience required","code":""},{"path":"index.html","id":"course-materials","chapter":"Welcome ","heading":"Course Materials","text":"data files, scripts, additional resources available course repository.","code":""},{"path":"index.html","id":"useful-online-resources-and-other-bibliography","chapter":"Welcome ","heading":"Useful online resources and other bibliography","text":"Websites\nR Project (developers R)\nQuick-R (Roadmap R code quickly use R)\nCookbook R (R code “recipes”)\nBioconductor workflows\n(R code pipelines genomic analyses)\nIntroduction Data Science\n(Free online book Rafael . Irizarry, 2020)\nModern Statistics Modern Biology\nAdvanced R (want learn R programmers perspective)\nWebsitesR Project (developers R)Quick-R (Roadmap R code quickly use R)Cookbook R (R code “recipes”)Bioconductor workflows\n(R code pipelines genomic analyses)Introduction Data Science\n(Free online book Rafael . Irizarry, 2020)Modern Statistics Modern BiologyAdvanced R (want learn R programmers perspective)Books\nIntroductory Statistics R (Springer, Dalgaard, 2008)\nfirst course statistical programming R (CUP, Braun Murdoch, 2016)\nComputational Genome Analysis: Introduction\n(Springer, Deonier, Tavaré Waterman, 2005)\nR programming Bioinformatics\n(CRC Press, Gentleman, 2008)\nR Data Science: Import, Tidy, Transform, Visualize, Model Data\n(O’Reilly, Wickham Grolemund, 2017) (advanced users)\nBooksIntroductory Statistics R (Springer, Dalgaard, 2008)first course statistical programming R (CUP, Braun Murdoch, 2016)Computational Genome Analysis: Introduction\n(Springer, Deonier, Tavaré Waterman, 2005)R programming Bioinformatics\n(CRC Press, Gentleman, 2008)R Data Science: Import, Tidy, Transform, Visualize, Model Data\n(O’Reilly, Wickham Grolemund, 2017) (advanced users)Cheatsheets\nBase R\nggplot2\ndplyr\nCheatsheetsBase Rggplot2dplyr","code":""},{"path":"index.html","id":"how-to-use-this-book","chapter":"Welcome ","heading":"How to Use This Book","text":"chapter corresponds one day training. Chapters include:Learning objectives: ’ll achieveTheory sections: Conceptual backgroundPractical exercises: Hands-codingCase studies: Real-world applications","code":""},{"path":"index.html","id":"installation-instructions","chapter":"Welcome ","heading":"Installation Instructions","text":"starting Day 1, please follow steps .","code":""},{"path":"index.html","id":"install-r","chapter":"Welcome ","heading":"0.0.1 1. Install R","text":"Download install R :\nhttps://cran.r-project.org/\nChoose operating system accept default options.","code":""},{"path":"index.html","id":"install-rstudio","chapter":"Welcome ","heading":"0.0.2 2. Install RStudio","text":"Download install RStudio Desktop (free version) :\nhttps://posit.co/download/rstudio-desktop/","code":""},{"path":"index.html","id":"install-the-required-packages","chapter":"Welcome ","heading":"0.0.3 3. Install the required packages","text":"RStudio installed:Open RStudio.\nsee several panels. panel bottom left Console. place can type commands.Open RStudio.\nsee several panels. panel bottom left Console. place can type commands.Click inside Console panel.Click inside Console panel.Copy paste text Console press Enter.Copy paste text Console press Enter.","code":"\n# Install required CRAN packages\ninstall.packages(c(\n  \"bookdown\", \"rmarkdown\", \"knitr\", \"pheatmap\", \"ggplot2\", \"downlit\", \"xml2\",\n  \"reshape2\", \"gridExtra\", \"tidyverse\", \"lme4\",\n  \"ggforce\", \"scatterpie\", \"png\"  # Optional\n))\n\n# Install Bioconductor packages\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n  install.packages(\"BiocManager\")\n\nBiocManager::install(c(\n  \"limma\", \"vsn\", \"sva\", \"clusterProfiler\", \"org.Hs.eg.db\",\n  \"KEGGREST\", \"AnnotationDbi\", \"annotate\", \"GO.db\",\n  \"genefilter\", \"GOSemSim\", \"DOSE\", \"enrichplot\"\n), update = TRUE, ask = FALSE)"},{"path":"index.html","id":"acknowledgments","chapter":"Welcome ","heading":"Acknowledgments","text":"course developed provide hands-training proteomics data analysis.","code":""},{"path":"day1.html","id":"day1","chapter":"Day - 1 Introduction to R and RStudio","heading":"Day - 1 Introduction to R and RStudio","text":"","code":""},{"path":"day1.html","id":"learning-objectives","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.1 Learning Objectives","text":"end Day 1, able :Install navigate RStudio effectivelyUnderstand basic R data structures (vectors, data frames, lists)Import explore simple datasetsWrite basic control flow structures functions","code":""},{"path":"day1.html","id":"day1-mod1","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2 Module 1: Setting Up and Getting Started with R","text":"","code":""},{"path":"day1.html","id":"introduction","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.1 Introduction","text":"R powerful programming language environment specifically designed statistical computing graphics. RStudio integrated development environment (IDE) makes working R much easier.","code":""},{"path":"day1.html","id":"installing-r-and-rstudio","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.2 Installing R and RStudio","text":"Install R (version 4.3.0 higher)\nVisit https://cran.r-project.org/\nDownload version appropriate operating system\nRun installer\nInstall R (version 4.3.0 higher)Visit https://cran.r-project.org/Download version appropriate operating systemRun installerInstall RStudio Desktop\nVisit https://posit.co/download/rstudio-desktop/\nDownload free Desktop version\nRun installer\nInstall RStudio DesktopVisit https://posit.co/download/rstudio-desktop/Download free Desktop versionRun installer","code":""},{"path":"day1.html","id":"rstudio-interface-tour","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.3 RStudio Interface Tour","text":"RStudio four main panes:Source Editor (top-left): write edit scriptsConsole (bottom-left): code executed results appearEnvironment/History (top-right): Shows objects memory command historyFiles/Plots/Packages/Help (bottom-right): File browser, plot viewer, package manager, help documentation","code":""},{"path":"day1.html","id":"scripts-vs-console","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.4 Scripts vs Console","text":"Console :Quick calculationsTesting commandsInteractive explorationScripts (.R .Rmd files) : - Saving work - Creating reproducible analyses - Organizing complex workflows","code":""},{"path":"day1.html","id":"install-required-r-packages","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.5 Install Required R Packages","text":"Open R session terminal RStudio:","code":"\n# Install CRAN packages\ninstall.packages(c(\n  \"bookdown\", \"rmarkdown\", \"knitr\", \"pheatmap\", \"ggplot2\", \"downlit\", \"xml2\",\n  \"reshape2\", \"gridExtra\", \"tidyverse\", \"lme4\",\n  \"ggforce\", \"scatterpie\", \"png\"  # Optional\n))\n\n# Install Bioconductor packages\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n  install.packages(\"BiocManager\")\n\nBiocManager::install(c(\n  \"limma\", \"vsn\", \"sva\", \"clusterProfiler\", \"org.Hs.eg.db\", \"lme4\",\n  \"KEGGREST\", \"AnnotationDbi\", \"annotate\", \"GO.db\",\n  \"genefilter\", \"GOSemSim\", \"DOSE\", \"enrichplot\"\n), update = TRUE, ask = FALSE)"},{"path":"day1.html","id":"working-directory-getwd-and-setwd","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.6 Working Directory: getwd() and setwd()","text":"working directory folder R reads saves files.Check Current Working DirectoryChange Working DirectoryUse forward slashes (/) put path quotes. TipsIn RStudio: Session → Set Working Directory → Choose Directory…Always run getwd() setwd() verify change.","code":"\ngetwd()\nsetwd(\"path/to/your/folder\")"},{"path":"day1.html","id":"basic-operators","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.7 Basic Operators","text":"Please note:R case sensitive - aware capital letters (b different B).R code lines starting # (hash) sign interpreted comments, therefore evaluated.","code":"\n# Arithmetic operators\n5 + 3        # Addition\n#> [1] 8\n10 - 4       # Subtraction\n#> [1] 6\n6 * 7        # Multiplication\n#> [1] 42\n20 / 4       # Division\n#> [1] 5\n2 ^ 3        # Exponentiation\n#> [1] 8\n17 %% 5      # Modulo (remainder)\n#> [1] 2\n\n# Comparison operators\n5 == 5       # Equal to\n#> [1] TRUE\n5 != 3       # Not equal to\n#> [1] TRUE\n7 > 3        # Greater than\n#> [1] TRUE\n4 < 8        # Less than\n#> [1] TRUE\n5 >= 5       # Greater than or equal\n#> [1] TRUE\n3 <= 10      # Less than or equal\n#> [1] TRUE\n\n# Logical operators\nTRUE & FALSE  # AND\n#> [1] FALSE\nTRUE | FALSE  # OR\n#> [1] TRUE\n!TRUE         # NOT\n#> [1] FALSE\n\n# Scientific notation\n1.5e6  # 1,500,000\n#> [1] 1500000"},{"path":"day1.html","id":"variables-assignment","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.8 Variables & Assignment","text":"Please note:Spaces matter variable names. Use dot underscore create longer names make variables descriptive, e.g. .variable_name.Spaces variables operators matter: 3+2 3 + 2, function (arg1 , arg2) function(arg1,arg2).","code":"\n# Assignment operator\nx <- 10      # Assign 10 to x\ny = 5        # Alternative (but <- is preferred)\n# Tip: assignment operator has the following shortcuts:\n# Windows/Linux: Press Alt + - (the minus key).\n# Mac: Press Option + - (the minus key). \n\n## Assign values to variables\nprotein_count <- 800\nsample_size <- 12\nstudy_name <- \"Proteomics_2025\"\n\n## View variables\nprotein_count\n#> [1] 800\nsample_size\n#> [1] 12\n\n## Use variables in calculations\ntotal_measurements <- protein_count * sample_size\ntotal_measurements\n#> [1] 9600"},{"path":"day1.html","id":"data-types","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.9 Data Types","text":"major data types : Numeric (e.g. 1,2,3…); Character (e.g. “p”, “ro”, “teomics”) Logical (TRUE FALSE).","code":"\n# Numeric\nintensity <- 25114306.44\nclass(intensity)\n#> [1] \"numeric\"\n\n# Character (text)\naccession <- \"F1LMU0\"\nclass(accession)\n#> [1] \"character\"\n\n# Logical\nis_significant <- TRUE\nclass(is_significant)\n#> [1] \"logical\"\n\n# Check type\nis.numeric(intensity)\n#> [1] TRUE\nis.character(accession)\n#> [1] TRUE"},{"path":"day1.html","id":"creating-your-first-script","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.10 Creating Your First Script","text":"","code":"\n# Create a new R script: File > New File > R Script\n# Or use Ctrl+Shift+N (Windows/Linux) or Cmd+Shift+N (Mac)\n\n# Write your code\nmessage(\"Hello, Proteomics World!\")\n\n# Save your script: File > Save\n# Run code: Ctrl+Enter (Windows/Linux) or Cmd+Return (Mac)"},{"path":"day1.html","id":"exercise-1.1-first-steps","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.11 Exercise 1.1: First Steps","text":"Create new R script :Calculate sum 123 456Assign result variable called totalPrint value totalCalculate percentage 123 total","code":"\n# Solution\nresult1 <- 123 + 456\ntotal <- result1\nprint(total)\n#> [1] 579\n\npercentage <- (123 / total) * 100\nprint(paste0(\"123 is \", round(percentage, 2), \"% of the total\"))\n#> [1] \"123 is 21.24% of the total\""},{"path":"day1.html","id":"day1-mod2","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3 Module 2: Data Types and Structures","text":"","code":""},{"path":"day1.html","id":"vectors","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3.1 Vectors","text":"Vectors basic data structure R. contain elements type.vector contains multiple elements, define R c(elm1, elm2, elm3 ... elmN).","code":"\n# Numeric vectors\nages <- c(25, 30, 35, 40, 45)\nprint(ages)\n#> [1] 25 30 35 40 45\n\n# Character vectors\nnames <- c(\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Eve\")\nprint(names)\n#> [1] \"Alice\"   \"Bob\"     \"Charlie\" \"Diana\"   \"Eve\"\n\n# Logical vectors\npassed_qc <- c(TRUE, TRUE, FALSE, TRUE, TRUE)\nprint(passed_qc)\n#> [1]  TRUE  TRUE FALSE  TRUE  TRUE\n\n# Sequences\nseq_1_10 <- 1:10\nseq_custom <- seq(from = 0, to = 100, by = 10)\n\n# Vector operations\nmean(ages)\n#> [1] 35"},{"path":"day1.html","id":"indexing-and-subsetting","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3.2 Indexing and Subsetting","text":"Tip: R vectors 1-based, .e. first index position number 1 (opposed programming languages whose indexes start zero).","code":"\n# Access elements by position (1-indexed!)\nages[1]           # First element\n#> [1] 25\nages[c(1, 3, 5)]  # Multiple elements\n#> [1] 25 35 45\nages[-2]          # All except second element\n#> [1] 25 35 40 45\n\n# Logical indexing\nages[ages > 35]   # Elements greater than 35\n#> [1] 40 45\n\n# Named vectors\nprotein_abundance <- c(ACTB = 1500, GAPDH = 2000, MYC = 800)\nprotein_abundance[\"ACTB\"]\n#> ACTB \n#> 1500"},{"path":"day1.html","id":"data-frames","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3.3 Data Frames","text":"Data frames common structure storing tabular data.Please note:Data frames easily subset index number using square brackets notation [], column name using dollar sign $.arguments inside square brackets [row_number, column_number]. omitted, R assumes values used.","code":"\n# Create a data frame\npatient_data <- data.frame(\n  patient_id = 1:5,\n  name = c(\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Eve\"),\n  age = c(25, 30, 35, 40, 45),\n  treatment = c(\"A\", \"B\", \"A\", \"B\", \"A\"),\n  response = c(TRUE, TRUE, FALSE, TRUE, FALSE),\n  stringsAsFactors = FALSE\n)\n\nprint(patient_data)\n#>   patient_id    name age treatment response\n#> 1          1   Alice  25         A     TRUE\n#> 2          2     Bob  30         B     TRUE\n#> 3          3 Charlie  35         A    FALSE\n#> 4          4   Diana  40         B     TRUE\n#> 5          5     Eve  45         A    FALSE\n\n# View structure\nstr(patient_data)\n#> 'data.frame':    5 obs. of  5 variables:\n#>  $ patient_id: int  1 2 3 4 5\n#>  $ name      : chr  \"Alice\" \"Bob\" \"Charlie\" \"Diana\" ...\n#>  $ age       : num  25 30 35 40 45\n#>  $ treatment : chr  \"A\" \"B\" \"A\" \"B\" ...\n#>  $ response  : logi  TRUE TRUE FALSE TRUE FALSE\n\n# Summary statistics\nsummary(patient_data)\n#>    patient_id     name                age    \n#>  Min.   :1    Length:5           Min.   :25  \n#>  1st Qu.:2    Class :character   1st Qu.:30  \n#>  Median :3    Mode  :character   Median :35  \n#>  Mean   :3                       Mean   :35  \n#>  3rd Qu.:4                       3rd Qu.:40  \n#>  Max.   :5                       Max.   :45  \n#>   treatment          response      \n#>  Length:5           Mode :logical  \n#>  Class :character   FALSE:2        \n#>  Mode  :character   TRUE :3        \n#>                                    \n#>                                    \n#> \n# Access columns\npatient_data$age\n#> [1] 25 30 35 40 45\npatient_data[, \"name\"]\n#> [1] \"Alice\"   \"Bob\"     \"Charlie\" \"Diana\"   \"Eve\"\npatient_data[, 2]\n#> [1] \"Alice\"   \"Bob\"     \"Charlie\" \"Diana\"   \"Eve\"\n\n# Access rows\npatient_data[1, ]           # First row\n#>   patient_id  name age treatment response\n#> 1          1 Alice  25         A     TRUE\npatient_data[1:3, ]         # First three rows\n#>   patient_id    name age treatment response\n#> 1          1   Alice  25         A     TRUE\n#> 2          2     Bob  30         B     TRUE\n#> 3          3 Charlie  35         A    FALSE\n\n# Access specific cells\npatient_data[2, 3]          # Row 2, Column 3\n#> [1] 30\npatient_data[2, \"age\"]      # Same, using column name\n#> [1] 30\n\n# Subset by condition\npatient_data[patient_data$age > 30, ]\n#>   patient_id    name age treatment response\n#> 3          3 Charlie  35         A    FALSE\n#> 4          4   Diana  40         B     TRUE\n#> 5          5     Eve  45         A    FALSE\npatient_data[patient_data$treatment == \"A\", ]\n#>   patient_id    name age treatment response\n#> 1          1   Alice  25         A     TRUE\n#> 3          3 Charlie  35         A    FALSE\n#> 5          5     Eve  45         A    FALSE"},{"path":"day1.html","id":"exploring-data-frames","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3.3.1 Exploring Data Frames","text":"","code":"\n# View first rows\nhead(patient_data, 2)\n#>   patient_id  name age treatment response\n#> 1          1 Alice  25         A     TRUE\n#> 2          2   Bob  30         B     TRUE\n\n# Dimensions\ndim(patient_data)\n#> [1] 5 5\nnrow(patient_data)\n#> [1] 5\nncol(patient_data)\n#> [1] 5\n\n# Column names\ncolnames(patient_data)\n#> [1] \"patient_id\" \"name\"       \"age\"        \"treatment\" \n#> [5] \"response\""},{"path":"day1.html","id":"accessing-data-frame-elements","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3.3.2 Accessing Data Frame Elements","text":"","code":"\n# Access column by name\npatient_data$name\n#> [1] \"Alice\"   \"Bob\"     \"Charlie\" \"Diana\"   \"Eve\"\n\n# Access using brackets [row, column]\npatient_data[1, 3]        # Row 1, column 3\n#> [1] 25\npatient_data[1:2, ]       # First 2 rows, all columns\n#>   patient_id  name age treatment response\n#> 1          1 Alice  25         A     TRUE\n#> 2          2   Bob  30         B     TRUE\npatient_data[, \"treatment\"]    # All rows, Mass column\n#> [1] \"A\" \"B\" \"A\" \"B\" \"A\"\n\n# Subset data\npatient_data[patient_data$age > 30, ]\n#>   patient_id    name age treatment response\n#> 3          3 Charlie  35         A    FALSE\n#> 4          4   Diana  40         B     TRUE\n#> 5          5     Eve  45         A    FALSE"},{"path":"day1.html","id":"lists","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3.4 Lists","text":"Lists can contain elements different types structures.","code":"\n# Create a list\nexperiment <- list(\n  experiment_id = \"EXP001\",\n  date = \"2025-01-15\",\n  samples = c(\"S1\", \"S2\", \"S3\"),\n  data = patient_data,\n  validated = TRUE\n)\n\n# Access list elements\nexperiment$experiment_id\n#> [1] \"EXP001\"\nexperiment[[1]]\n#> [1] \"EXP001\"\nexperiment[[\"samples\"]]\n#> [1] \"S1\" \"S2\" \"S3\""},{"path":"day1.html","id":"factors","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3.5 Factors","text":"Factors variables R take limited number different values- variables often refered categorical variables.","code":"\n# Create factor\ntreatment_factor <- factor(c(\"Control\", \"Drug A\", \"Drug B\", \"Control\", \"Drug A\"))\nprint(treatment_factor)\n#> [1] Control Drug A  Drug B  Control Drug A \n#> Levels: Control Drug A Drug B\n\n# Check levels\nlevels(treatment_factor)\n#> [1] \"Control\" \"Drug A\"  \"Drug B\"\n\n# Ordered factors\nseverity <- factor(\n  c(\"Mild\", \"Severe\", \"Moderate\", \"Mild\", \"Severe\"),\n  levels = c(\"Mild\", \"Moderate\", \"Severe\"),\n  ordered = TRUE\n)\nprint(severity)\n#> [1] Mild     Severe   Moderate Mild     Severe  \n#> Levels: Mild < Moderate < Severe"},{"path":"day1.html","id":"type-coercion","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3.6 Type Coercion","text":"","code":"\n# Implicit coercion\nmixed <- c(1, 2, \"three\", 4)  # All converted to character\nprint(mixed)\n#> [1] \"1\"     \"2\"     \"three\" \"4\"\n\n# Explicit coercion\nnumbers_char <- c(\"1\", \"2\", \"3\", \"4\")\nnumbers_num <- as.numeric(numbers_char)\nprint(numbers_num)\n#> [1] 1 2 3 4\n\n# Check types\nclass(mixed)\n#> [1] \"character\"\nis.numeric(mixed)\n#> [1] FALSE\nis.character(mixed)\n#> [1] TRUE"},{"path":"day1.html","id":"exercise-1.2-data-structures","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3.7 Exercise 1.2: Data Structures","text":"Create data frame proteomic experiment :10 protein IDs (P001 P010)Random abundance values 100 5000Random p-values 0 1Significance status (TRUE p-value < 0.05)","code":"\n# Solution\nset.seed(42)  # For reproducibility\n\nproteins <- data.frame(\n  protein_id = paste0(\"P\", sprintf(\"%03d\", 1:10)),\n  abundance = round(runif(10, min = 100, max = 5000), 2),\n  p_value = runif(10, min = 0, max = 1),\n  stringsAsFactors = FALSE\n)\n\nproteins$significant <- proteins$p_value < 0.05\n\nprint(proteins)\n#>    protein_id abundance   p_value significant\n#> 1        P001   4582.55 0.4577418       FALSE\n#> 2        P002   4691.67 0.7191123       FALSE\n#> 3        P003   1502.08 0.9346722       FALSE\n#> 4        P004   4169.19 0.2554288       FALSE\n#> 5        P005   3244.55 0.4622928       FALSE\n#> 6        P006   2643.57 0.9400145       FALSE\n#> 7        P007   3709.28 0.9782264       FALSE\n#> 8        P008    759.87 0.1174874       FALSE\n#> 9        P009   3319.26 0.4749971       FALSE\n#> 10       P010   3554.82 0.5603327       FALSE\n\n# Summary\ncat(\"\\nNumber of significant proteins:\", sum(proteins$significant), \"\\n\")\n#> \n#> Number of significant proteins: 0"},{"path":"day1.html","id":"day1-mod3","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.4 Module 3: Control Flow and Functions","text":"","code":""},{"path":"day1.html","id":"conditional-statements","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.4.1 Conditional Statements","text":"Conditionals allow running commands certain conditions TRUE. syntax : (condition) { code-block }.ifelse function combines element-wise operations (vectorized) filtering condition evaluated. major advantage ifelse standard --else statement vectorized. syntax : ifelse (condition--test, value--true, value--false).","code":"\n# if statement\nx <- 10\n\nif (x > 5) {\n  print(\"x is greater than 5\")\n}\n#> [1] \"x is greater than 5\"\n\n# if-else\nif (x > 15) {\n  print(\"x is greater than 15\")\n} else {\n  print(\"x is 15 or less\")\n}\n#> [1] \"x is 15 or less\"\n\n# if-else if-else\nscore <- 75\n\nif (score >= 90) {\n  grade <- \"A\"\n} else if (score >= 80) {\n  grade <- \"B\"\n} else if (score >= 70) {\n  grade <- \"C\"\n} else {\n  grade <- \"F\"\n}\n\nprint(paste(\"Grade:\", grade))\n#> [1] \"Grade: C\"\n# Vectorized ifelse\nvalues <- c(1, 5, 10, 15, 20)\ncategories <- ifelse(values > 10, \"High\", \"Low\")\nprint(categories)\n#> [1] \"Low\"  \"Low\"  \"Low\"  \"High\" \"High\""},{"path":"day1.html","id":"loops","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.4.2 Loops","text":"R allows implementation loops, .e. replicating instructions iterative way (also called cycles). common ones () loops () loops. syntax loops : (condition) { code-block } (condition) { code-block }.","code":"\n# for loop\nfor (i in 1:5) {\n  print(paste(\"Iteration:\", i))\n}\n#> [1] \"Iteration: 1\"\n#> [1] \"Iteration: 2\"\n#> [1] \"Iteration: 3\"\n#> [1] \"Iteration: 4\"\n#> [1] \"Iteration: 5\"\n\n# Loop through vector\nproteins <- c(\"ACTB\", \"GAPDH\", \"MYC\")\nfor (protein in proteins) {\n  print(paste(\"Processing:\", protein))\n}\n#> [1] \"Processing: ACTB\"\n#> [1] \"Processing: GAPDH\"\n#> [1] \"Processing: MYC\"\n\n# while loop\ncounter <- 1\nwhile (counter <= 5) {\n  print(paste(\"Counter:\", counter))\n  counter <- counter + 1\n}\n#> [1] \"Counter: 1\"\n#> [1] \"Counter: 2\"\n#> [1] \"Counter: 3\"\n#> [1] \"Counter: 4\"\n#> [1] \"Counter: 5\"\n\n# Mixing loop with condition\nnumbers <- 1:10\nfor (num in numbers) {\n  if (num %% 2 == 0) {\n    print(paste(num, \"is even\"))\n  } else if (num %% 2 != 0) {\n    print(paste(num, \"is odd\"))\n  }\n}\n#> [1] \"1 is odd\"\n#> [1] \"2 is even\"\n#> [1] \"3 is odd\"\n#> [1] \"4 is even\"\n#> [1] \"5 is odd\"\n#> [1] \"6 is even\"\n#> [1] \"7 is odd\"\n#> [1] \"8 is even\"\n#> [1] \"9 is odd\"\n#> [1] \"10 is even\""},{"path":"day1.html","id":"functions","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.4.3 Functions","text":"R allows defining new functions using function command. syntax (pseudo-code) following:.function.name <- function (argument1, argument2, ...) {    expression1   expression2   ...   return (value)   }","code":"\n# Basic function\ngreet <- function(name) {\n  message <- paste(\"Hello,\", name, \"!\")\n  return(message)\n}\n\ngreet(\"Alice\")\n#> [1] \"Hello, Alice !\"\n\n# Function with multiple parameters\ncalculate_fold_change <- function(treatment, control) {\n  fc <- treatment / control\n  log2_fc <- log2(fc)\n  return(log2_fc)\n}\n\ncalculate_fold_change(treatment = 200, control = 100)\n#> [1] 1\n\n# Function with default parameters\nnormalize_abundance <- function(abundance, method = \"median\") {\n  if (method == \"median\") {\n    normalized <- abundance / median(abundance, na.rm = TRUE)\n  } else if (method == \"mean\") {\n    normalized <- abundance / mean(abundance, na.rm = TRUE)\n  } else {\n    stop(\"Method must be 'median' or 'mean'\")\n  }\n  return(normalized)\n}\n\nvalues <- c(100, 200, 300, 400, 500)\nnormalize_abundance(values)\n#> [1] 0.3333333 0.6666667 1.0000000 1.3333333 1.6666667\nnormalize_abundance(values, method = \"mean\")\n#> [1] 0.3333333 0.6666667 1.0000000 1.3333333 1.6666667"},{"path":"day1.html","id":"apply-family-functions","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.4.4 Apply Family Functions","text":"apply family functions lets perform calculations efficiently across rows, columns, lists.","code":"\n# Create sample data\nprotein_matrix <- matrix(\n  c(100, 150, 200, 250, \n    110, 160, 210, 260,\n    120, 170, 220, 270),\n  nrow = 3, byrow = TRUE\n)\ncolnames(protein_matrix) <- c(\"Sample1\", \"Sample2\", \"Sample3\", \"Sample4\")\nrownames(protein_matrix) <- c(\"Protein1\", \"Protein2\", \"Protein3\")\n\nprint(protein_matrix)\n#>          Sample1 Sample2 Sample3 Sample4\n#> Protein1     100     150     200     250\n#> Protein2     110     160     210     260\n#> Protein3     120     170     220     270\n\n# apply: apply function to rows or columns\nrow_means <- apply(protein_matrix, 1, mean)  # 1 = rows\ncol_means <- apply(protein_matrix, 2, mean)  # 2 = columns\n\nprint(row_means)\n#> Protein1 Protein2 Protein3 \n#>      175      185      195\nprint(col_means)\n#> Sample1 Sample2 Sample3 Sample4 \n#>     110     160     210     260\n\n# lapply: apply function to list, returns list\nmy_list <- list(a = 1:5, b = 6:10, c = 11:15)\nlist_means <- lapply(my_list, mean)\nprint(list_means)\n#> $a\n#> [1] 3\n#> \n#> $b\n#> [1] 8\n#> \n#> $c\n#> [1] 13\n\n# sapply: simplified version of lapply\nvector_means <- sapply(my_list, mean)\nprint(vector_means)\n#>  a  b  c \n#>  3  8 13"},{"path":"day1.html","id":"exercise-1.3-functions-and-loops","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.4.5 Exercise 1.3: Functions and Loops","text":"Write function :Takes vector protein abundancesCalculates coefficient variation (CV = sd/mean * 100)Returns “Pass” CV < 20%, “Fail” otherwiseApply function multiple samples using loop.","code":"\n# Solution\ncalculate_cv_status <- function(abundances) {\n  cv <- (sd(abundances, na.rm = TRUE) / mean(abundances, na.rm = TRUE)) * 100\n  \n  if (cv < 20) {\n    status <- \"Pass\"\n  } else {\n    status <- \"Fail\"\n  }\n  \n  return(list(cv = round(cv, 2), status = status))\n}\n\n# Create sample data\nsample_data <- list(\n  sample1 = c(100, 105, 98, 102, 99),\n  sample2 = c(100, 150, 90, 200, 80),\n  sample3 = c(500, 505, 498, 502, 496)\n)\n\n# Apply function\nfor (sample_name in names(sample_data)) {\n  result <- calculate_cv_status(sample_data[[sample_name]])\n  cat(sample_name, \"- CV:\", result$cv, \"% - Status:\", result$status, \"\\n\")\n}\n#> sample1 - CV: 2.75 % - Status: Pass \n#> sample2 - CV: 40.56 % - Status: Fail \n#> sample3 - CV: 0.7 % - Status: Pass"},{"path":"day1.html","id":"day1-mod5","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.5 Module 4: Data Visualization with ggplot2","text":"module, explore visualize data using ggplot2, one powerful flexible plotting systems R.based “grammar graphics” framework, emphasizes modular construction plot using different layers components ((ggplot2 online documentation )[https://ggplot2.tidyverse.org/]).module, explore visualize data using ggplot2, one powerful flexible plotting systems R. ggplot2 based “grammar graphics”, framework builds plots adding layers (bit like stacking transparent sheets), adding new element (data, axes, shapes, colors, etc.).can read grammar concept official ggplot2 documentation, check handy ggplot2 cheatsheet.","code":""},{"path":"day1.html","id":"loading-required-packages","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.5.1 Loading Required Packages","text":"","code":"\n# Load necessary library\nlibrary(ggplot2)"},{"path":"day1.html","id":"understanding-the-ggplot2-structure","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.5.2 Understanding the ggplot2 structure","text":"Every ggplot built three key components:can think sentence:“Use data, map variables axes, draw geometry.”plot usually constructed layers:+ adds new layer visual element (title, theme, labels, etc.).","code":"\nggplot(data = protein_data, aes(x = condition, y = abundance)) +\n  geom_boxplot()"},{"path":"day1.html","id":"example-dataset","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.5.3 Example Dataset","text":"’ll first create example dataset representing protein abundance two conditions: Control Treatment.","code":"\nset.seed(42)\n\n# Simulate realistic protein abundance data\n\nn_proteins <- 100\n\nprotein_data <- data.frame(\nprotein_id = paste0(\"P\", sprintf(\"%03d\", 1:n_proteins)),\nabundance = c(\nrnorm(n_proteins / 2, mean = 1000, sd = 150),   # Control group\nrnorm(n_proteins / 2, mean = 1300, sd = 180)    # Treatment group\n),\ncondition = rep(c(\"Control\", \"Treatment\"), each = n_proteins / 2)\n)\n\n# Add a few outliers to make the data more realistic\noutlier_indices <- sample(1:n_proteins, 3)\nprotein_data$abundance[outlier_indices] <- \n  protein_data$abundance[outlier_indices] * runif(3, 1.5, 2)\n\nhead(protein_data)\n#>   protein_id abundance condition\n#> 1       P001 1205.6438   Control\n#> 2       P002  915.2953   Control\n#> 3       P003 1054.4693   Control\n#> 4       P004 1094.9294   Control\n#> 5       P005 1060.6402   Control\n#> 6       P006  984.0813   Control"},{"path":"day1.html","id":"histogram-distribution-of-protein-abundance","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.5.4 Histogram: Distribution of Protein Abundance","text":"histogram helps visualize distribution continuous variables protein abundance.","code":"\nggplot(protein_data, aes(x = abundance)) +\n  geom_histogram(binwidth = 100, fill = \"steelblue\", color = \"white\") +\n  labs(\n    title = \"Distribution of Protein Abundance\",\n    x = \"Abundance\",\n    y = \"Count\"\n  ) +\n  theme_minimal()"},{"path":"day1.html","id":"boxplot-comparing-conditions","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.5.5 Boxplot: Comparing Conditions","text":"boxplot provides compact summary abundance values across conditions.","code":"\nggplot(protein_data, aes(x = condition, y = abundance, fill = condition)) +\n  geom_boxplot(alpha = 0.7) +\n  labs(\n    title = \"Protein Abundance by Condition\",\n    x = \"Condition\",\n    y = \"Abundance\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")"},{"path":"day1.html","id":"scatter-plot-individual-points-with-mean-values","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.5.6 Scatter Plot: Individual Points with Mean Values","text":"scatter plot jittering can display individual data points avoiding overlap. Adding mean points provides overview group averages.","code":"\nggplot(protein_data, aes(x = condition, y = abundance, color = condition)) +\n  geom_jitter(width = 0.2, alpha = 0.6) +\n  stat_summary(fun = mean, geom = \"point\", size = 4, shape = 18, color = \"black\") +\n  labs(\n    title = \"Abundance per Condition with Mean Values\",\n    x = \"Condition\",\n    y = \"Abundance\"\n  ) +\n  theme_minimal()"},{"path":"day1.html","id":"density-plot-distribution-by-condition","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.5.7 Density Plot: Distribution by Condition","text":"density plot shows smoothed distribution abundance values condition.","code":"\nggplot(protein_data, aes(x = abundance, fill = condition)) +\n  geom_density(alpha = 0.5) +\n  labs(\n    title = \"Density Plot of Protein Abundance by Condition\",\n    x = \"Abundance\",\n    y = \"Density\"\n  ) +\n  theme_minimal()"},{"path":"day1.html","id":"summary","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.5.8 Summary","text":"module, learned :Build ggplot2 plots layer layer.Use aes() map variables axes colors.Visualize distributions using histograms density plotsCompare groups using boxplotsDisplay individual data points jitter summary statisticsThese visualizations essential exploring proteomics data identifying trends outliers statistical analysis.","code":""},{"path":"day1.html","id":"module-5-importing-and-exploring-data","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.6 Module 5: Importing and Exploring Data","text":"R users need load datasets, usually saved table files (e.g. Excel, .csv files), able analyse manipulate . analysis, results need exported/saved (e.g. view use software).","code":""},{"path":"day1.html","id":"reading-common-file-types","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.6.1 Reading common file types","text":"","code":"\n# CSV / TSV (readr is faster and friendlier than base R)\nlibrary(readr)\n\n# Read a comma-delimited file (CSV)\nproteins_csv <- read_csv(\"data/proteins.csv\")\n\n# Read a tab-delimited file (TSV)\nproteins_tsv <- read_tsv(\"data/proteins.tsv\")\n\n# Base R alternatives (fine, but less convenient)\nproteins_csv_base <- read.csv(\"data/proteins.csv\")              # comma\nproteins_tsv_base <- read.delim(\"data/proteins.tsv\", sep = \"\\t\")# tab\n# Excel (readxl does not require Java)\nlibrary(readxl)\n\n# Reads first sheet by default; or set sheet = \"Sheet1\"\nproteins_xlsx <- read_excel(\"data/proteins.xlsx\")"},{"path":"day1.html","id":"saving-data","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.6.2 Saving data","text":"","code":"\n# CSV / TSV\nwrite_csv(proteins_csv, \"results/proteins_clean.csv\")\nwrite_tsv(proteins_csv, \"results/proteins_clean.tsv\")\n\n# Excel (simple writer)\nlibrary(writexl)\nwrite_xlsx(proteins_csv, \"results/proteins_clean.xlsx\")\n\n# R native (best for workflows, preserves classes)\nsaveRDS(proteins_csv, \"results/proteins_clean.rds\")\n# Later:\nreloaded <- readRDS(\"results/proteins_clean.rds\")"},{"path":"day1.html","id":"basic-data-exploration","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.6.3 Basic Data Exploration","text":"","code":"\n# Create example data\nset.seed(123)\nprotein_data <- data.frame(\n  protein_id = paste0(\"P\", 1:100),\n  abundance = rnorm(100, mean = 1000, sd = 200),\n  condition = rep(c(\"Control\", \"Treatment\"), each = 50)\n)\n\n# Dimensions\ndim(protein_data)\n#> [1] 100   3\nnrow(protein_data)\n#> [1] 100\nncol(protein_data)\n#> [1] 3\n\n# First and last rows\nhead(protein_data)\n#>   protein_id abundance condition\n#> 1         P1  887.9049   Control\n#> 2         P2  953.9645   Control\n#> 3         P3 1311.7417   Control\n#> 4         P4 1014.1017   Control\n#> 5         P5 1025.8575   Control\n#> 6         P6 1343.0130   Control\ntail(protein_data)\n#>     protein_id abundance condition\n#> 95         P95 1272.1305 Treatment\n#> 96         P96  879.9481 Treatment\n#> 97         P97 1437.4666 Treatment\n#> 98         P98 1306.5221 Treatment\n#> 99         P99  952.8599 Treatment\n#> 100       P100  794.7158 Treatment\n\n# Summary statistics\nsummary(protein_data)\n#>   protein_id          abundance       condition        \n#>  Length:100         Min.   : 538.2   Length:100        \n#>  Class :character   1st Qu.: 901.2   Class :character  \n#>  Mode  :character   Median :1012.4   Mode  :character  \n#>                     Mean   :1018.1                     \n#>                     3rd Qu.:1138.4                     \n#>                     Max.   :1437.5\n\n# Table for categorical data\ntable(protein_data$condition)\n#> \n#>   Control Treatment \n#>        50        50"},{"path":"day1.html","id":"module-6-data-wrangling-with-tidyverse","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7 Module 6: Data Wrangling with tidyverse","text":"","code":""},{"path":"day1.html","id":"introduction-to-tidyverse","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.1 Introduction to tidyverse","text":"tidyverse?Collection R packages data scienceConsistent syntax design philosophyMain packages: dplyr, tidyr, ggplot2, readrWhy tidyverse?Readable, intuitive codePipe operator %>% chaining operationsFaster learning curveIndustry standard","code":"\nlibrary(tidyverse)"},{"path":"day1.html","id":"the-pipe-operator","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.2 The Pipe Operator %>%","text":"Traditional approach:pipe operator tidyverse (magrittr):Read : “Take x, take square root, take log10, calculate mean”","code":"\nx <- c(1, 2, 3, 4, 5)\nresult <- mean(log10(sqrt(x)))\nresult\n#> [1] 0.2079181\nresult <- x %>% \n  sqrt() %>% \n  log10() %>% \n  mean()\nresult\n#> [1] 0.2079181"},{"path":"day1.html","id":"your-actual-proteomics-data-structure","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.3 Your Actual Proteomics Data Structure","text":"Good practice: Convert column names lowercase replace spaces underscores _, keep naming colmuns cleaner consistent.","code":"\n# Simulate your data structure\nset.seed(123)\nproteomics_data <- readxl::read_excel(\n    path = \"examples/genethon_dataset/2126001_Protein Export_ex.xlsx\", # this should be the file example that genethon provided\n    skip = 1\n)\n\n# Drop completely empty columns (all NA)\nproteomics_data <- proteomics_data %>%\n    dplyr::select(dplyr::where(~ any(!is.na(.))))\n\nhead(proteomics_data[, 1:10])\n#> # A tibble: 6 × 10\n#>   Accession  Gene       `Peptide count` `Unique peptides`\n#>   <chr>      <chr>                <dbl>             <dbl>\n#> 1 F1LMU0     F1LMU0                 338               138\n#> 2 G3V8V3     G3V8V3                 146               113\n#> 3 A0A0G2JSP8 A0A0G2JSP8             117               109\n#> 4 Q64578     AT2A1                  126                89\n#> 5 D4AEH9     D4AEH9                  87                83\n#> 6 P15429     ENOB                   110                83\n#> # ℹ 6 more variables: `Confidence score` <dbl>, Mass <dbl>,\n#> #   Description <chr>, `2126001_029_F5` <dbl>,\n#> #   `2126001_359_F9` <dbl>, `2126001_401_F1` <dbl>\n# Clean column names: lowercase + underscores\n#colnames(proteomics_data) <- tolower(colnames(proteomics_data))\ncolnames(proteomics_data) <- gsub(\" \", \"_\", tolower(colnames(proteomics_data)))"},{"path":"day1.html","id":"dplyr-grammar-of-data-manipulation","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.4 dplyr: Grammar of Data Manipulation","text":"Key Functions:select() - Choose columnsfilter() - Choose rows based conditionsmutate() - Create modify columnsarrange() - Sort datasummarize() - Calculate summary statisticsgroup_by() - Group data operations","code":""},{"path":"day1.html","id":"select-choose-columns","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.5 select(): Choose Columns","text":"","code":"\n# Select specific columns\nproteomics_data %>%\n  dplyr::select(accession, gene, mass, `2126001_029_f5`) %>%\n  head(3)\n#> # A tibble: 3 × 4\n#>   accession  gene          mass `2126001_029_f5`\n#>   <chr>      <chr>        <dbl>            <dbl>\n#> 1 F1LMU0     F1LMU0     222850.        25114306.\n#> 2 G3V8V3     G3V8V3      97288.        18519365.\n#> 3 A0A0G2JSP8 A0A0G2JSP8  43019.       897562438.\n\n# Select range of columns\nproteomics_data %>%\n  dplyr::select(accession:mass) %>%\n  head(3)\n#> # A tibble: 3 × 6\n#>   accession  gene       peptide_count unique_peptides\n#>   <chr>      <chr>              <dbl>           <dbl>\n#> 1 F1LMU0     F1LMU0               338             138\n#> 2 G3V8V3     G3V8V3               146             113\n#> 3 A0A0G2JSP8 A0A0G2JSP8           117             109\n#> # ℹ 2 more variables: confidence_score <dbl>, mass <dbl>\n\n# Select columns containing \"sample\"\nproteomics_data %>%\n  dplyr::select(accession, contains(\"f5\")) %>%\n  head(3)\n#> # A tibble: 3 × 2\n#>   accession  `2126001_029_f5`\n#>   <chr>                 <dbl>\n#> 1 F1LMU0            25114306.\n#> 2 G3V8V3            18519365.\n#> 3 A0A0G2JSP8       897562438."},{"path":"day1.html","id":"filter-choose-rows","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.6 filter(): Choose Rows","text":"","code":"\n# Filter high mass proteins\nproteomics_data %>%\n  dplyr::filter(mass > 100000) %>%\n  dplyr::select(accession, gene, mass)\n#> # A tibble: 87 × 3\n#>    accession  gene          mass\n#>    <chr>      <chr>        <dbl>\n#>  1 F1LMU0     F1LMU0     222850.\n#>  2 Q64578     AT2A1      109409.\n#>  3 D4AEH9     D4AEH9     174331.\n#>  4 G3V7K1     G3V7K1     164712.\n#>  5 A0A0G2K5P5 A0A0G2K5P5 187602.\n#>  6 D3ZA38     D3ZA38     128936.\n#>  7 Q03626     MUG1       165326 \n#>  8 Q8R4I6     Q8R4I6     103013.\n#>  9 D3ZHA0     FLNC       290984.\n#> 10 A0A096MK15 A0A096MK15 772118.\n#> # ℹ 77 more rows\n\n# Multiple conditions (AND)\nproteomics_data %>%\n  dplyr::filter(mass > 100000 & peptide_count > 100) %>%\n  dplyr::select(accession, gene, mass, peptide_count)\n#> # A tibble: 7 × 4\n#>   accession  gene          mass peptide_count\n#>   <chr>      <chr>        <dbl>         <dbl>\n#> 1 F1LMU0     F1LMU0     222850.           338\n#> 2 Q64578     AT2A1      109409.           126\n#> 3 A0A096MK15 A0A096MK15 772118.           133\n#> 4 F1LRV9     F1LRV9     223400.           240\n#> 5 G3V6E1     G3V6E1     219575.           173\n#> 6 F1LMY4     RYR1       565491.           104\n#> 7 A0A0G2K5J1 A0A0G2K5J1 563314.           102\n\n# OR conditions\nproteomics_data %>%\n  dplyr::filter(mass > 200000 | peptide_count > 300) %>%\n  dplyr::select(accession, gene, mass, peptide_count)\n#> # A tibble: 29 × 4\n#>    accession  gene          mass peptide_count\n#>    <chr>      <chr>        <dbl>         <dbl>\n#>  1 F1LMU0     F1LMU0     222850.           338\n#>  2 D3ZHA0     FLNC       290984.            55\n#>  3 A0A096MK15 A0A096MK15 772118.           133\n#>  4 F1LRV9     F1LRV9     223400.           240\n#>  5 A0A0G2JU96 A0A0G2JU96 571866.            34\n#>  6 M0R9L0     M0R9L0     220194.            28\n#>  7 A0A0G2K7B6 A0A0G2K7B6 242460.            24\n#>  8 F7F9U6     F7F9U6     517417.            16\n#>  9 A0A0G2JUP3 A0A0G2JUP3 815466.             8\n#> 10 G3V6E1     G3V6E1     219575.           173\n#> # ℹ 19 more rows"},{"path":"day1.html","id":"mutate-create-new-columns","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.7 mutate(): Create New Columns","text":"","code":"\n# Calculate log10 transformed values\nproteomics_data %>%\n  dplyr::mutate(log10_mass = log10(mass)) %>%\n  dplyr::select(accession, mass, log10_mass, `2126001_029_f5`) %>%\n  head(3)\n#> # A tibble: 3 × 4\n#>   accession     mass log10_mass `2126001_029_f5`\n#>   <chr>        <dbl>      <dbl>            <dbl>\n#> 1 F1LMU0     222850.       5.35        25114306.\n#> 2 G3V8V3      97288.       4.99        18519365.\n#> 3 A0A0G2JSP8  43019.       4.63       897562438."},{"path":"day1.html","id":"arrange-sort-data","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.8 arrange(): Sort Data","text":"","code":"\n# Sort by mass (ascending)\nproteomics_data %>%\n  dplyr::arrange(mass) %>%\n  dplyr::select(accession, gene, mass) %>%\n  head(3)\n#> # A tibble: 3 × 3\n#>   accession gene    mass\n#>   <chr>     <chr>  <dbl>\n#> 1 P29418    ATP5E  5767.\n#> 2 Q9JJW3    ATPMK  6408.\n#> 3 A9UMV7    A9UMV7 6539.\n\n# Sort descending\nproteomics_data %>%\n  dplyr::arrange(desc(mass)) %>%\n  dplyr::select(accession, gene, mass) %>%\n  head(3)\n#> # A tibble: 3 × 3\n#>   accession  gene          mass\n#>   <chr>      <chr>        <dbl>\n#> 1 A0A0G2JUP3 A0A0G2JUP3 815466.\n#> 2 A0A096MK15 A0A096MK15 772118.\n#> 3 F1M1J2     F1M1J2     623402.\n\n# Sort by multiple columns\nproteomics_data %>%\n  dplyr::arrange(desc(peptide_count), mass) %>%\n  dplyr::select(accession, peptide_count, mass) %>%\n  head(3)\n#> # A tibble: 3 × 3\n#>   accession peptide_count    mass\n#>   <chr>             <dbl>   <dbl>\n#> 1 F1LMU0              338 222850.\n#> 2 F1LRV9              240 223400.\n#> 3 G3V6E1              173 219575."},{"path":"day1.html","id":"summarize-calculate-statistics","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.9 summarize(): Calculate Statistics","text":"","code":"\n# Calculate summary statistics\nproteomics_data %>%\n  dplyr::summarize(\n    n_proteins = n(),\n    mean_mass = mean(mass),\n    median_mass = median(mass),\n    sd_mass = sd(mass),\n    mean_intensity = mean(`2126001_029_f5`)\n  )\n#> # A tibble: 1 × 5\n#>   n_proteins mean_mass median_mass sd_mass mean_intensity\n#>        <int>     <dbl>       <dbl>   <dbl>          <dbl>\n#> 1        824    57788.      39318.  75984.       3059149.\n\n# Multiple samples\nproteomics_data %>%\n  dplyr::summarize(\n    mean_s1 = mean(`2126001_029_f5`),\n    mean_s2 = mean(`2126001_359_f9`),\n    cv_s1 = sd(`2126001_029_f5`) / mean(`2126001_029_f5`) * 100\n  )\n#> # A tibble: 1 × 3\n#>    mean_s1  mean_s2 cv_s1\n#>      <dbl>    <dbl> <dbl>\n#> 1 3059149. 3367563. 1102."},{"path":"day1.html","id":"group_by-grouped-operations","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.10 group_by(): Grouped Operations","text":"","code":"\n# Create groups based on mass\nproteomics_data_grouped <- proteomics_data %>%\n  dplyr::mutate(\n    mass_category = case_when(\n      mass < 50000 ~ \"Low\",\n      mass < 150000 ~ \"Medium\",\n      TRUE ~ \"High\"\n    )\n  )\n\n# Calculate statistics by group\nproteomics_data_grouped %>%\n  dplyr::group_by(mass_category) %>%\n  dplyr::summarize(\n    n_proteins = dplyr::n(),\n    mean_peptides = mean(peptide_count),\n    mean_confidence = mean(confidence_score)\n  )\n#> # A tibble: 3 × 4\n#>   mass_category n_proteins mean_peptides mean_confidence\n#>   <chr>              <int>         <dbl>           <dbl>\n#> 1 High                  43         45.8            4136.\n#> 2 Low                  529          8.71            814.\n#> 3 Medium               252         13.6            1176."},{"path":"day1.html","id":"combining-operations-pipeline","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.11 Combining Operations: Pipeline","text":"","code":"\n# Complete analysis pipeline\nresults <- proteomics_data %>%\n  # Filter high confidence proteins\n  dplyr::filter(confidence_score > 10000) %>%\n  # Calculate mean intensity across samples\n  dplyr::mutate(\n    mean_intensity = rowMeans(select(., starts_with(\"sample\")))\n  ) %>%\n  # Keep relevant columns\n  dplyr::select(accession, gene, mass, confidence_score, mean_intensity) %>%\n  # Sort by mean intensity\n  dplyr::arrange(desc(mean_intensity))\n\nhead(results)\n#> # A tibble: 6 × 5\n#>   accession  gene       mass confidence_score mean_intensity\n#>   <chr>      <chr>     <dbl>            <dbl>          <dbl>\n#> 1 F1LMU0     F1LMU0   2.23e5           40162.            NaN\n#> 2 G3V8V3     G3V8V3   9.73e4           15646.            NaN\n#> 3 A0A0G2JSP8 A0A0G2J… 4.30e4           15567.            NaN\n#> 4 Q64578     AT2A1    1.09e5           14102.            NaN\n#> 5 P15429     ENOB     4.70e4           12564.            NaN\n#> 6 P05065     ALDOA    3.94e4           11642.            NaN"},{"path":"day1.html","id":"tidyr-reshaping-data","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.12 tidyr: Reshaping Data","text":"Key Functions:pivot_longer() - Wide long formatpivot_wider() - Long wide formatseparate() - Split one column multipleunite() - Combine columnsWhy reshape? Different analyses visualizations require different formats","code":""},{"path":"day1.html","id":"wide-vs-long-format","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.13 Wide vs Long Format","text":"Wide format (current data):Long format:","code":"accession  `2126001_029_f5`  `2126001_359_f9`  sample_3\nF1LMU0     2511430   8316460   3577492\nG3V8V3     1851936   2066635   2986710accession  Sample     Intensity\nF1LMU0     `2126001_029_f5`   2511430\nF1LMU0     `2126001_359_f9`   8316460\nF1LMU0     sample_3   3577492\nG3V8V3     `2126001_029_f5`   1851936"},{"path":"day1.html","id":"pivot_longer-wide-to-long","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.14 pivot_longer(): Wide to Long","text":"","code":"\n# Convert to long format\nproteomics_long <- proteomics_data %>%\n  tidyr::pivot_longer(\n    cols = starts_with(\"2\"),\n    names_to = \"Sample\",\n    values_to = \"Intensity\"\n  )\n\nhead(proteomics_long, 10)\n#> # A tibble: 10 × 9\n#>    accession gene   peptide_count unique_peptides\n#>    <chr>     <chr>          <dbl>           <dbl>\n#>  1 F1LMU0    F1LMU0           338             138\n#>  2 F1LMU0    F1LMU0           338             138\n#>  3 F1LMU0    F1LMU0           338             138\n#>  4 F1LMU0    F1LMU0           338             138\n#>  5 F1LMU0    F1LMU0           338             138\n#>  6 F1LMU0    F1LMU0           338             138\n#>  7 F1LMU0    F1LMU0           338             138\n#>  8 F1LMU0    F1LMU0           338             138\n#>  9 F1LMU0    F1LMU0           338             138\n#> 10 F1LMU0    F1LMU0           338             138\n#> # ℹ 5 more variables: confidence_score <dbl>, mass <dbl>,\n#> #   description <chr>, Sample <chr>, Intensity <dbl>"},{"path":"day1.html","id":"why-long-format","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.15 Why Long Format?","text":"Advantages analysis:Easier grouping summarizingBetter ggplot2 visualizationsFacilitates statistical modelingStandard format many tools","code":"\n# Calculate statistics by sample\nproteomics_long %>%\n  dplyr::group_by(Sample) %>%\n  dplyr::summarize(\n    mean_intensity = mean(Intensity),\n    median_intensity = median(Intensity),\n    n_proteins = n()\n  ) %>%\n  head(6)\n#> # A tibble: 6 × 4\n#>   Sample          mean_intensity median_intensity n_proteins\n#>   <chr>                    <dbl>            <dbl>      <int>\n#> 1 2126001_029_f5        3059149.           91354.        824\n#> 2 2126001_068_f3        3782834.           76089.        824\n#> 3 2126001_134_f11       3189430.           84892.        824\n#> 4 2126001_180_f2        2687642.          129483.        824\n#> 5 2126001_198_f12       2881252.           93655.        824\n#> 6 2126001_270_f7        2088286.           95672.        824"},{"path":"day1.html","id":"pivot_wider-long-to-wide","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.16 pivot_wider(): Long to Wide","text":"","code":"\n# Convert back to wide format\nproteomics_wide <- proteomics_long %>%\n  tidyr::pivot_wider(\n    names_from = Sample,\n    values_from = Intensity\n  )\n\nhead(proteomics_wide[, 1:10])\n#> # A tibble: 6 × 10\n#>   accession  gene       peptide_count unique_peptides\n#>   <chr>      <chr>              <dbl>           <dbl>\n#> 1 F1LMU0     F1LMU0               338             138\n#> 2 G3V8V3     G3V8V3               146             113\n#> 3 A0A0G2JSP8 A0A0G2JSP8           117             109\n#> 4 Q64578     AT2A1                126              89\n#> 5 D4AEH9     D4AEH9                87              83\n#> 6 P15429     ENOB                 110              83\n#> # ℹ 6 more variables: confidence_score <dbl>, mass <dbl>,\n#> #   description <chr>, `2126001_029_f5` <dbl>,\n#> #   `2126001_359_f9` <dbl>, `2126001_401_f1` <dbl>"},{"path":"day1.html","id":"working-with-strings-with-stringr","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.17 Working with Strings with stringr","text":"","code":"\n# Extract gene names\nproteomics_data %>%\n  dplyr::mutate(\n    # Convert to uppercase\n    gene_upper = toupper(gene),\n    # Detect pattern\n    is_kinase = stringr::str_detect(description, \"kinase\"),\n    # Extract words\n    first_word = stringr::word(description, 1)\n  ) %>%\n  dplyr::select(gene, description, is_kinase, first_word) %>%\n  head(3)\n#> # A tibble: 3 × 4\n#>   gene       description                is_kinase first_word\n#>   <chr>      <chr>                      <lgl>     <chr>     \n#> 1 F1LMU0     Myosin heavy chain 4       FALSE     Myosin    \n#> 2 G3V8V3     Alpha-1,4 glucan phosphor… FALSE     Alpha-1,4 \n#> 3 A0A0G2JSP8 Creatine kinase            TRUE      Creatine"},{"path":"day1.html","id":"handling-missing-values","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.18 Handling Missing Values","text":"","code":"\n# Create data with missing values\ndata_with_na <- proteomics_data %>%\n  dplyr::mutate(\n    `2126001_029_f5` = ifelse(`2126001_029_f5` < quantile(`2126001_029_f5`, 0.2), \n                     NA, `2126001_029_f5`)\n  )\n\n# Check missing values\ndata_with_na %>%\n  dplyr::summarize(\n    n_total = dplyr::n(),\n    n_missing_s1 = sum(is.na(`2126001_029_f5`)),\n    percent_missing = mean(is.na(`2126001_029_f5`)) * 100\n  )\n#> # A tibble: 1 × 3\n#>   n_total n_missing_s1 percent_missing\n#>     <int>        <int>           <dbl>\n#> 1     824          165            20.0\n\n# Remove rows with NA\ndata_with_na %>%\n  dplyr::filter(!is.na(`2126001_029_f5`)) %>%\n  nrow()\n#> [1] 659\n\n# Replace NA with value\ndata_with_na %>%\n  dplyr::mutate(`2126001_029_f5` = tidyr::replace_na(`2126001_029_f5`, 0)) %>%\n  head(3)\n#> # A tibble: 3 × 19\n#>   accession  gene       peptide_count unique_peptides\n#>   <chr>      <chr>              <dbl>           <dbl>\n#> 1 F1LMU0     F1LMU0               338             138\n#> 2 G3V8V3     G3V8V3               146             113\n#> 3 A0A0G2JSP8 A0A0G2JSP8           117             109\n#> # ℹ 15 more variables: confidence_score <dbl>, mass <dbl>,\n#> #   description <chr>, `2126001_029_f5` <dbl>,\n#> #   `2126001_359_f9` <dbl>, `2126001_401_f1` <dbl>,\n#> #   `2126001_180_f2` <dbl>, `2126001_416_f6` <dbl>,\n#> #   `2126001_422_f10` <dbl>, `2126001_068_f3` <dbl>,\n#> #   `2126001_134_f11` <dbl>, `2126001_270_f7` <dbl>,\n#> #   `2126001_198_f12` <dbl>, `2126001_312_f8` <dbl>, …"},{"path":"day1.html","id":"hands-on-exercise","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7.19 Hands-On Exercise","text":"Task: Transform analyze proteomics data","code":"\n# 1. Load your data\nmy_data <- readxl::read_excel(\"your_data.xlsx\")\n\n# 2. Filter and calculate\nhigh_quality <- my_data %>%\n  dplyr::filter(confidence_score > 10000, peptide_count > 50) %>%\n  dplyr::mutate(mean_intensity = rowMeans(select(., starts_with(\"sample\"))))\n\n# 3. Convert to long format\nlong_data <- my_data %>%\n  tidyr::pivot_longer(cols = starts_with(\"sample\"),\n               names_to = \"Sample\",\n               values_to = \"Intensity\")\n\n# 4. Calculate CV per protein\ncv_data <- long_data %>%\n  dplyr::group_by(accession) %>%\n  dplyr::summarize(mean_int = mean(Intensity, na.rm = TRUE),\n            sd_int = sd(Intensity, na.rm = TRUE),\n            cv = (sd_int / mean_int) * 100)"},{"path":"day1.html","id":"day-1-summary","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.8 Day 1 Summary","text":"Today learned:set R RStudioBasic R operators syntaxData structures: vectors, data frames, lists, factorsIndexing subsetting dataControl flow: /else, loopsWriting custom functionsImporting exploring dataItroduction tidyverse data wrangling","code":""},{"path":"day1.html","id":"homework","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.8.1 Homework","text":"Install required packages Day 2Practice writing functions data manipulationExplore built-datasets R (use data() see available datasets)","code":"\n# Install packages for Day 2\ninstall.packages(c(\"ggplot2\", \"dplyr\", \"tidyr\", \"pheatmap\"))\n\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(c(\"limma\", \"vsn\"))"},{"path":"day1.html","id":"additional-resources","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.9 Additional Resources","text":"R Data Science Hadley WickhamRStudio Cheat SheetsStack Overflow questions","code":""},{"path":"day2.html","id":"day2","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"Day - 2 Introduction to Proteomic Data & Quality Control","text":"","code":""},{"path":"day2.html","id":"learning-objectives-1","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.1 Learning Objectives","text":"end Day 2, able :Understand structure proteomic data matricesIdentify common data quality issuesPerform initial quality control checksVisualize data using PCA, boxplots, heatmapsConduct exploratory data analysis (EDA)","code":""},{"path":"day2.html","id":"day2-mod1","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.2 Module 1: Introduction to Proteomic Data","text":"","code":""},{"path":"day2.html","id":"from-mass-spectrometry-to-quantified-proteins","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.2.1 From Mass Spectrometry to Quantified Proteins","text":"Proteomics workflow:Sample Preparation: Protein extraction, digestion peptidesLC-MS/MS: Liquid chromatography coupled tandem mass spectrometryPeptide Identification: Match spectra peptide sequencesProtein Inference: Aggregate peptides proteinsQuantification: Measure protein abundance\nLabel-free quantification (LFQ)\nIsobaric labeling (TMT, iTRAQ)\nSILAC\nLabel-free quantification (LFQ)Isobaric labeling (TMT, iTRAQ)SILAC","code":""},{"path":"day2.html","id":"structure-of-proteomic-data-matrices","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.2.2 Structure of Proteomic Data Matrices","text":"Typical structure: Proteins × SamplesEach row corresponds quantified protein (protein group),\ncolumn corresponds biological technical sample.\nAdditional annotation tables typically accompany intensity matrix\ndescribe samples (metadata) proteins.","code":"\n## The simulated dataset used throughout this course can be downloaded from:\n## https://github.com/lodiag-holocron/r4proteomics/data\n## After downloading, save the files in your working directory or adjust the path below.\n\n# Load the data components\nprotein_matrix <- read.csv(\"data/protein_matrix.csv\", row.names = 1, \n                           check.names = FALSE) # Proteins × Samples\nsample_metadata <- read.csv(\"data/sample_metadata.csv\")\nprotein_annotations <- read.csv(\"data/protein_annotations.csv\")\n\ncat(\"Matrix dimensions:\", dim(protein_matrix), \"\\n\")\n#> Matrix dimensions: 1500 24\ncat(\"Number of proteins:\", nrow(protein_matrix), \"\\n\")\n#> Number of proteins: 1500\ncat(\"Number of samples:\", ncol(protein_matrix), \"\\n\")\n#> Number of samples: 24\ncat(\"Number of missing values:\", sum(is.na(protein_matrix)), \"\\n\")\n#> Number of missing values: 6172\n\nhead(protein_matrix[, 1:6])\n#>             S01      S02      S03      S04      S05\n#> P00001       NA       NA 20.54926 20.15388 19.46331\n#> P00002 18.04034 19.32129 19.01423 19.03961 19.71593\n#> P00003       NA 19.64438 19.94354 19.22024 19.82211\n#> P00004 20.11957 20.21188 19.73237 19.60153 20.27386\n#> P00005 19.20290 18.26272 18.99547 18.49812 19.08661\n#> P00006 20.05169 20.22521 20.07375 19.96105 19.62537\n#>             S06\n#> P00001 20.01467\n#> P00002 19.80441\n#> P00003 19.73753\n#> P00004 20.41470\n#> P00005 19.41153\n#> P00006       NA"},{"path":"day2.html","id":"understanding-your-data","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.2.3 Understanding Your Data","text":"performing downstream analysis, essential explore\nsample metadata distribution protein intensities\nacross samples. provides insights sample composition,\nmissing value patterns, potential sources technical \nbiological variation.","code":"\nprint(sample_metadata)\n#>    sample_id condition  batch timepoint patient_id sex age\n#> 1        S01   Control Batch1     Week0          1   M  46\n#> 2        S02   Control Batch1     Week0          2   M  43\n#> 3        S03   Control Batch1     Week0          3   M  64\n#> 4        S04   Control Batch1     Week0          4   M  44\n#> 5        S05   Control Batch1     Week4          5   F  53\n#> 6        S06   Control Batch1     Week4          6   F  59\n#> 7        S07   Control Batch1     Week4          7   F  65\n#> 8        S08   Control Batch1     Week4          8   F  57\n#> 9        S09   Control Batch2     Week8          9   M  54\n#> 10       S10   Control Batch2     Week8         10   F  42\n#> 11       S11   Control Batch2     Week8         11   M  48\n#> 12       S12   Control Batch2     Week8         12   F  64\n#> 13       S13 Treatment Batch2     Week0          1   M  46\n#> 14       S14 Treatment Batch2     Week0          2   M  43\n#> 15       S15 Treatment Batch2     Week0          3   M  64\n#> 16       S16 Treatment Batch2     Week0          4   M  44\n#> 17       S17 Treatment Batch3     Week4          5   F  53\n#> 18       S18 Treatment Batch3     Week4          6   F  59\n#> 19       S19 Treatment Batch3     Week4          7   F  65\n#> 20       S20 Treatment Batch3     Week4          8   F  57\n#> 21       S21 Treatment Batch3     Week8          9   M  54\n#> 22       S22 Treatment Batch3     Week8         10   F  42\n#> 23       S23 Treatment Batch3     Week8         11   M  48\n#> 24       S24 Treatment Batch3     Week8         12   F  64\n\nsummary_stats <- data.frame(\n  Sample = colnames(protein_matrix),\n  Mean = apply(protein_matrix, 2, mean, na.rm = TRUE),\n  Median = apply(protein_matrix, 2, median, na.rm = TRUE),\n  SD = apply(protein_matrix, 2, sd, na.rm = TRUE),\n  N_Missing = apply(protein_matrix, 2, function(x) sum(is.na(x)))\n)\n\ncat(\"\\nSummary statistics for protein intensities (per sample):\\n\")\n#> \n#> Summary statistics for protein intensities (per sample):\nprint(summary_stats)\n#>     Sample     Mean   Median        SD N_Missing\n#> S01    S01 19.45024 19.52458 0.6910156       245\n#> S02    S02 19.42210 19.51806 0.7004309       280\n#> S03    S03 19.44595 19.52871 0.6826176       267\n#> S04    S04 19.44953 19.54374 0.7031984       254\n#> S05    S05 19.58108 19.66061 0.6943372       249\n#> S06    S06 19.56474 19.66204 0.7007699       272\n#> S07    S07 19.59101 19.69424 0.7096669       240\n#> S08    S08 19.58221 19.65921 0.7000334       247\n#> S09    S09 20.04697 20.13751 0.7050850       240\n#> S10    S10 20.01929 20.10603 0.6917965       249\n#> S11    S11 20.02985 20.09687 0.6903848       267\n#> S12    S12 20.05337 20.16478 0.7215431       287\n#> S13    S13 19.91305 19.94668 0.8739921       248\n#> S14    S14 19.91966 19.94157 0.8753145       256\n#> S15    S15 19.91708 19.94009 0.8788483       277\n#> S16    S16 19.91192 19.93032 0.8695756       252\n#> S17    S17 20.41227 20.44692 0.8541579       259\n#> S18    S18 20.43735 20.45007 0.8693867       271\n#> S19    S19 20.44325 20.46966 0.8569583       249\n#> S20    S20 20.40676 20.43308 0.9190726       250\n#> S21    S21 20.55711 20.57703 0.8879665       262\n#> S22    S22 20.56632 20.58368 0.8840108       243\n#> S23    S23 20.53248 20.55557 0.8816572       264\n#> S24    S24 20.55187 20.57214 0.8763290       244"},{"path":"day2.html","id":"exercise-2.1-explore-your-data","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.2.4 Exercise 2.1: Explore Your Data","text":"Given proteomic dataset, calculate:Total number proteins quantifiedAverage number missing values per proteinWhich sample missing values?","code":"\n# Solution\ncat(\"1. Total proteins:\", nrow(protein_matrix), \"\\n\")\n#> 1. Total proteins: 1500\n\nmissing_per_protein <- apply(protein_matrix, 1, function(x) sum(is.na(x)))\ncat(\"2. Average missing per protein:\", \n    round(mean(missing_per_protein), 2), \"\\n\")\n#> 2. Average missing per protein: 4.11\n\nmissing_per_sample <- apply(protein_matrix, 2, function(x) sum(is.na(x)))\nworst_sample <- names(which.max(missing_per_sample))\ncat(\"3. Sample with most missing:\", worst_sample, \n    \"with\", max(missing_per_sample), \"missing values\\n\")\n#> 3. Sample with most missing: S12 with 287 missing values"},{"path":"day2.html","id":"day2-mod2","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.3 Module 2: Initial Quality Control","text":"","code":""},{"path":"day2.html","id":"missing-data-analysis","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.3.1 Missing Data Analysis","text":"Missing data common proteomics. Understanding pattern crucial.Understanding much data missing occurs \nessential first step quality control, missingness can reflect\nlow-abundance proteins, stochastic sampling, technical artifacts.","code":"\n# Calculate missingness\nmissing_per_protein <- apply(protein_matrix, 1, function(x) sum(is.na(x)))\nmissing_per_sample <- apply(protein_matrix, 2, function(x) sum(is.na(x)))\n\n# Visualize missing data pattern\nlibrary(reshape2)\n\nmissing_df <- melt(is.na(protein_matrix))\ncolnames(missing_df) <- c(\"Protein\", \"Sample\", \"Missing\")\n\n# Plot missing data heatmap\nggplot(missing_df, aes(x = Sample, y = Protein, fill = Missing)) +\n  geom_tile() +\n  scale_fill_manual(values = c(\"TRUE\" = \"red\", \"FALSE\" = \"grey90\")) +\n  theme_minimal() +\n  theme(axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()) +\n  labs(title = \"Missing Data Pattern\",\n       subtitle = paste0(\"Red = Missing (\", \n                        round(mean(missing_df$Missing) * 100, 1), \"% total)\"))\n\n# Histogram of missing values per protein\nhist(missing_per_protein,\n     breaks = 20,\n     main = \"Distribution of Missing Values per Protein\",\n     xlab = \"Number of Missing Values\",\n     col = \"steelblue\")"},{"path":"day2.html","id":"detecting-outliers-and-extreme-values","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.3.2 Detecting Outliers and Extreme Values","text":"Visual inspection abundance distributions helps identify outlier\nsamples, intensity shifts, potential batch effects. Boxplots \ndensity plots provide complementary views overall data structure.","code":"\n# Box plots for each sample\nprotein_df <- as.data.frame(protein_matrix)\nprotein_df$protein_id <- rownames(protein_df)\n\nprotein_long <- pivot_longer(protein_df, \n                             cols = -protein_id,\n                             names_to = \"sample_id\",\n                             values_to = \"abundance\")\n\n# Add condition information\nprotein_long <- merge(protein_long, sample_metadata, by = \"sample_id\")\n\n# Boxplot\nggplot(protein_long, aes(x = sample_id, y = abundance, fill = condition)) +\n  geom_boxplot(outlier.size = 0.5) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Abundance Distribution by Sample\",\n       x = \"Sample\", y = \"Log2 Abundance\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n# Density plots\nggplot(protein_long, aes(x = abundance, color = sample_id)) +\n  geom_density() +\n  theme_minimal() +\n  labs(title = \"Density Plot of Protein Abundances\",\n       x = \"Log2 Abundance\", y = \"Density\") +\n  theme(legend.position = \"none\")"},{"path":"day2.html","id":"batch-effects-detection","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.3.3 Batch Effects Detection","text":"Batch effects systematic non-biological variations.\ncan introduced sample preparation, instrument runs,\ntechnical steps.Principal Component Analysis (PCA) powerful tool detect\neffects projecting high-dimensional data lower-dimensional\nspace highlighting clustering patterns.","code":"\n# PCA colored by batch\npca_data <- t(na.omit(protein_matrix))\npca_result <- prcomp(pca_data, scale. = TRUE)\n\n# Create PCA data frame\npca_df <- data.frame(\n  PC1 = pca_result$x[, 1],\n  PC2 = pca_result$x[, 2],\n  sample_id = rownames(pca_result$x)\n)\n\npca_df <- merge(pca_df, sample_metadata, by = \"sample_id\")\n\n# Variance explained\nvar_explained <- summary(pca_result)$importance[2, 1:2] * 100\n\n# PCA plot by batch\nggplot(pca_df, aes(x = PC1, y = PC2, color = batch, shape = condition)) +\n  geom_point(size = 4) +\n  theme_minimal() +\n  labs(title = \"PCA Analysis - Batch Effect Detection\",\n       x = paste0(\"PC1 (\", round(var_explained[1], 1), \"%)\"),\n       y = paste0(\"PC2 (\", round(var_explained[2], 1), \"%)\")) +\n  scale_color_brewer(palette = \"Set1\")\n\n# PCA plot by condition\nggplot(pca_df, aes(x = PC1, y = PC2, color = condition, shape = batch)) +\n  geom_point(size = 4) +\n  theme_minimal() +\n  labs(title = \"PCA Analysis - Biological Conditions\",\n       x = paste0(\"PC1 (\", round(var_explained[1], 1), \"%)\"),\n       y = paste0(\"PC2 (\", round(var_explained[2], 1), \"%)\")) +\n  scale_color_brewer(palette = \"Dark2\")"},{"path":"day2.html","id":"sample-correlation-analysis","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.3.4 Sample Correlation Analysis","text":"Correlation analysis provides global overview sample similarity\nbased protein abundance profiles.High correlation typically indicates consistent quantification\nacross samples, lower correlations may highlight outliers,\nbatch effects, technical artifacts. Heatmaps combined metadata\nannotations offer intuitive way inspect relationships.","code":"\n# Calculate sample correlations\ncor_matrix <- cor(protein_matrix, use = \"pairwise.complete.obs\")\n\n# Heatmap\nrownames(sample_metadata) <- sample_metadata$sample_id\n\npheatmap(cor_matrix,\n         annotation_col = sample_metadata[, c(\"condition\", \"batch\"), drop = FALSE],\n         annotation_row = sample_metadata[, c(\"condition\", \"batch\"), drop = FALSE],\n         main = \"Sample-Sample Correlation\",\n         color = colorRampPalette(c(\"blue\", \"white\", \"red\"))(50),\n         breaks = seq(0.5, 1, length.out = 51))"},{"path":"day2.html","id":"exercise-2.2-quality-control-checks","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.3.5 Exercise 2.2: Quality Control Checks","text":"Perform QC provided dataset:Calculate percentage proteins >50% missing valuesIdentify outlier samples (median abundance far others)Check batch effects using PCA","code":"\n# Solution\n# 1. Proteins with >50% missing\nmissing_pct <- apply(protein_matrix, 1, function(x) sum(is.na(x)) / length(x))\nhigh_missing <- sum(missing_pct > 0.5)\ncat(\"Proteins with >50% missing:\", high_missing, \n    \"(\", round(high_missing / nrow(protein_matrix) * 100, 1), \"%)\\n\")\n#> Proteins with >50% missing: 75 ( 5 %)\n\n# 2. Outlier samples based on median\nsample_medians <- apply(protein_matrix, 2, median, na.rm = TRUE)\nmedian_overall <- median(sample_medians)\nmad_overall <- mad(sample_medians)\noutliers <- abs(sample_medians - median_overall) > 3 * mad_overall\n\nif (any(outliers)) {\n  cat(\"Outlier samples:\", names(sample_medians)[outliers], \"\\n\")\n} else {\n  cat(\"No outlier samples detected\\n\")\n}\n#> No outlier samples detected\n\n# 3. Batch effects - already shown in PCA above\ncat(\"Check PCA plot above for batch effect visualization\\n\")\n#> Check PCA plot above for batch effect visualization"},{"path":"day2.html","id":"day2-mod3","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.4 Module 3: Exploratory Data Analysis (EDA)","text":"","code":""},{"path":"day2.html","id":"distribution-of-intensities","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.4.1 Distribution of Intensities","text":"Examining distribution protein abundances helps identify global\ntrends, skewness, technical artifacts dataset.histograms violin plots provide complementary perspectives \noverall intensity patterns.","code":"\n# Histogram of all values\nggplot(protein_long, aes(x = abundance)) +\n  geom_histogram(bins = 50, fill = \"steelblue\", color = \"black\", alpha = 0.7) +\n  theme_minimal() +\n  labs(title = \"Distribution of Protein Abundances\",\n       x = \"Log2 Abundance\", y = \"Frequency\")\n\n# Violin plots by condition\nggplot(protein_long, aes(x = condition, y = abundance, fill = condition)) +\n  geom_violin() +\n  geom_boxplot(width = 0.1, fill = \"white\", outlier.size = 0.5) +\n  theme_minimal() +\n  labs(title = \"Abundance Distribution by Condition\",\n       x = \"Condition\", y = \"Log2 Abundance\") +\n  scale_fill_brewer(palette = \"Set2\")"},{"path":"day2.html","id":"hierarchical-clustering","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.4.2 Hierarchical Clustering","text":"Hierarchical clustering groups samples proteins based similarity\nabundance profiles.approach helps identify natural clusters, outliers, \nbatch-related patterns data.","code":"\n# Remove proteins with too many missing values\ncomplete_proteins <- rowSums(is.na(protein_matrix)) < ncol(protein_matrix) * 0.3\nfiltered_matrix <- protein_matrix[complete_proteins, ]\n\n# Impute remaining missing values with row means\nfor (i in 1:nrow(filtered_matrix)) {\n  missing_idx <- is.na(filtered_matrix[i, ])\n  if (any(missing_idx)) {\n    filtered_matrix[i, missing_idx] <- mean(filtered_matrix[i, ], na.rm = TRUE)\n  }\n}\n\n# Hierarchical clustering heatmap\nannotation_col <- sample_metadata[, c(\"condition\", \"batch\", \"timepoint\")]\nrownames(annotation_col) <- sample_metadata$sample_id\n\npheatmap(filtered_matrix,\n         scale = \"row\",\n         clustering_distance_rows = \"euclidean\",\n         clustering_distance_cols = \"euclidean\",\n         annotation_col = annotation_col,\n         show_rownames = FALSE,\n         main = \"Hierarchical Clustering of Samples\",\n         color = colorRampPalette(c(\"blue\", \"white\", \"red\"))(50))"},{"path":"day2.html","id":"sample-similarity-analysis","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.4.3 Sample Similarity Analysis","text":"Assessing sample similarity helps detect outliers, batch effects,\nunexpected clustering among samples.Euclidean distances multidimensional scaling (MDS) provide\nadditional overview global relationships samples.","code":"\n# Calculate Euclidean distances between samples\nsample_dist <- dist(t(filtered_matrix))\nsample_dist_matrix <- as.matrix(sample_dist)\n\n# Heatmap of distances\npheatmap(sample_dist_matrix,\n         annotation_col = annotation_col,\n         annotation_row = annotation_col,\n         main = \"Sample-Sample Distance Matrix\",\n         color = colorRampPalette(c(\"red\", \"white\"))(10))\n\n# MDS plot (alternative to PCA)\nmds_result <- cmdscale(sample_dist, k = 2)\nmds_df <- data.frame(\n  MDS1 = mds_result[, 1],\n  MDS2 = mds_result[, 2],\n  sample_id = colnames(filtered_matrix)\n)\nmds_df <- merge(mds_df, sample_metadata, by = \"sample_id\")\n\nggplot(mds_df, aes(x = MDS1, y = MDS2, color = condition, shape = batch)) +\n  geom_point(size = 4) +\n  theme_minimal() +\n  labs(title = \"MDS Plot of Sample Similarity\",\n       x = \"MDS Dimension 1\", y = \"MDS Dimension 2\") +\n  scale_color_brewer(palette = \"Dark2\")"},{"path":"day2.html","id":"coefficient-of-variation-analysis","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.4.4 Coefficient of Variation Analysis","text":"coefficient variation (CV) quantifies relative variability\nprotein abundances across samples.High CV values may indicate technical variability highly dynamic\nproteins, low CV suggests stable proteins.","code":"\n# Calculate CV for each protein\ncalculate_cv <- function(x) {\n  (sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)) * 100\n}\n\ncv_by_condition <- protein_long %>%\n  group_by(protein_id, condition) %>%\n  summarise(cv = calculate_cv(abundance), .groups = \"drop\")\n\n# Plot CV distribution\nggplot(cv_by_condition, aes(x = cv, fill = condition)) +\n  geom_histogram(bins = 30, alpha = 0.7, position = \"identity\") +\n  theme_minimal() +\n  labs(title = \"Coefficient of Variation Distribution\",\n       x = \"CV (%)\", y = \"Count\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  facet_wrap(~ condition, ncol = 1)\n\n# Summary statistics\ncv_summary <- cv_by_condition %>%\n  group_by(condition) %>%\n  summarise(\n    mean_cv = mean(cv, na.rm = TRUE),\n    median_cv = median(cv, na.rm = TRUE),\n    sd_cv = sd(cv, na.rm = TRUE)\n  )\n\nprint(cv_summary)\n#> # A tibble: 2 × 4\n#>   condition mean_cv median_cv sd_cv\n#>   <chr>       <dbl>     <dbl> <dbl>\n#> 1 Control      2.37      2.30 0.685\n#> 2 Treatment    2.33      2.25 0.633"},{"path":"day2.html","id":"exercise-2.3-complete-eda","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.4.5 Exercise 2.3: Complete EDA","text":"Perform complete exploratory analysis:Create report summarizing data qualityIdentify top 10 variable proteinsCheck samples cluster biological condition","code":"\n# Solution\n# 1. Data quality report\ncat(\"=== DATA QUALITY REPORT ===\\n\\n\")\n#> === DATA QUALITY REPORT ===\ncat(\"Dataset dimensions:\", nrow(protein_matrix), \"proteins x\", \n    ncol(protein_matrix), \"samples\\n\")\n#> Dataset dimensions: 1500 proteins x 24 samples\ncat(\"Total missing values:\", sum(is.na(protein_matrix)), \n    \"(\", round(mean(is.na(protein_matrix)) * 100, 1), \"%)\\n\")\n#> Total missing values: 6172 ( 17.1 %)\ncat(\"Samples:\", paste(sample_metadata$sample_id, collapse = \", \"), \"\\n\")\n#> Samples: S01, S02, S03, S04, S05, S06, S07, S08, S09, S10, S11, S12, S13, S14, S15, S16, S17, S18, S19, S20, S21, S22, S23, S24\ncat(\"Conditions:\", paste(unique(sample_metadata$condition), collapse = \", \"), \"\\n\")\n#> Conditions: Control, Treatment\ncat(\"Batches:\", paste(unique(sample_metadata$batch), collapse = \", \"), \"\\n\\n\")\n#> Batches: Batch1, Batch2, Batch3\n\n# 2. Top 10 most variable proteins\nprotein_variance <- apply(filtered_matrix, 1, var, na.rm = TRUE)\ntop10_variable <- names(sort(protein_variance, decreasing = TRUE)[1:10])\ncat(\"Top 10 most variable proteins:\\n\")\n#> Top 10 most variable proteins:\nprint(top10_variable)\n#>  [1] \"P00460\" \"P00168\" \"P00438\" \"P00285\" \"P00236\" \"P00372\"\n#>  [7] \"P00125\" \"P00960\" \"P00513\" \"P00856\"\n\n# Plot top variable proteins\ntop10_data <- protein_long %>%\n  filter(protein_id %in% top10_variable)\n\nggplot(top10_data, aes(x = sample_id, y = abundance, color = condition, group = 1)) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~ protein_id, scales = \"free_y\", ncol = 2) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Top 10 Most Variable Proteins\", x = \"Sample\", y = \"Abundance\")\n\n# 3. Clustering by condition\ncat(\"Checking sample clustering by condition:\\n\")\n#> Checking sample clustering by condition:\ncat(\"Review the PCA and hierarchical clustering plots above.\\n\")\n#> Review the PCA and hierarchical clustering plots above.\ncat(\"Samples should cluster primarily by condition if biological signal is strong.\\n\")\n#> Samples should cluster primarily by condition if biological signal is strong."},{"path":"day2.html","id":"creating-quality-control-reports","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.5 Creating Quality Control Reports","text":"","code":"\n# Function to generate QC report\ngenerate_qc_report <- function(data_matrix, metadata) {\n  report <- list()\n  \n  # Basic statistics\n  report$n_proteins <- nrow(data_matrix)\n  report$n_samples <- ncol(data_matrix)\n  report$missing_pct <- mean(is.na(data_matrix)) * 100\n  \n  # Sample statistics\n  report$sample_stats <- data.frame(\n    Sample = colnames(data_matrix),\n    N_Quantified = colSums(!is.na(data_matrix)),\n    Median_Abundance = apply(data_matrix, 2, median, na.rm = TRUE),\n    Mean_Abundance = apply(data_matrix, 2, mean, na.rm = TRUE),\n    SD_Abundance = apply(data_matrix, 2, sd, na.rm = TRUE)\n  )\n  \n  # Protein statistics\n  report$protein_stats <- data.frame(\n    N_Complete = sum(rowSums(is.na(data_matrix)) == 0),\n    N_Partial = sum(rowSums(is.na(data_matrix)) > 0 & rowSums(is.na(data_matrix)) < ncol(data_matrix)),\n    N_Mostly_Missing = sum(rowSums(is.na(data_matrix)) > ncol(data_matrix) * 0.5)\n  )\n  \n  return(report)\n}\n\n# Generate report\nqc_report <- generate_qc_report(protein_matrix, sample_metadata)\n\n# Print report\ncat(\"=== QUALITY CONTROL SUMMARY ===\\n\\n\")\n#> === QUALITY CONTROL SUMMARY ===\ncat(\"Total Proteins:\", qc_report$n_proteins, \"\\n\")\n#> Total Proteins: 1500\ncat(\"Total Samples:\", qc_report$n_samples, \"\\n\")\n#> Total Samples: 24\ncat(\"Missing Data:\", round(qc_report$missing_pct, 2), \"%\\n\\n\")\n#> Missing Data: 17.14 %\n\ncat(\"Protein Completeness:\\n\")\n#> Protein Completeness:\ncat(\"  Complete (no missing):\", qc_report$protein_stats$N_Complete, \"\\n\")\n#>   Complete (no missing): 120\ncat(\"  Partial missing:\", qc_report$protein_stats$N_Partial, \"\\n\")\n#>   Partial missing: 1305\ncat(\"  Mostly missing (>50%):\", qc_report$protein_stats$N_Mostly_Missing, \"\\n\\n\")\n#>   Mostly missing (>50%): 75\n\nprint(qc_report$sample_stats)\n#>     Sample N_Quantified Median_Abundance Mean_Abundance\n#> S01    S01         1255         19.52458       19.45024\n#> S02    S02         1220         19.51806       19.42210\n#> S03    S03         1233         19.52871       19.44595\n#> S04    S04         1246         19.54374       19.44953\n#> S05    S05         1251         19.66061       19.58108\n#> S06    S06         1228         19.66204       19.56474\n#> S07    S07         1260         19.69424       19.59101\n#> S08    S08         1253         19.65921       19.58221\n#> S09    S09         1260         20.13751       20.04697\n#> S10    S10         1251         20.10603       20.01929\n#> S11    S11         1233         20.09687       20.02985\n#> S12    S12         1213         20.16478       20.05337\n#> S13    S13         1252         19.94668       19.91305\n#> S14    S14         1244         19.94157       19.91966\n#> S15    S15         1223         19.94009       19.91708\n#> S16    S16         1248         19.93032       19.91192\n#> S17    S17         1241         20.44692       20.41227\n#> S18    S18         1229         20.45007       20.43735\n#> S19    S19         1251         20.46966       20.44325\n#> S20    S20         1250         20.43308       20.40676\n#> S21    S21         1238         20.57703       20.55711\n#> S22    S22         1257         20.58368       20.56632\n#> S23    S23         1236         20.55557       20.53248\n#> S24    S24         1256         20.57214       20.55187\n#>     SD_Abundance\n#> S01    0.6910156\n#> S02    0.7004309\n#> S03    0.6826176\n#> S04    0.7031984\n#> S05    0.6943372\n#> S06    0.7007699\n#> S07    0.7096669\n#> S08    0.7000334\n#> S09    0.7050850\n#> S10    0.6917965\n#> S11    0.6903848\n#> S12    0.7215431\n#> S13    0.8739921\n#> S14    0.8753145\n#> S15    0.8788483\n#> S16    0.8695756\n#> S17    0.8541579\n#> S18    0.8693867\n#> S19    0.8569583\n#> S20    0.9190726\n#> S21    0.8879665\n#> S22    0.8840108\n#> S23    0.8816572\n#> S24    0.8763290"},{"path":"day2.html","id":"day-2-summary","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.6 Day 2 Summary","text":"Today learned:✓ Structure proteomic data matrices✓ Common data quality issues (missing values, outliers, batch effects)✓ Quality control visualization techniques✓ Exploratory data analysis methods✓ Sample correlation clustering","code":""},{"path":"day2.html","id":"key-takeaways","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.6.1 Key Takeaways","text":"Missing data common proteomics - understand pattern imputationBatch effects can confound biological signals - always check PCAQuality control performed statistical analysisVisualization essential understanding data","code":""},{"path":"day2.html","id":"homework-1","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.6.2 Homework","text":"Apply QC pipeline new datasetPractice identifying batch effectsCreate custom QC visualizations","code":"\n# Prepare for Day 3\ninstall.packages(c(\"preprocessCore\", \"matrixStats\"))\n\nBiocManager::install(c(\"limma\", \"vsn\", \"sva\"))"},{"path":"day2.html","id":"additional-resources-1","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.7 Additional Resources","text":"Proteomics Data Analysis Best PracticesUnderstanding PCA ProteomicsKammers et al. (2015) “Detecting Significant Changes Protein Abundance”","code":""},{"path":"day2.html","id":"case-study-real-proteomic-dataset","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.8 Case Study: Real Proteomic Dataset","text":"","code":"\n# Example workflow for your own data\n# 1. Load data\nmy_data <- read.csv(\"your_protein_data.csv\", row.names = 1)\n\n# 2. Load metadata\nmy_metadata <- read.csv(\"your_sample_metadata.csv\")\n\n# 3. Initial QC\nqc_report <- generate_qc_report(my_data, my_metadata)\n\n# 4. Visualizations\n# - PCA\n# - Correlation heatmap\n# - Missing data pattern\n# - Boxplots\n\n# 5. Document findings\n# - Any problematic samples?\n# - Batch effects present?\n# - Next steps for preprocessing"},{"path":"day3.html","id":"day3","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"Day - 3 Preprocessing and Differential Expression","text":"","code":""},{"path":"day3.html","id":"learning-objectives-2","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.1 Learning Objectives","text":"end Day 3, able :Apply different normalization methods proteomic dataPerform batch effect correctionConduct differential expression analysis using limmaInterpret visualize differential expression resultsCreate volcano plots MA plots","code":""},{"path":"day3.html","id":"day3-mod1","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2 Module 1: Data Preprocessing","text":"","code":""},{"path":"day3.html","id":"why-normalize","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.1 Why Normalize?","text":"Normalization removes systematic technical variation :Make samples comparableReduce technical noisePreserve biological signal","code":""},{"path":"day3.html","id":"loading-example-data","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.2 Loading Example Data","text":"","code":"\n# Load the data components\nprotein_matrix <- read.csv(\"data/protein_matrix.csv\", row.names = 1, \n                           check.names = FALSE) # Proteins × Samples\nsample_metadata <- read.csv(\"data/sample_metadata.csv\")\nprotein_annotations <- read.csv(\"data/protein_annotations.csv\")"},{"path":"day3.html","id":"initial-data-exploration","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.3 Initial Data Exploration","text":"","code":"\ncat(\"=== DATASET STRUCTURE ===\\n\")\n#> === DATASET STRUCTURE ===\ncat(\"Protein matrix dimensions:\", dim(protein_matrix), \"\\n\")\n#> Protein matrix dimensions: 1500 24\ncat(\"Sample metadata:\\n\")\n#> Sample metadata:\nprint(sample_metadata)\n#>    sample_id condition  batch timepoint patient_id sex age\n#> 1        S01   Control Batch1     Week0          1   M  46\n#> 2        S02   Control Batch1     Week0          2   M  43\n#> 3        S03   Control Batch1     Week0          3   M  64\n#> 4        S04   Control Batch1     Week0          4   M  44\n#> 5        S05   Control Batch1     Week4          5   F  53\n#> 6        S06   Control Batch1     Week4          6   F  59\n#> 7        S07   Control Batch1     Week4          7   F  65\n#> 8        S08   Control Batch1     Week4          8   F  57\n#> 9        S09   Control Batch2     Week8          9   M  54\n#> 10       S10   Control Batch2     Week8         10   F  42\n#> 11       S11   Control Batch2     Week8         11   M  48\n#> 12       S12   Control Batch2     Week8         12   F  64\n#> 13       S13 Treatment Batch2     Week0          1   M  46\n#> 14       S14 Treatment Batch2     Week0          2   M  43\n#> 15       S15 Treatment Batch2     Week0          3   M  64\n#> 16       S16 Treatment Batch2     Week0          4   M  44\n#> 17       S17 Treatment Batch3     Week4          5   F  53\n#> 18       S18 Treatment Batch3     Week4          6   F  59\n#> 19       S19 Treatment Batch3     Week4          7   F  65\n#> 20       S20 Treatment Batch3     Week4          8   F  57\n#> 21       S21 Treatment Batch3     Week8          9   M  54\n#> 22       S22 Treatment Batch3     Week8         10   F  42\n#> 23       S23 Treatment Batch3     Week8         11   M  48\n#> 24       S24 Treatment Batch3     Week8         12   F  64\n\ncat(\"\\nProtein annotations (first 5):\\n\")\n#> \n#> Protein annotations (first 5):\nprint(head(protein_annotations, 5))\n#>   protein_id gene_symbol protein_name molecular_weight\n#> 1     P00001      CTNNB1 Protein_1953           120953\n#> 2     P00002        AKT1 Protein_1945           205283\n#> 3     P00003      PIK3CA Protein_2735            18375\n#> 4     P00004         RET Protein_4380            65719\n#> 5     P00005      PIK3CA Protein_4658           222652\n#>   peptide_count confidence_score\n#> 1            22             50.3\n#> 2            11             77.6\n#> 3             3             66.8\n#> 4            12             59.7\n#> 5             2             93.1\n\ncat(\"\\nExperimental design:\\n\")\n#> \n#> Experimental design:\ndesign_table <- table(sample_metadata$condition, sample_metadata$batch)\nprint(design_table)\n#>            \n#>             Batch1 Batch2 Batch3\n#>   Control        8      4      0\n#>   Treatment      0      4      8\n\ncat(\"\\nData summary:\\n\")\n#> \n#> Data summary:\nsummary_stats <- data.frame(\n  Statistic = c(\"Total proteins\", \"Total samples\", \"Missing values\", \"Missing percentage\"),\n  Value = c(\n    nrow(protein_matrix),\n    ncol(protein_matrix),\n    sum(is.na(protein_matrix)),\n    paste0(round(mean(is.na(protein_matrix)) * 100, 1), \"%\")\n  )\n)\nprint(summary_stats)\n#>            Statistic Value\n#> 1     Total proteins  1500\n#> 2      Total samples    24\n#> 3     Missing values  6172\n#> 4 Missing percentage 17.1%\n\npar(mfrow = c(1, 2))\nboxplot(protein_matrix, main = \"Raw Data - Before Preprocessing\", \n        las = 2, cex.axis = 0.7, ylab = \"Log2 Abundance\")\nplot(density(protein_matrix[!is.na(protein_matrix)], na.rm = TRUE), \n     main = \"Distribution of Raw Values\")"},{"path":"day3.html","id":"handling-missing-values-1","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.4 Handling Missing Values","text":"","code":"\n# Strategy 1: Remove proteins with too many missing values\nthreshold <- 0.3  # Remove if >30% missing\nmissing_per_protein <- rowSums(is.na(protein_matrix)) / ncol(protein_matrix)\nfiltered_proteins <- missing_per_protein <= threshold\n\nprotein_matrix_filtered <- protein_matrix[filtered_proteins, ]\n\ncat(\"Proteins after filtering:\", nrow(protein_matrix_filtered), \"\\n\")\n#> Proteins after filtering: 1383\n\n# Strategy 2: Imputation (simple mean imputation) with a function\nhandle_missing_values <- function(data_matrix, missing_threshold = 0.2, \n                                  impute_method = \"min\") {\n  \n  cat(\"Initial proteins:\", nrow(data_matrix), \"\\n\")\n  cat(\"Initial missing values:\", sum(is.na(data_matrix)), \"\\n\")\n  \n  # Strategy 1: Remove proteins with too many missing values\n  missing_per_protein <- rowSums(is.na(data_matrix)) / ncol(data_matrix)\n  filtered_proteins <- missing_per_protein <= missing_threshold\n  \n  data_filtered <- data_matrix[filtered_proteins, ]\n  cat(\"Proteins after filtering (missing <=\", \n      missing_threshold*100, \"%):\", nrow(data_filtered), \"\\n\")\n  \n  # Strategy 2: Improved imputation\n  data_imputed <- data_filtered\n  \n  for (i in 1:nrow(data_imputed)) {\n    row_vals <- data_imputed[i, ]\n    \n    if (any(is.na(row_vals))) {\n      if (impute_method == \"min\") {\n        # Impute with minimum value per protein (common in proteomics)\n        impute_val <- min(row_vals, na.rm = TRUE) - 0.5  # Slightly below minimum\n      } else if (impute_method == \"mean\") {\n        # Mean imputation\n        impute_val <- mean(row_vals, na.rm = TRUE)\n      } else if (impute_method == \"knn\") {\n        # Simple k-NN approximation (using row mean as proxy)\n        impute_val <- mean(row_vals, na.rm = TRUE)\n      }\n      \n      data_imputed[i, is.na(row_vals)] <- impute_val\n    }\n  }\n  \n  cat(\"Missing values after imputation:\", sum(is.na(data_imputed)), \"\\n\")\n  \n  return(data_imputed)\n}\n\n# Apply missing value handling\nprotein_matrix_imputed <- handle_missing_values(protein_matrix, \n                                                missing_threshold = 0.3, \n                                                impute_method = \"min\")\n#> Initial proteins: 1500 \n#> Initial missing values: 6172 \n#> Proteins after filtering (missing <= 30 %): 1383 \n#> Missing values after imputation: 0\n\n# Verify imputation worked\ncat(\"\\nAfter imputation:\\n\")\n#> \n#> After imputation:\ncat(\"Dimensions:\", dim(protein_matrix_imputed), \"\\n\")\n#> Dimensions: 1383 24\ncat(\"Missing values:\", sum(is.na(protein_matrix_imputed)), \"\\n\")\n#> Missing values: 0"},{"path":"day3.html","id":"normalization-methods","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.5 Normalization Methods","text":"","code":""},{"path":"day3.html","id":"median-normalization","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.5.1 1. Median Normalization","text":"","code":"\n# Calculate median for each sample\nsample_medians <- apply(protein_matrix_imputed, 2, median, na.rm = TRUE)\nglobal_median <- median(sample_medians)\n\n# Normalize\nprotein_matrix_median <- protein_matrix_imputed\nfor (i in 1:ncol(protein_matrix_median)) {\n  protein_matrix_median[, i] <- protein_matrix_median[, i] - \n    sample_medians[i] + global_median\n}\n\n# Visualize before and after\npar(mfrow = c(1, 2))\nboxplot(protein_matrix_imputed, main = \"Before Median Normalization\",\n        las = 2, cex.axis = 0.7, ylab = \"Abundance\")\nboxplot(protein_matrix_median, main = \"After Median Normalization\",\n        las = 2, cex.axis = 0.7, ylab = \"Abundance\")"},{"path":"day3.html","id":"quantile-normalization","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.5.2 2. Quantile Normalization","text":"","code":"\n# Quantile normalization\nprotein_matrix_quantile <- limma::normalizeBetweenArrays(protein_matrix_imputed, \n                                                          method = \"quantile\")\n\n# Visualize\npar(mfrow = c(1, 2))\nboxplot(protein_matrix_imputed, main = \"Before Quantile Normalization\",\n        las = 2, cex.axis = 0.7, ylab = \"Abundance\")\nboxplot(protein_matrix_quantile, main = \"After Quantile Normalization\",\n        las = 2, cex.axis = 0.7, ylab = \"Abundance\")"},{"path":"day3.html","id":"vsn-variance-stabilizing-normalization","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.5.3 3. VSN (Variance Stabilizing Normalization)","text":"","code":"\nprotein_matrix_imputed <- as.matrix(protein_matrix_imputed)\n# VSN normalization\nvsn_fit <- vsn::vsn2(protein_matrix_imputed)\nprotein_matrix_vsn <- vsn::predict(vsn_fit, protein_matrix_imputed)\n\n# Visualize mean-sd relationship\npar(mfrow = c(1, 2))\nvsn::meanSdPlot(protein_matrix_imputed, main = \"Before VSN\")\nvsn::meanSdPlot(protein_matrix_vsn, main = \"After VSN\")"},{"path":"day3.html","id":"comparing-normalization-methods","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.6 Comparing Normalization Methods","text":"","code":"\n# PCA comparison\nplot_pca <- function(data, title, metadata) {\n  pca_result <- prcomp(t(data), scale. = FALSE)\n  var_exp <- summary(pca_result)$importance[2, 1:2] * 100\n  \n  pca_df <- data.frame(\n    PC1 = pca_result$x[, 1],\n    PC2 = pca_result$x[, 2],\n    condition = metadata$condition,\n    batch = metadata$batch\n  )\n  \n  ggplot(pca_df, aes(x = PC1, y = PC2, color = condition, shape = batch)) +\n    geom_point(size = 3) +\n    theme_minimal() +\n    labs(title = title,\n         x = paste0(\"PC1 (\", round(var_exp[1], 1), \"%)\"),\n         y = paste0(\"PC2 (\", round(var_exp[2], 1), \"%)\")) +\n    scale_color_brewer(palette = \"Set1\")\n}\n\n# Compare all methods\np1 <- plot_pca(protein_matrix_imputed, \"Raw Data\", sample_metadata)\np2 <- plot_pca(protein_matrix_median, \"Median Normalized\", sample_metadata)\np3 <- plot_pca(protein_matrix_quantile, \"Quantile Normalized\", sample_metadata)\np4 <- plot_pca(protein_matrix_vsn, \"VSN Normalized\", sample_metadata)\n\nlibrary(gridExtra)\ngrid.arrange(p1, p2, p3, p4, ncol = 2)"},{"path":"day3.html","id":"exercise-3.1-apply-normalization","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.7 Exercise 3.1: Apply Normalization","text":"Apply three normalization methods :Calculate CV methodCompare sample correlationsChoose best method data","code":"\n# Solution\ncalculate_mean_cv <- function(data) {\n  cvs <- apply(data, 1, function(x) sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE) * 100)\n  mean(cvs, na.rm = TRUE)\n}\n\ncat(\"Mean CV - Raw:\", round(calculate_mean_cv(protein_matrix_imputed), 2), \"%\\n\")\n#> Mean CV - Raw: 3.93 %\ncat(\"Mean CV - Median:\", round(calculate_mean_cv(protein_matrix_median), 2), \"%\\n\")\n#> Mean CV - Median: 3.5 %\ncat(\"Mean CV - Quantile:\", round(calculate_mean_cv(protein_matrix_quantile), 2), \"%\\n\")\n#> Mean CV - Quantile: 3.45 %\ncat(\"Mean CV - VSN:\", round(calculate_mean_cv(protein_matrix_vsn), 2), \"%\\n\")\n#> Mean CV - VSN: 1.14 %\n\n# Sample correlations\ncor_raw <- mean(cor(protein_matrix_imputed)[upper.tri(cor(protein_matrix_imputed))])\ncor_median <- mean(cor(protein_matrix_median)[upper.tri(cor(protein_matrix_median))])\ncor_quantile <- mean(cor(protein_matrix_quantile)[upper.tri(cor(protein_matrix_quantile))])\n\ncat(\"\\nMean sample correlation - Raw:\", round(cor_raw, 3), \"\\n\")\n#> \n#> Mean sample correlation - Raw: 0.36\ncat(\"Mean sample correlation - Median:\", round(cor_median, 3), \"\\n\")\n#> Mean sample correlation - Median: 0.36\ncat(\"Mean sample correlation - Quantile:\", round(cor_quantile, 3), \"\\n\")\n#> Mean sample correlation - Quantile: 0.359"},{"path":"day3.html","id":"day3-mod2","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.3 Module 2: Batch Effect Correction","text":"","code":""},{"path":"day3.html","id":"detecting-batch-effects","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.3.1 Detecting Batch Effects","text":"","code":"\n# PCA colored by batch\npca_result <- prcomp(t(protein_matrix_quantile), scale. = TRUE)\nvar_exp <- summary(pca_result)$importance[2, 1:2] * 100\n\npca_df <- data.frame(\n  PC1 = pca_result$x[, 1],\n  PC2 = pca_result$x[, 2],\n  sample_id = colnames(protein_matrix_quantile)\n)\npca_df <- merge(pca_df, sample_metadata, by = \"sample_id\")\n\n# Plot by batch\np_batch <- ggplot(pca_df, aes(x = PC1, y = PC2, color = batch, shape = condition)) +\n  geom_point(size = 4) +\n  theme_minimal() +\n  labs(title = \"PCA - Batch Effect Visible\",\n       x = paste0(\"PC1 (\", round(var_exp[1], 1), \"%)\"),\n       y = paste0(\"PC2 (\", round(var_exp[2], 1), \"%)\")) +\n  scale_color_manual(values = c(\"Batch1\" = \"red\", \"Batch2\" = \"blue\"))\n\nprint(p_batch)"},{"path":"day3.html","id":"combat-batch-correction","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.3.2 ComBat Batch Correction","text":"","code":"\n# Prepare for ComBat\nbatch_vector <- sample_metadata$batch\ncondition_matrix <- model.matrix(~condition, data = sample_metadata)\n\n# Apply ComBat\nprotein_matrix_combat <- sva::ComBat(\n  dat = protein_matrix_quantile,\n  batch = batch_vector,\n  mod = condition_matrix,\n  par.prior = TRUE,\n  prior.plots = FALSE\n)\n#> Found 1 genes with uniform expression within a single batch (all zeros); these will not be adjusted for batch.\n\n# Compare before and after\npca_combat <- prcomp(t(protein_matrix_combat), scale. = TRUE)\nvar_exp_combat <- summary(pca_combat)$importance[2, 1:2] * 100\n\npca_df_combat <- data.frame(\n  PC1 = pca_combat$x[, 1],\n  PC2 = pca_combat$x[, 2],\n  sample_id = colnames(protein_matrix_combat)\n)\npca_df_combat <- merge(pca_df_combat, sample_metadata, by = \"sample_id\")\n\np_combat <- ggplot(pca_df_combat, aes(x = PC1, y = PC2, color = batch, shape = condition)) +\n  geom_point(size = 4) +\n  theme_minimal() +\n  labs(title = \"PCA - After ComBat Correction\",\n       x = paste0(\"PC1 (\", round(var_exp_combat[1], 1), \"%)\"),\n       y = paste0(\"PC2 (\", round(var_exp_combat[2], 1), \"%)\")) +\n  scale_color_manual(values = c(\"Batch1\" = \"red\", \"Batch2\" = \"blue\"))\n\nlibrary(gridExtra)\ngrid.arrange(p_batch, p_combat, ncol = 2)"},{"path":"day3.html","id":"scaling-methods","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.3.3 Scaling Methods","text":"","code":"\n# Z-score scaling (by protein)\nprotein_matrix_scaled <- t(scale(t(protein_matrix_combat)))\n\n# Pareto scaling\nprotein_matrix_pareto <- t(scale(t(protein_matrix_combat))) / sqrt(apply(protein_matrix_combat, 1, sd, na.rm = TRUE))\n\nrownames(sample_metadata) <- sample_metadata$sample_id\n\n# Visualize effect of scaling\npheatmap(protein_matrix_combat[1:1000, ],\n         scale = \"row\",\n         main = \"Heatmap with Row Scaling\",\n         show_rownames = FALSE,\n         annotation_col = sample_metadata[, c(\"condition\", \"batch\"), drop = FALSE])"},{"path":"day3.html","id":"exercise-3.2-complete-preprocessing-pipeline","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.3.4 Exercise 3.2: Complete Preprocessing Pipeline","text":"Create complete preprocessing function :Filters proteins >30% missingImputes missing valuesApplies normalizationCorrects batch effects","code":"\n# Solution\npreprocess_proteomics <- function(raw_data, metadata, \n                                   missing_threshold = 0.3,\n                                   norm_method = \"quantile\",\n                                  batch_correction = TRUE) {\n  # Step 1: Filter\n  missing_per_protein <- rowSums(is.na(raw_data)) / ncol(raw_data)\n  filtered_data <- raw_data[missing_per_protein <= missing_threshold, ]\n  cat(\"Filtered to\", nrow(filtered_data), \"proteins\\n\")\n  \n  # Step 2: Impute\n  impute_method = \"min\"\n  data_imputed <- filtered_data\n  for (i in 1:nrow(data_imputed)) {\n    row_vals <- data_imputed[i, ]\n    \n    if (any(is.na(row_vals))) {\n      if (impute_method == \"min\") {\n        # Impute with minimum value per protein (common in proteomics)\n        impute_val <- min(row_vals, na.rm = TRUE) - 0.5  # Slightly below minimum\n      } else if (impute_method == \"mean\") {\n        # Mean imputation\n        impute_val <- mean(row_vals, na.rm = TRUE)\n      } else if (impute_method == \"knn\") {\n        # Simple k-NN approximation (using row mean as proxy)\n        impute_val <- mean(row_vals, na.rm = TRUE)\n      }\n      \n      data_imputed[i, is.na(row_vals)] <- impute_val\n    }\n  }\n  cat(\"Imputed\", sum(is.na(filtered_data)), \"missing values\\n\")\n  \n  # Step 3: Normalize\n  if (norm_method == \"quantile\") {\n    normalized_data <- limma::normalizeBetweenArrays(data_imputed, method = \"quantile\")\n  } else if (norm_method == \"median\") {\n    sample_medians <- apply(data_imputed, 2, median)\n    global_median <- median(sample_medians)\n    normalized_data <- sweep(imputed_data, 2, sample_medians - global_median)\n  }\n  cat(\"Applied\", norm_method, \"normalization\\n\")\n  \n  # Step 4: Batch correction\n  if (batch_correction && \"batch\" %in% colnames(metadata)) {\n    condition_matrix <- model.matrix(~condition, data = metadata)\n    corrected_data <- sva::ComBat(\n      dat = normalized_data,\n      batch = metadata$batch,\n      mod = condition_matrix,\n      par.prior = TRUE,\n      prior.plots = FALSE\n    )\n    cat(\"Applied ComBat batch correction\\n\")\n  } else {\n    corrected_data <- normalized_data\n  }\n  \n  return(corrected_data)\n}\n\n# Apply pipeline\nprocessed_data <- preprocess_proteomics(protein_matrix, sample_metadata)\n#> Filtered to 1383 proteins\n#> Imputed 4014 missing values\n#> Applied quantile normalization\n#> Found 1 genes with uniform expression within a single batch (all zeros); these will not be adjusted for batch.\n#> Applied ComBat batch correction"},{"path":"day3.html","id":"day3-mod3","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.4 Module 3: Differential Expression Analysis","text":"","code":""},{"path":"day3.html","id":"introduction-to-limma","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.4.1 Introduction to limma","text":"limma (Linear Models Microarray Data) widely used differential expression.Key advantages:\n- Empirical Bayes moderation\n- Handles complex designs\n- Works well small sample sizes","code":""},{"path":"day3.html","id":"basic-differential-expression","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.4.2 Basic Differential Expression","text":"","code":"\n# Design matrix\ndesign <- model.matrix(~0 + condition, data = sample_metadata)\ncolnames(design) <- c(\"Control\", \"Treatment\")\n\n# Fit linear model\nfit <- lmFit(processed_data, design)\n\n# Define contrast\ncontrast_matrix <- makeContrasts(\n  TreatmentVsControl = Treatment - Control,\n  levels = design\n)\n\n# Fit contrasts\nfit2 <- contrasts.fit(fit, contrast_matrix)\n\n# Empirical Bayes moderation\nfit2 <- eBayes(fit2)\n\n# Extract results\nde_results <- topTable(fit2, coef = \"TreatmentVsControl\", number = Inf)\n\n# Add protein IDs and annotations\nde_results$protein_id <- rownames(de_results)\nde_results_annotated <- de_results %>%\n  left_join(protein_annotations, by = \"protein_id\")\n\n# View top results\ncat(\"\\nTop 10 differentially expressed proteins:\\n\")\n#> \n#> Top 10 differentially expressed proteins:\nprint(de_results_annotated[1:10, c(\"protein_id\", \"gene_symbol\", \"logFC\", \"P.Value\", \"adj.P.Val\")])\n#>    protein_id gene_symbol     logFC      P.Value\n#> 1      P01172         MYC -3.259075 3.102431e-18\n#> 2      P00804       MAPK1 -2.617582 8.924126e-17\n#> 3      P00857        AKT1 -3.173146 7.084863e-15\n#> 4      P00825         APC -1.749628 1.493181e-12\n#> 5      P00438         KIT  2.229704 3.682046e-12\n#> 6      P01138         FAS -1.700512 5.270544e-12\n#> 7      P00043        EGFR -2.335420 3.513380e-11\n#> 8      P01176        MTOR -2.235232 3.607181e-11\n#> 9      P00421       CCND1  2.496499 1.739572e-10\n#> 10     P01322        KRAS  1.387225 2.164925e-10\n#>       adj.P.Val\n#> 1  4.290661e-15\n#> 2  6.171033e-14\n#> 3  3.266122e-12\n#> 4  5.162673e-10\n#> 5  1.018454e-09\n#> 6  1.214860e-09\n#> 7  6.235913e-09\n#> 8  6.235913e-09\n#> 9  2.673143e-08\n#> 10 2.994091e-08\n\n# Summary\ncat(\"\\nDifferential Expression Summary:\\n\")\n#> \n#> Differential Expression Summary:\ncat(\"Significant proteins (FDR < 0.05):\", sum(de_results$adj.P.Val < 0.05), \"\\n\")\n#> Significant proteins (FDR < 0.05): 227\ncat(\"Upregulated (FC > 1.5, FDR < 0.05):\", \n    sum(de_results$adj.P.Val < 0.05 & de_results$logFC > log2(1.5)), \"\\n\")\n#> Upregulated (FC > 1.5, FDR < 0.05): 107\ncat(\"Downregulated (FC < -1.5, FDR < 0.05):\", \n    sum(de_results$adj.P.Val < 0.05 & de_results$logFC < -log2(1.5)), \"\\n\")\n#> Downregulated (FC < -1.5, FDR < 0.05): 109"},{"path":"day3.html","id":"volcano-plot","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.4.3 Volcano Plot","text":"","code":"\n# Prepare data for volcano plot\nvolcano_data <- de_results\nvolcano_data$significance <- \"NS\"\nvolcano_data$significance[volcano_data$adj.P.Val < 0.05 & volcano_data$logFC > log2(1.5)] <- \"Up\"\nvolcano_data$significance[volcano_data$adj.P.Val < 0.05 & volcano_data$logFC < -log2(1.5)] <- \"Down\"\n\n# Volcano plot\nggplot(volcano_data, aes(x = logFC, y = -log10(adj.P.Val), color = significance)) +\n  geom_point(alpha = 0.6, size = 2) +\n  scale_color_manual(values = c(\"Up\" = \"red\", \"Down\" = \"blue\", \"NS\" = \"grey\")) +\n  geom_hline(yintercept = -log10(0.05), linetype = \"dashed\") +\n  geom_vline(xintercept = c(-log2(1.5), log2(1.5)), linetype = \"dashed\") +\n  theme_minimal() +\n  labs(title = \"Volcano Plot: Treatment vs Control\",\n       x = \"log2 Fold Change\",\n       y = \"-log10 Adjusted P-value\") +\n  theme(legend.title = element_blank())"},{"path":"day3.html","id":"ma-plot","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.4.4 MA Plot","text":"","code":"\n# MA plot\nvolcano_data$AveExpr <- de_results$AveExpr\n\nggplot(volcano_data, aes(x = AveExpr, y = logFC, color = significance)) +\n  geom_point(alpha = 0.6, size = 2) +\n  scale_color_manual(values = c(\"Up\" = \"red\", \"Down\" = \"blue\", \"NS\" = \"grey\")) +\n  geom_hline(yintercept = 0, linetype = \"solid\") +\n  geom_hline(yintercept = c(-log2(1.5), log2(1.5)), linetype = \"dashed\") +\n  theme_minimal() +\n  labs(title = \"MA Plot: Treatment vs Control\",\n       x = \"Average Expression\",\n       y = \"log2 Fold Change\") +\n  theme(legend.title = element_blank())"},{"path":"day3.html","id":"heatmap-of-de-proteins","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.4.5 Heatmap of DE Proteins","text":"","code":"\n# Select significant proteins\nsig_proteins <- rownames(de_results[de_results$adj.P.Val < 0.05, ])\n\nannotation_col <- as.data.frame(sample_metadata[, c(\"condition\")])\ncolnames(annotation_col) <- \"Condition\"\nrownames(annotation_col) <- sample_metadata$sample_id\n\n# Plot heatmap if there are significant proteins\nif (length(sig_proteins) > 1) {\n  pheatmap(processed_data[sig_proteins, ],\n           scale = \"row\",\n           clustering_distance_rows = \"correlation\",\n           clustering_distance_cols = \"euclidean\",\n           annotation_col = annotation_col, \n           show_rownames = FALSE,\n           show_colnames = TRUE,\n           fontsize_col = 10, \n           main = \"Heatmap of Significantly Differentially Expressed Proteins\")\n} else {\n  cat(\"Not enough significant proteins to generate a heatmap.\\n\")\n}"},{"path":"day3.html","id":"save-results-for-day-4","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.4.6 Save Results for Day 4","text":"","code":"\n# Create results directory\nif (!dir.exists(\"results\")) {\n    dir.create(\"results\")\n}\n\n# Save processed data and results\nsaveRDS(processed_data, \"results/day3_processed_data.rds\")\nsaveRDS(de_results_annotated, \"results/day3_de_results.rds\")\n\n# Also save a summary table\nde_summary <- de_results_annotated %>%\n    filter(adj.P.Val < 0.05) %>%\n    dplyr::select(protein_id, gene_symbol, logFC, P.Value, adj.P.Val, protein_name)\n\nwrite.csv(de_summary, \"results/day3_significant_proteins.csv\", row.names = FALSE)\n\ncat(\"\\nResults saved for Day 4:\\n\")\n#> \n#> Results saved for Day 4:\ncat(\"- Processed data: results/day3_processed_data.rds\\n\")\n#> - Processed data: results/day3_processed_data.rds\ncat(\"- DE results: results/day3_de_results.rds\\n\")\n#> - DE results: results/day3_de_results.rds\ncat(\"- Significant proteins: results/day3_significant_proteins.csv\\n\")\n#> - Significant proteins: results/day3_significant_proteins.csv"},{"path":"day3.html","id":"day-3-summary","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.5 Day 3 Summary","text":"Today learned:✓ handle missing values proteomic data✓ Different normalization methods effects✓ Batch effect detection correction using ComBat✓ Differential expression analysis limma✓ Visualization DE results (volcano plots, MA plots, heatmaps)","code":""},{"path":"day3.html","id":"key-takeaways-1","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.5.1 Key Takeaways","text":"Normalization crucial making samples comparableBatch correction can remove technical artifactslimma provides robust differential expression analysisVisualization helps interpret complex DE results","code":""},{"path":"day3.html","id":"homework-2","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.5.2 Homework","text":"Try different normalization methods compare resultsExperiment different FDR fold change thresholdsCreate custom visualizations specific research questions","code":"\n# Prepare for Day 4\ninstall.packages(c(\"clusterProfiler\", \"enrichplot\", \"org.Hs.eg.db\"))\n\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(c(\"clusterProfiler\", \"enrichplot\", \"org.Hs.eg.db\"))"},{"path":"day3.html","id":"additional-resources-2","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.6 Additional Resources","text":"limma User’s GuideComBat paperProteomics normalization review","code":""},{"path":"day4.html","id":"day4","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"Day - 4 Functional Analysis, Longitudinal & Public Data","text":"","code":""},{"path":"day4.html","id":"learning-objectives-3","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.1 Learning Objectives","text":"end Day 4, able :Perform functional enrichment analysis (GO, KEGG, Reactome)Conduct Gene Set Enrichment Analysis (GSEA)Analyze longitudinal proteomics dataDownload integrate public datasets GEO PRIDEUse online tools enhanced functional interpretation","code":""},{"path":"day4.html","id":"module-1-functional-enrichment-gsea","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.2 Module 1: Functional Enrichment & GSEA","text":"","code":""},{"path":"day4.html","id":"introduction-to-functional-analysis","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.2.1 Introduction to Functional Analysis","text":"Functional analysis helps interpret differential expression results\nbiological context identifying enriched pathways, processes,\nfunctions.Key Concepts:Gene Ontology (GO): Biological Process, Molecular Function, Cellular ComponentKEGG Pathways: Curated pathway databasesReactome: Expert-curated pathway databaseGSEA: Gene Set Enrichment Analysis (rank-based)","code":""},{"path":"day4.html","id":"preparing-de-results-for-functional-analysis","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.2.2 Preparing DE Results for Functional Analysis","text":"","code":"\n# Prepare significant DE results\nde_significant <- de_results %>%\n  filter(adj.P.Val < 0.05 & abs(logFC) > log2(1.5)) %>%\n  arrange(desc(abs(logFC)))\n\ncat(\"Significant DE proteins for functional analysis:\", nrow(de_significant), \"\\n\")\n#> Significant DE proteins for functional analysis: 216\n\n# Create gene list with statistics for GSEA\ngene_list <- de_results$logFC\nnames(gene_list) <- de_results$gene_symbol\ngene_list <- sort(gene_list, decreasing = TRUE)\n\n# Remove duplicates and NA values\ngene_list <- gene_list[!is.na(names(gene_list))]\ngene_list <- gene_list[!duplicated(names(gene_list))]\n\ncat(\"Unique genes for GSEA:\", length(gene_list), \"\\n\")\n#> Unique genes for GSEA: 30"},{"path":"day4.html","id":"gene-ontology-go-enrichment-analysis","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.2.3 Gene Ontology (GO) Enrichment Analysis","text":"","code":"\ncat(\"Starting GO enrichment analysis... This may take 1-2 minutes.\\n\")\n#> Starting GO enrichment analysis... This may take 1-2 minutes.\n\n# Over-representation analysis for significant genes\nsignificant_genes <- de_significant$gene_symbol\n\nif(length(significant_genes) >= 10) {\n  # GO Biological Process\n  ego_bp <- enrichGO(\n    gene = significant_genes,\n    OrgDb = org.Hs.eg.db,\n    keyType = \"SYMBOL\",\n    ont = \"BP\",\n    pvalueCutoff = 0.05,\n    qvalueCutoff = 0.05,\n    readable = TRUE\n  )\n  \n  # GO Molecular Function\n  ego_mf <- enrichGO(\n    gene = significant_genes,\n    OrgDb = org.Hs.eg.db,\n    keyType = \"SYMBOL\", \n    ont = \"MF\",\n    pvalueCutoff = 0.05,\n    qvalueCutoff = 0.05,\n    readable = TRUE\n  )\n  \n  # GO Cellular Component\n  ego_cc <- enrichGO(\n    gene = significant_genes,\n    OrgDb = org.Hs.eg.db,\n    keyType = \"SYMBOL\",\n    ont = \"CC\", \n    pvalueCutoff = 0.05,\n    qvalueCutoff = 0.05,\n    readable = TRUE\n  )\n  \n  cat(\"GO enrichment results:\\n\")\n  cat(\" - BP:\", nrow(ego_bp), \"terms\\n\")\n  cat(\" - MF:\", nrow(ego_mf), \"terms\\n\") \n  cat(\" - CC:\", nrow(ego_cc), \"terms\\n\")\n  \n} else {\n  cat(\"Warning: Too few significant genes for meaningful GO analysis\\n\")\n  ego_bp <- NULL\n  ego_mf <- NULL\n  ego_cc <- NULL\n}\n#> GO enrichment results:\n#>  - BP: 1833 terms\n#>  - MF: 54 terms\n#>  - CC: 49 terms"},{"path":"day4.html","id":"kegg-pathway-enrichment","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.2.4 KEGG Pathway Enrichment","text":"","code":"\ncat(\"Starting KEGG enrichment analysis... This may take 2-3 minutes.\\n\")\n#> Starting KEGG enrichment analysis... This may take 2-3 minutes.\n\nif(length(significant_genes) >= 10) {\n  # Convert gene symbols to Entrez IDs\n  gene_df <- bitr(significant_genes, fromType = \"SYMBOL\", \n                  toType = \"ENTREZID\", OrgDb = org.Hs.eg.db)\n  \n  # KEGG enrichment\n  kk <- enrichKEGG(\n    gene = gene_df$ENTREZID,\n    organism = 'hsa',\n    pvalueCutoff = 0.05,\n    qvalueCutoff = 0.05\n  )\n  \n  if(!is.null(kk) && nrow(kk) > 0) {\n    cat(\"KEGG enrichment:\", nrow(kk), \"pathways\\n\")\n    \n    # Simplify KEGG results for visualization\n    kk_simplified <- kk@result %>%\n      filter(p.adjust < 0.05) %>%\n      arrange(p.adjust) %>%\n      # Use a threshold to reduce terms based on fold enrichment, z-score, etc.\n      filter(FoldEnrichment > 10)\n    \n  } else {\n    cat(\"No significant KEGG pathways found\\n\")\n    kk <- NULL\n  }\n  \n} else {\n  cat(\"Too few genes for KEGG analysis\\n\")\n  kk <- NULL\n}\n#> KEGG enrichment: 154 pathways"},{"path":"day4.html","id":"visualization-of-enrichment-results","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.2.5 Visualization of Enrichment Results","text":"","code":"\n# Create enrichment plots\nif(exists(\"ego_bp\") && !is.null(ego_bp) && nrow(ego_bp) > 0) {\n  \n  # Dot plot for GO BP\n  p1 <- dotplot(ego_bp, showCategory = 15, font.size = 10) + \n    ggtitle(\"GO Biological Process Enrichment\")\n  \n  # Network plot\n  # Calculate pairwise similarity for the GO terms\n  ego_bp_sim <- pairwise_termsim(ego_bp)\n  p2 <- emapplot(ego_bp_sim, showCategory = 20) + \n      ggtitle(\"GO BP Network\")\n\n  # Ridge plot for gene distribution\n  #p3 <- ridgeplot(ego_bp) + \n  #  ggtitle(\"Gene Distribution in GO Terms\")\n  \n  # Display plots\n  print(p1)\n  print(p2)\n  #print(p3)\n}\nif(exists(\"kk\") && !is.null(kk) && nrow(kk) > 0) {\n  # KEGG dot plot\n  p4 <- dotplot(kk, showCategory = 15) + \n    ggtitle(\"KEGG Pathway Enrichment\")\n  print(p4)\n}"},{"path":"day4.html","id":"gene-set-enrichment-analysis-gsea","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.2.6 Gene Set Enrichment Analysis (GSEA)","text":"","code":"\ncat(\"Starting GSEA... This may take 3-5 minutes for large gene sets.\\n\")\n#> Starting GSEA... This may take 3-5 minutes for large gene sets.\n\nif(length(gene_list) >= 100) {\n  # GSEA for GO\n  gsea_go <- gseGO(\n    geneList = gene_list,\n    OrgDb = org.Hs.eg.db,\n    ont = \"BP\",\n    minGSSize = 10,\n    maxGSSize = 500,\n    pvalueCutoff = 0.05,\n    verbose = FALSE\n  )\n  \n  if(!is.null(gsea_go) && nrow(gsea_go) > 0) {\n    cat(\"GSEA GO results:\", nrow(gsea_go), \"gene sets\\n\")\n    \n    # GSEA plot for top enriched term\n    top_term <- gsea_go$Description[1]\n    p5 <- gseaplot2(gsea_go, geneSetID = 1, title = top_term)\n    print(p5)\n    \n  } else {\n    cat(\"No significant GSEA results\\n\")\n  }\n  \n} else {\n  cat(\"Insufficient genes for GSEA (need at least 100)\\n\")\n}\n#> Insufficient genes for GSEA (need at least 100)"},{"path":"day4.html","id":"online-tools-for-functional-analysis","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.2.7 Online Tools for Functional Analysis","text":"Recommended Online Tools:STRING Database (https://string-db.org/)\nProtein-protein interaction networks\nFunctional enrichment\nUsage: Upload gene list, get interactions pathways\nProtein-protein interaction networksFunctional enrichmentUsage: Upload gene list, get interactions pathwaysg:Profiler (https://biit.cs.ut.ee/gprofiler/)\nMulti-functional enrichment tool\nSupports GO, KEGG, Reactome, etc.\nUsage: Upload gene list, select databases\nMulti-functional enrichment toolSupports GO, KEGG, Reactome, etc.Usage: Upload gene list, select databasesEnrichr (https://maayanlab.cloud/Enrichr/)\nComprehensive enrichment analysis\nUser-friendly interface\nUsage: Paste gene list, run analysis\nComprehensive enrichment analysisUser-friendly interfaceUsage: Paste gene list, run analysis","code":"\n# Export gene list for online tools\nsignificant_gene_list <- de_significant$gene_symbol\n\n# Save for online tools\nwrite.table(significant_gene_list, \n            \"results/significant_genes_for_online_tools.txt\",\n            row.names = FALSE, col.names = FALSE, quote = FALSE)\n\ncat(\"Gene list saved for online tools: results/significant_genes_for_online_tools.txt\\n\")"},{"path":"day4.html","id":"exercise-4.1-functional-interpretation","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.2.8 Exercise 4.1: Functional Interpretation","text":"Run GO enrichment Molecular Function Cellular ComponentIdentify top 5 enriched pathwaysCompare results online tools (STRING/g:Profiler)Create biological interpretation report","code":"\n# Solution\ncat(\"=== FUNCTIONAL INTERPRETATION REPORT ===\\n\\n\")\n#> === FUNCTIONAL INTERPRETATION REPORT ===\n\nif (exists(\"ego_bp\") && nrow(ego_bp) > 0) {\n  cat(\"TOP BIOLOGICAL PROCESSES:\\n\")\n  top_bp <- head(ego_bp, 5)\n  for(i in 1:nrow(top_bp)) {\n    cat(i, \". \", top_bp$Description[i], \" (p.adj = \", \n        formatC(top_bp$p.adjust[i], format = \"e\", digits = 2), \")\\n\", sep = \"\")\n  }\n}\n#> TOP BIOLOGICAL PROCESSES:\n#> 1. gland development (p.adj = 3.00e-15)\n#> 2. epithelial cell proliferation (p.adj = 6.14e-15)\n#> 3. neuron apoptotic process (p.adj = 6.18e-13)\n#> 4. gliogenesis (p.adj = 2.07e-12)\n#> 5. negative regulation of cell development (p.adj = 4.97e-12)\n\nif (exists(\"kk\") && nrow(kk) > 0) {\n  cat(\"\\nTOP KEGG PATHWAYS:\\n\")\n  top_kegg <- head(kk, 5)\n  for(i in 1:nrow(top_kegg)) {\n    cat(i, \". \", top_kegg$Description[i], \" (p.adj = \", \n        formatC(top_kegg$p.adjust[i], format = \"e\", digits = 2), \")\\n\", sep = \"\")\n  }\n}\n#> \n#> TOP KEGG PATHWAYS:\n#> 1. Breast cancer (p.adj = 9.52e-28)\n#> 2. Endometrial cancer (p.adj = 3.12e-22)\n#> 3. Colorectal cancer (p.adj = 6.70e-22)\n#> 4. Hepatocellular carcinoma (p.adj = 4.12e-21)\n#> 5. Prostate cancer (p.adj = 9.62e-21)\n\n# Biological insights\ncat(\"\\nBIOLOGICAL INSIGHTS:\\n\")\n#> \n#> BIOLOGICAL INSIGHTS:\ncat(\"- Treatment appears to affect cellular processes related to [interpret based on top terms]\\n\")\n#> - Treatment appears to affect cellular processes related to [interpret based on top terms]\ncat(\"- Key pathways involved: [list key pathways]\\n\")\n#> - Key pathways involved: [list key pathways]\ncat(\"- Potential therapeutic targets: [suggest based on results]\\n\")\n#> - Potential therapeutic targets: [suggest based on results]"},{"path":"day4.html","id":"module-2-longitudinal-data-analysis","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.3 Module 2: Longitudinal Data Analysis","text":"","code":""},{"path":"day4.html","id":"working-with-longitudinal-proteomics-data","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.3.1 Working with Longitudinal Proteomics Data","text":"","code":"\n# Create longitudinal dataset from our course data\nlongitudinal_data <- protein_annotations %>%\n  dplyr::select(protein_id, gene_symbol) %>%\n  inner_join(\n    as.data.frame(processed_data) %>%\n      rownames_to_column(\"protein_id\") %>%\n      pivot_longer(cols = -protein_id, names_to = \"sample_id\", values_to = \"abundance\"),\n    by = \"protein_id\"\n  ) %>%\n  left_join(sample_metadata, by = \"sample_id\") %>%\n  mutate(\n    week = as.numeric(gsub(\"Week\", \"\", timepoint)),\n    patient_condition = paste0(\"P\", patient_id, \"_\", condition)\n  )\n\ncat(\"Longitudinal dataset created:\", nrow(longitudinal_data), \"measurements\\n\")\n#> Longitudinal dataset created: 33192 measurements"},{"path":"day4.html","id":"visualizing-protein-trajectories","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.3.2 Visualizing Protein Trajectories","text":"","code":"\n# Select top variable proteins for visualization\ntop_proteins <- de_significant %>%\n  arrange(desc(abs(logFC))) %>%\n  head(12) %>%\n  pull(gene_symbol)\n\n# Plot trajectories for top proteins\ntrajectory_plot <- longitudinal_data %>%\n  filter(gene_symbol %in% top_proteins) %>%\n  ggplot(aes(x = week, y = abundance, color = condition, group = patient_condition)) +\n  geom_line(alpha = 0.6) +\n  geom_point(size = 1) +\n  geom_smooth(aes(group = condition), method = \"lm\", se = TRUE, size = 1.5) +\n  facet_wrap(~ gene_symbol, scales = \"free_y\", ncol = 4) +\n  theme_minimal() +\n  labs(title = \"Protein Abundance Trajectories Over Time\",\n       x = \"Week\", y = \"Normalized Abundance\",\n       color = \"Condition\") +\n  scale_color_brewer(palette = \"Set1\")\n\nprint(trajectory_plot)"},{"path":"day4.html","id":"mixed-effects-modeling","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.3.3 Mixed Effects Modeling","text":"","code":"\ncat(\"Fitting mixed effects models... This may take 1-2 minutes.\\n\")\n#> Fitting mixed effects models... This may take 1-2 minutes.\n\n# Function to fit mixed model for a protein\nfit_mixed_model <- function(protein_data) {\n  tryCatch({\n    model <- lmer(abundance ~ condition * week + (1 + week | patient_id), \n                  data = protein_data)\n    return(model)\n  }, error = function(e) {\n    return(NULL)\n  })\n}\n\n# Fit models for top proteins\nmixed_model_results <- longitudinal_data %>%\n  filter(gene_symbol %in% head(top_proteins, 6)) %>%\n  group_by(gene_symbol) %>%\n  nest() %>%\n  mutate(\n    model = map(data, fit_mixed_model),\n    summary = map(model, ~if(!is.null(.)) summary(.) else NULL),\n    coefs = map(summary, ~if(!is.null(.)) coef(.) else NULL)\n  )\n\n# Display model results\nfor(i in 1:nrow(mixed_model_results)) {\n  gene <- mixed_model_results$gene_symbol[i]\n  if(!is.null(mixed_model_results$summary[[i]])) {\n    cat(\"\\nMixed model for\", gene, \":\\n\")\n    print(mixed_model_results$summary[[i]]$coefficients)\n  }\n}\n#> \n#> Mixed model for AKT1 :\n#>                              Estimate Std. Error\n#> (Intercept)             19.7086884617 0.07352461\n#> conditionTreatment      -0.0517629357 0.10397950\n#> week                    -0.0042315872 0.01423798\n#> conditionTreatment:week -0.0008073289 0.02013554\n#>                              t value\n#> (Intercept)             268.05566483\n#> conditionTreatment       -0.49781866\n#> week                     -0.29720419\n#> conditionTreatment:week  -0.04009472\n#> \n#> Mixed model for EGFR :\n#>                             Estimate Std. Error     t value\n#> (Intercept)             19.771017530 0.05798293 340.9799627\n#> conditionTreatment       0.068815718 0.08200025   0.8392135\n#> week                    -0.003050035 0.01122835  -0.2716371\n#> conditionTreatment:week  0.002105610 0.01587928   0.1326011\n#> \n#> Mixed model for MAPK1 :\n#>                             Estimate Std. Error     t value\n#> (Intercept)             19.683277753 0.06176267 318.6921407\n#> conditionTreatment       0.101465576 0.08734561   1.1616563\n#> week                     0.004952698 0.01196029   0.4140952\n#> conditionTreatment:week -0.003730085 0.01691440  -0.2205271\n#> \n#> Mixed model for TNF :\n#>                             Estimate Std. Error     t value\n#> (Intercept)             19.774558712 0.05801208 340.8696941\n#> conditionTreatment      -0.002040273 0.08204147  -0.0248688\n#> week                     0.005991395 0.01123399   0.5333275\n#> conditionTreatment:week -0.003955523 0.01588726  -0.2489745\n#> \n#> Mixed model for CCND1 :\n#>                             Estimate Std. Error     t value\n#> (Intercept)             19.779745531 0.05508533 359.0746586\n#> conditionTreatment       0.224313632 0.07784138   2.8816760\n#> week                     0.008165382 0.01071033   0.7623836\n#> conditionTreatment:week -0.012905287 0.01507392  -0.8561336\n#> \n#> Mixed model for MYC :\n#>                            Estimate Std. Error     t value\n#> (Intercept)             19.61741226 0.06252496 313.7533035\n#> conditionTreatment       0.01209204 0.08818899   0.1371151\n#> week                    -0.01373845 0.01232137  -1.1150095\n#> conditionTreatment:week  0.01950071 0.01707772   1.1418800"},{"path":"day4.html","id":"module-3-public-data-integration","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.4 Module 3: Public Data Integration","text":"","code":""},{"path":"day4.html","id":"downloading-data-from-geo","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.4.1 Downloading Data from GEO","text":"","code":"\ncat(\"ALERT: GEO downloads can take 5-15 minutes depending on dataset size and internet speed.\\n\")\n\n# Example: Download a real proteomics dataset from GEO\n# GSE12345 is a placeholder - replace with actual dataset ID\ngeo_accession <- \"GSE12345\"  # Replace with real dataset\n\n# Download dataset (commented out to avoid accidental downloads during rendering)\n# gse_data <- getGEO(geo_accession, destdir = \"data/geo/\")\n\n# Alternative: Use a pre-downloaded example dataset\ncat(\"Using simulated public dataset for demonstration...\\n\")"},{"path":"day4.html","id":"working-with-pride-proteomics-data","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.4.2 Working with PRIDE Proteomics Data","text":"","code":"\ncat(\"ALERT: PRIDE dataset processing can be computationally intensive and time-consuming.\\n\")\n\n# Example workflow for PRIDE data\n# 1. Download from https://www.ebi.ac.uk/pride/\n# 2. Use tools like MSstats or ProteomeDiscoverer for quantification\n# 3. Import results into R\n\n# Simulated PRIDE-like dataset for demonstration\ncreate_simulated_pride_data <- function() {\n  set.seed(123)\n  n_proteins <- 800\n  n_samples <- 16\n  \n  pride_data <- matrix(\n    rnorm(n_proteins * n_samples, mean = 20, sd = 2),\n    nrow = n_proteins,\n    ncol = n_samples\n  )\n  \n  colnames(pride_data) <- paste0(\"PRIDE_S\", 1:n_samples)\n  rownames(pride_data) <- paste0(\"P\", sprintf(\"%05d\", 1:n_proteins))\n  \n  return(pride_data)\n}\n\npride_matrix <- create_simulated_pride_data()"},{"path":"day4.html","id":"complete-public-data-analysis-pipeline","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.4.3 Complete Public Data Analysis Pipeline","text":"","code":"\n#[TO BE REVISED]\ncat(\"Running public data analysis pipeline...\\n\")\n\n# Simulate public dataset analysis\npublic_sample_metadata <- data.frame(\n  sample_id = paste0(\"PUBLIC_S\", 1:16),\n  condition = rep(c(\"Disease\", \"Healthy\"), each = 8),\n  batch = rep(1:4, each = 4),\n  age = sample(30:70, 16, replace = TRUE),\n  sex = sample(c(\"M\", \"F\"), 16, replace = TRUE)\n)\n\n# Run complete analysis pipeline on public data\npublic_de_results <- {\n  # Normalization\n  public_normalized <- normalizeBetweenArrays(pride_matrix, method = \"quantile\")\n  \n  # Batch correction\n  mod <- model.matrix(~ condition, data = public_sample_metadata)\n  public_corrected <- ComBat(public_normalized, \n                            batch = public_sample_metadata$batch, \n                            mod = mod)\n  \n  # Differential expression\n  design <- model.matrix(~ 0 + condition, data = public_sample_metadata)\n  colnames(design) <- c(\"Disease\", \"Healthy\")\n  fit <- lmFit(public_corrected, design)\n  contrast <- makeContrasts(DiseaseVsHealthy = Disease - Healthy, levels = design)\n  fit2 <- contrasts.fit(fit, contrast)\n  fit2 <- eBayes(fit2)\n  topTable(fit2, number = Inf)\n}\n\ncat(\"Public data analysis completed.\\n\")\ncat(\"Significant hits in public data:\", \n    sum(public_de_results$adj.P.Val < 0.05), \"\\n\")"},{"path":"day4.html","id":"cross-dataset-validation","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.4.4 Cross-Dataset Validation","text":"","code":"\n# Compare our results with public dataset (simulated overlap)\ncat(\"Cross-dataset validation...\\n\")\n#> Cross-dataset validation...\n\n# Create simulated overlap between datasets\ncommon_genes <- sample(protein_annotations$gene_symbol, 50)\n\nvalidation_results <- data.frame(\n  gene = common_genes,\n  our_study_logFC = rnorm(50, mean = 1, sd = 0.5),\n  public_data_logFC = rnorm(50, mean = 0.8, sd = 0.6),\n  correlation = runif(50, 0.3, 0.8)\n)\n\n# Plot correlation\nvalidation_plot <- ggplot(validation_results, aes(x = our_study_logFC, y = public_data_logFC)) +\n  geom_point(aes(color = correlation), size = 3) +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  theme_minimal() +\n  scale_color_viridis() +\n  labs(title = \"Cross-Dataset Validation\",\n       x = \"Our Study logFC\", \n       y = \"Public Data logFC\",\n       color = \"Correlation\") +\n  annotate(\"text\", x = min(validation_results$our_study_logFC), \n           y = max(validation_results$public_data_logFC),\n           label = paste(\"r =\", round(cor(validation_results$our_study_logFC, \n                                         validation_results$public_data_logFC), 3)))\n\nprint(validation_plot)"},{"path":"day4.html","id":"exercise-4.2-public-data-integration","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.4.5 Exercise 4.2: Public Data Integration","text":"Find relevant proteomics dataset GEO PRIDEDownload preprocess dataPerform differential expression analysisCompare results analysisIdentify conserved novel findings","code":"\n# Solution framework\ncat(\"=== PUBLIC DATA INTEGRATION WORKFLOW ===\\n\\n\")\n\ncat(\"1. DATA SOURCING:\\n\")\ncat(\"   - Visit https://www.ncbi.nlm.nih.gov/geo/\\n\")\ncat(\"   - Search for 'proteomics cancer' (or your disease of interest)\\n\")\ncat(\"   - Select dataset with appropriate sample size and conditions\\n\")\ncat(\"   - Download matrix and metadata files\\n\\n\")\n\ncat(\"2. DATA PROCESSING:\\n\")\ncat(\"   - Load expression matrix and sample metadata\\n\")\ncat(\"   - Perform quality control (similar to Day 2)\\n\")\ncat(\"   - Normalize and batch correct if needed\\n\")\ncat(\"   - Run differential expression analysis\\n\\n\")\n\ncat(\"3. COMPARATIVE ANALYSIS:\\n\")\ncat(\"   - Identify overlapping significant proteins\\n\")\ncat(\"   - Check direction consistency of fold changes\\n\")\ncat(\"   - Perform functional enrichment on conserved hits\\n\")\ncat(\"   - Report novel findings specific to your dataset\\n\")\n\n# Example code structure\n# public_data <- read.csv(\"downloaded_public_data.csv\")\n# public_metadata <- read.csv(\"public_sample_sheet.csv\")\n# ... analysis steps ..."},{"path":"day4.html","id":"online-resources-and-tools","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.5 Online Resources and Tools","text":"","code":""},{"path":"day4.html","id":"essential-online-platforms","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.5.1 Essential Online Platforms:","text":"GEO (Gene Expression Omnibus)\nURL: https://www.ncbi.nlm.nih.gov/geo/\nUsage: Search → Download → Analyze R\nURL: https://www.ncbi.nlm.nih.gov/geo/Usage: Search → Download → Analyze RPRIDE Proteomics Database\nURL: https://www.ebi.ac.uk/pride/\nUsage: Browse datasets → Download raw processed data\nURL: https://www.ebi.ac.uk/pride/Usage: Browse datasets → Download raw processed dataProteomicsDB\nURL: https://www.proteomicsdb.org/\nUsage: Query protein expression across tissues/cancers\nURL: https://www.proteomicsdb.org/Usage: Query protein expression across tissues/cancersCPTAC (Clinical Proteomic Tumor Analysis Consortium)\nURL: https://proteomics.cancer.gov/programs/cptac\nUsage: Download cancer proteomics datasets\nURL: https://proteomics.cancer.gov/programs/cptacUsage: Download cancer proteomics datasets","code":""},{"path":"day4.html","id":"r-packages-for-public-data","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.5.2 R Packages for Public Data:","text":"","code":"\n# Install additional packages for public data analysis\nBiocManager::install(c(\n  \"GEOquery\",      # Download GEO data\n  \"SRAdb\",         # Sequence Read Archive access\n  \"proteomics\",    # Proteomics data handling\n  \"MSnbase\"        # Mass spectrometry data\n))"},{"path":"day4.html","id":"day-4-summary","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.6 Day 4 Summary","text":"Today learned: - ✓ Functional enrichment analysis (GO, KEGG, GSEA) - ✓ Longitudinal data analysis mixed models - ✓ Public data integration GEO PRIDE - ✓ Online tools enhanced interpretation - ✓ Cross-dataset validation techniques","code":""},{"path":"day4.html","id":"key-takeaways-2","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.6.1 Key Takeaways","text":"Functional analysis provides biological context DE resultsLongitudinal models capture time-dependent changesPublic data enables validation discoveryOnline tools complement R-based analyses","code":""},{"path":"day4.html","id":"homework-3","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.6.2 Homework","text":"Perform functional analysis DE resultsDownload analyze public proteomics datasetCompare findings across multiple datasetsCreate comprehensive biological interpretation report","code":"\n# Save functional analysis results\nif(exists(\"ego_bp\")) saveRDS(ego_bp, \"results/day4_go_bp.rds\")\nif(exists(\"kk\")) saveRDS(kk, \"results/day4_kegg.rds\")\nif(exists(\"gsea_go\")) saveRDS(gsea_go, \"results/day4_gsea.rds\")\n\nsaveRDS(longitudinal_data, \"results/day4_longitudinal_data.rds\")\nsaveRDS(public_de_results, \"results/day4_public_de_results.rds\")\n\ncat(\"Day 4 results saved for Day 5 integration.\\n\")"},{"path":"day4.html","id":"additional-resources-3","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.7 Additional Resources","text":"clusterProfiler bookGEO tutorialPRIDE API documentationMixed models R ```","code":""},{"path":"day5.html","id":"day5","chapter":"Day - 5 Application on Real Data","heading":"Day - 5 Application on Real Data","text":"","code":""},{"path":"day5.html","id":"objectives","chapter":"Day - 5 Application on Real Data","heading":"5.1 Objectives","text":"Apply full workflow real internal datasetInterpret results biological contextTroubleshoot discuss","code":""},{"path":"day5.html","id":"modules","chapter":"Day - 5 Application on Real Data","heading":"5.2 Modules","text":"","code":""},{"path":"day5.html","id":"full-analysis-pipeline","chapter":"Day - 5 Application on Real Data","heading":"5.2.1 1. Full Analysis Pipeline","text":"QC → normalization → DE → functional → longitudinal (relevant).\nRun steps provided dataset (participants’ data).","code":""},{"path":"day5.html","id":"group-discussion-interpretation","chapter":"Day - 5 Application on Real Data","heading":"5.2.2 2. Group Discussion & Interpretation","text":"Interpret results, compare across participants, discuss limitations, challenges, possible variations.","code":""},{"path":"day5.html","id":"presentation-reporting","chapter":"Day - 5 Application on Real Data","heading":"5.2.3 3. Presentation & Reporting","text":"Generate basic report/graphics (ggplot2), integrate R Markdown / html / PDF.\nProvide guidance next steps.","code":""},{"path":"day5.html","id":"conclusion","chapter":"Day - 5 Application on Real Data","heading":"5.3 Conclusion","text":"Recap entire week.\nSuggest reading, resources, packages, courses.","code":""}]
