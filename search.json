[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"","code":""},{"path":"index.html","id":"about-this-course","chapter":"Welcome","heading":"About This Course","text":"recent years, mass spectrometry-based proteomics become essential tool life sciences, enabling quantitative, systems-level insights protein expression, post-translational modifications, cellular signaling dynamics. complexity volume proteomics data continue increase, demand robust, transparent, reproducible computational methods never greater.5-day intensive training course - r4proteomics - designed equip researchers, bioinformaticians, data scientists practical skills theoretical grounding necessary analyze proteomics data using R programming language Bioconductor ecosystem. combination guided tutorials, hands-exercises, real-world case studies, participants build fluency core statistical computational methods widely used proteomics research translational applications.curriculum begins foundational programming R progresses quality control, normalization, differential analysis proteomics data, culminating advanced topics functional enrichment, longitudinal modeling, integration public datasets.course ideal professionals seeking deepen expertise computational proteomics within pharmaceutical, biotechnology, academic research environments. Participants leave solid methodological framework also ready--use code templates workflows applicable projects.learn:Day 1: R fundamentals RStudio basicsDay 2: Understanding proteomic data quality controlDay 3: Data preprocessing differential expression analysisDay 4: Functional analysis, longitudinal studies, public datasetsDay 5: Real-world applications case studies","code":""},{"path":"index.html","id":"prerequisites","chapter":"Welcome","heading":"Prerequisites","text":"Basic computer literacyInterest biological data analysisNo prior R programming experience required","code":""},{"path":"index.html","id":"course-materials","chapter":"Welcome","heading":"Course Materials","text":"data files, scripts, additional resources available course repository.","code":""},{"path":"index.html","id":"how-to-use-this-book","chapter":"Welcome","heading":"How to Use This Book","text":"chapter corresponds one day training. Chapters include:Learning objectives: ’ll achieveTheory sections: Conceptual backgroundPractical exercises: Hands-codingCase studies: Real-world applications","code":""},{"path":"index.html","id":"installation-instructions","chapter":"Welcome","heading":"Installation Instructions","text":"starting Day 1, please ensure installed:","code":"\n# Install R (version >= 4.3.0) from https://cran.r-project.org/\n# Install RStudio from https://posit.co/download/rstudio-desktop/\n\n# Install required packages\ninstall.packages(c(\"tidyverse\", \"bookdown\", \"knitr\", \"rmarkdown\"))\n\n# Install Bioconductor packages\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(c(\n  \"limma\", \"vsn\", \"sva\", \"clusterProfiler\",\n  \"org.Hs.eg.db\", \"ReactomePA\", \"enrichplot\"\n))"},{"path":"index.html","id":"acknowledgments","chapter":"Welcome","heading":"Acknowledgments","text":"course developed provide hands-training proteomics data analysis.","code":""},{"path":"day1.html","id":"day1","chapter":"Day - 1 Introduction to R and RStudio","heading":"Day - 1 Introduction to R and RStudio","text":"","code":""},{"path":"day1.html","id":"learning-objectives","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.1 Learning Objectives","text":"end Day 1, able :Install navigate RStudio effectivelyUnderstand basic R data structures (vectors, data frames, lists)Import explore simple datasetsWrite basic control flow structures functions","code":""},{"path":"day1.html","id":"day1-mod1","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2 Module 1: Setting Up and Getting Started with R","text":"","code":""},{"path":"day1.html","id":"introduction","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.1 Introduction","text":"R powerful programming language environment specifically designed statistical computing graphics. RStudio integrated development environment (IDE) makes working R much easier.","code":""},{"path":"day1.html","id":"installing-r-and-rstudio","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.2 Installing R and RStudio","text":"Install R (version 4.3.0 higher)\nVisit https://cran.r-project.org/\nDownload version appropriate operating system\nRun installer\nVisit https://cran.r-project.org/Download version appropriate operating systemRun installerInstall RStudio Desktop\nVisit https://posit.co/download/rstudio-desktop/\nDownload free Desktop version\nRun installer\nVisit https://posit.co/download/rstudio-desktop/Download free Desktop versionRun installer","code":""},{"path":"day1.html","id":"rstudio-interface-tour","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.3 RStudio Interface Tour","text":"RStudio four main panes:Source Editor (top-left): write edit scriptsConsole (bottom-left): code executed results appearEnvironment/History (top-right): Shows objects memory command historyFiles/Plots/Packages/Help (bottom-right): File browser, plot viewer, package manager, help documentation","code":""},{"path":"day1.html","id":"scripts-vs-console","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.4 Scripts vs Console","text":"Console :\n- Quick calculations\n- Testing commands\n- Interactive explorationScripts (.R .Rmd files) :\n- Saving work\n- Creating reproducible analyses\n- Organizing complex workflows","code":""},{"path":"day1.html","id":"basic-operators","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.5 Basic Operators","text":"","code":"\n# Arithmetic operators\n5 + 3        # Addition\n#> [1] 8\n10 - 4       # Subtraction\n#> [1] 6\n6 * 7        # Multiplication\n#> [1] 42\n20 / 4       # Division\n#> [1] 5\n2 ^ 3        # Exponentiation\n#> [1] 8\n17 %% 5      # Modulo (remainder)\n#> [1] 2\n\n# Assignment operator\nx <- 10      # Assign 10 to x\ny = 5        # Alternative (but <- is preferred)\n\n# Comparison operators\n5 == 5       # Equal to\n#> [1] TRUE\n5 != 3       # Not equal to\n#> [1] TRUE\n7 > 3        # Greater than\n#> [1] TRUE\n4 < 8        # Less than\n#> [1] TRUE\n5 >= 5       # Greater than or equal\n#> [1] TRUE\n3 <= 10      # Less than or equal\n#> [1] TRUE\n\n# Logical operators\nTRUE & FALSE  # AND\n#> [1] FALSE\nTRUE | FALSE  # OR\n#> [1] TRUE\n!TRUE         # NOT\n#> [1] FALSE"},{"path":"day1.html","id":"creating-your-first-script","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.6 Creating Your First Script","text":"","code":"\n# Create a new R script: File > New File > R Script\n# Or use Ctrl+Shift+N (Windows/Linux) or Cmd+Shift+N (Mac)\n\n# Write your code\nmessage(\"Hello, Proteomics World!\")\n\n# Save your script: File > Save\n# Run code: Ctrl+Enter (Windows/Linux) or Cmd+Return (Mac)"},{"path":"day1.html","id":"exercise-1.1-first-steps","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.2.7 Exercise 1.1: First Steps","text":"Create new R script :Calculate sum 123 456Assign result variable called totalPrint value totalCalculate percentage 123 total","code":"\n# Solution\nresult1 <- 123 + 456\ntotal <- result1\nprint(total)\n#> [1] 579\n\npercentage <- (123 / total) * 100\nprint(paste0(\"123 is \", round(percentage, 2), \"% of the total\"))\n#> [1] \"123 is 21.24% of the total\""},{"path":"day1.html","id":"day1-mod2","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3 Module 2: Data Types and Structures","text":"","code":""},{"path":"day1.html","id":"vectors","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3.1 Vectors","text":"Vectors basic data structure R. contain elements type.","code":"\n# Numeric vectors\nages <- c(25, 30, 35, 40, 45)\nprint(ages)\n#> [1] 25 30 35 40 45\n\n# Character vectors\nnames <- c(\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Eve\")\nprint(names)\n#> [1] \"Alice\"   \"Bob\"     \"Charlie\" \"Diana\"   \"Eve\"\n\n# Logical vectors\npassed_qc <- c(TRUE, TRUE, FALSE, TRUE, TRUE)\nprint(passed_qc)\n#> [1]  TRUE  TRUE FALSE  TRUE  TRUE\n\n# Sequences\nseq_1_10 <- 1:10\nseq_custom <- seq(from = 0, to = 100, by = 10)"},{"path":"day1.html","id":"indexing-and-subsetting","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3.2 Indexing and Subsetting","text":"","code":"\n# Access elements by position (1-indexed!)\nages[1]           # First element\n#> [1] 25\nages[c(1, 3, 5)]  # Multiple elements\n#> [1] 25 35 45\nages[-2]          # All except second element\n#> [1] 25 35 40 45\n\n# Logical indexing\nages[ages > 35]   # Elements greater than 35\n#> [1] 40 45\n\n# Named vectors\nprotein_abundance <- c(ACTB = 1500, GAPDH = 2000, MYC = 800)\nprotein_abundance[\"ACTB\"]\n#> ACTB \n#> 1500"},{"path":"day1.html","id":"data-frames","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3.3 Data Frames","text":"Data frames common structure storing tabular data.","code":"\n# Create a data frame\npatient_data <- data.frame(\n  patient_id = 1:5,\n  name = c(\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Eve\"),\n  age = c(25, 30, 35, 40, 45),\n  treatment = c(\"A\", \"B\", \"A\", \"B\", \"A\"),\n  response = c(TRUE, TRUE, FALSE, TRUE, FALSE),\n  stringsAsFactors = FALSE\n)\n\nprint(patient_data)\n#>   patient_id    name age treatment response\n#> 1          1   Alice  25         A     TRUE\n#> 2          2     Bob  30         B     TRUE\n#> 3          3 Charlie  35         A    FALSE\n#> 4          4   Diana  40         B     TRUE\n#> 5          5     Eve  45         A    FALSE\n\n# View structure\nstr(patient_data)\n#> 'data.frame':    5 obs. of  5 variables:\n#>  $ patient_id: int  1 2 3 4 5\n#>  $ name      : chr  \"Alice\" \"Bob\" \"Charlie\" \"Diana\" ...\n#>  $ age       : num  25 30 35 40 45\n#>  $ treatment : chr  \"A\" \"B\" \"A\" \"B\" ...\n#>  $ response  : logi  TRUE TRUE FALSE TRUE FALSE\n\n# Summary statistics\nsummary(patient_data)\n#>    patient_id     name                age    \n#>  Min.   :1    Length:5           Min.   :25  \n#>  1st Qu.:2    Class :character   1st Qu.:30  \n#>  Median :3    Mode  :character   Median :35  \n#>  Mean   :3                       Mean   :35  \n#>  3rd Qu.:4                       3rd Qu.:40  \n#>  Max.   :5                       Max.   :45  \n#>   treatment          response      \n#>  Length:5           Mode :logical  \n#>  Class :character   FALSE:2        \n#>  Mode  :character   TRUE :3        \n#>                                    \n#>                                    \n#> \n\n# Access columns\npatient_data$age\n#> [1] 25 30 35 40 45\npatient_data[, \"name\"]\n#> [1] \"Alice\"   \"Bob\"     \"Charlie\" \"Diana\"   \"Eve\"\npatient_data[, 2]\n#> [1] \"Alice\"   \"Bob\"     \"Charlie\" \"Diana\"   \"Eve\"\n\n# Access rows\npatient_data[1, ]           # First row\n#>   patient_id  name age treatment response\n#> 1          1 Alice  25         A     TRUE\npatient_data[1:3, ]         # First three rows\n#>   patient_id    name age treatment response\n#> 1          1   Alice  25         A     TRUE\n#> 2          2     Bob  30         B     TRUE\n#> 3          3 Charlie  35         A    FALSE\n\n# Access specific cells\npatient_data[2, 3]          # Row 2, Column 3\n#> [1] 30\npatient_data[2, \"age\"]      # Same, using column name\n#> [1] 30\n\n# Subset by condition\npatient_data[patient_data$age > 30, ]\n#>   patient_id    name age treatment response\n#> 3          3 Charlie  35         A    FALSE\n#> 4          4   Diana  40         B     TRUE\n#> 5          5     Eve  45         A    FALSE\npatient_data[patient_data$treatment == \"A\", ]\n#>   patient_id    name age treatment response\n#> 1          1   Alice  25         A     TRUE\n#> 3          3 Charlie  35         A    FALSE\n#> 5          5     Eve  45         A    FALSE"},{"path":"day1.html","id":"lists","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3.4 Lists","text":"Lists can contain elements different types structures.","code":"\n# Create a list\nexperiment <- list(\n  experiment_id = \"EXP001\",\n  date = \"2025-01-15\",\n  samples = c(\"S1\", \"S2\", \"S3\"),\n  data = patient_data,\n  validated = TRUE\n)\n\n# Access list elements\nexperiment$experiment_id\n#> [1] \"EXP001\"\nexperiment[[1]]\n#> [1] \"EXP001\"\nexperiment[[\"samples\"]]\n#> [1] \"S1\" \"S2\" \"S3\""},{"path":"day1.html","id":"factors","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3.5 Factors","text":"Factors used categorical data.","code":"\n# Create factor\ntreatment_factor <- factor(c(\"Control\", \"Drug A\", \"Drug B\", \"Control\", \"Drug A\"))\nprint(treatment_factor)\n#> [1] Control Drug A  Drug B  Control Drug A \n#> Levels: Control Drug A Drug B\n\n# Check levels\nlevels(treatment_factor)\n#> [1] \"Control\" \"Drug A\"  \"Drug B\"\n\n# Ordered factors\nseverity <- factor(\n  c(\"Mild\", \"Severe\", \"Moderate\", \"Mild\", \"Severe\"),\n  levels = c(\"Mild\", \"Moderate\", \"Severe\"),\n  ordered = TRUE\n)\nprint(severity)\n#> [1] Mild     Severe   Moderate Mild     Severe  \n#> Levels: Mild < Moderate < Severe"},{"path":"day1.html","id":"type-coercion","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3.6 Type Coercion","text":"","code":"\n# Implicit coercion\nmixed <- c(1, 2, \"three\", 4)  # All converted to character\nprint(mixed)\n#> [1] \"1\"     \"2\"     \"three\" \"4\"\n\n# Explicit coercion\nnumbers_char <- c(\"1\", \"2\", \"3\", \"4\")\nnumbers_num <- as.numeric(numbers_char)\nprint(numbers_num)\n#> [1] 1 2 3 4\n\n# Check types\nclass(mixed)\n#> [1] \"character\"\nis.numeric(mixed)\n#> [1] FALSE\nis.character(mixed)\n#> [1] TRUE"},{"path":"day1.html","id":"exercise-1.2-data-structures","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.3.7 Exercise 1.2: Data Structures","text":"Create data frame proteomic experiment :10 protein IDs (P001 P010)Random abundance values 100 5000Random p-values 0 1Significance status (TRUE p-value < 0.05)","code":"\n# Solution\nset.seed(42)  # For reproducibility\n\nproteins <- data.frame(\n  protein_id = paste0(\"P\", sprintf(\"%03d\", 1:10)),\n  abundance = round(runif(10, min = 100, max = 5000), 2),\n  p_value = runif(10, min = 0, max = 1),\n  stringsAsFactors = FALSE\n)\n\nproteins$significant <- proteins$p_value < 0.05\n\nprint(proteins)\n#>    protein_id abundance   p_value significant\n#> 1        P001   4582.55 0.4577418       FALSE\n#> 2        P002   4691.67 0.7191123       FALSE\n#> 3        P003   1502.08 0.9346722       FALSE\n#> 4        P004   4169.19 0.2554288       FALSE\n#> 5        P005   3244.55 0.4622928       FALSE\n#> 6        P006   2643.57 0.9400145       FALSE\n#> 7        P007   3709.28 0.9782264       FALSE\n#> 8        P008    759.87 0.1174874       FALSE\n#> 9        P009   3319.26 0.4749971       FALSE\n#> 10       P010   3554.82 0.5603327       FALSE\n\n# Summary\ncat(\"\\nNumber of significant proteins:\", sum(proteins$significant), \"\\n\")\n#> \n#> Number of significant proteins: 0"},{"path":"day1.html","id":"day1-mod3","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.4 Module 3: Control Flow and Functions","text":"","code":""},{"path":"day1.html","id":"conditional-statements","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.4.1 Conditional Statements","text":"","code":"\n# if statement\nx <- 10\n\nif (x > 5) {\n  print(\"x is greater than 5\")\n}\n#> [1] \"x is greater than 5\"\n\n# if-else\nif (x > 15) {\n  print(\"x is greater than 15\")\n} else {\n  print(\"x is 15 or less\")\n}\n#> [1] \"x is 15 or less\"\n\n# if-else if-else\nscore <- 75\n\nif (score >= 90) {\n  grade <- \"A\"\n} else if (score >= 80) {\n  grade <- \"B\"\n} else if (score >= 70) {\n  grade <- \"C\"\n} else {\n  grade <- \"F\"\n}\n\nprint(paste(\"Grade:\", grade))\n#> [1] \"Grade: C\"\n\n# Vectorized ifelse\nvalues <- c(1, 5, 10, 15, 20)\ncategories <- ifelse(values > 10, \"High\", \"Low\")\nprint(categories)\n#> [1] \"Low\"  \"Low\"  \"Low\"  \"High\" \"High\""},{"path":"day1.html","id":"loops","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.4.2 Loops","text":"","code":"\n# for loop\nfor (i in 1:5) {\n  print(paste(\"Iteration:\", i))\n}\n#> [1] \"Iteration: 1\"\n#> [1] \"Iteration: 2\"\n#> [1] \"Iteration: 3\"\n#> [1] \"Iteration: 4\"\n#> [1] \"Iteration: 5\"\n\n# Loop through vector\nproteins <- c(\"ACTB\", \"GAPDH\", \"MYC\")\nfor (protein in proteins) {\n  print(paste(\"Processing:\", protein))\n}\n#> [1] \"Processing: ACTB\"\n#> [1] \"Processing: GAPDH\"\n#> [1] \"Processing: MYC\"\n\n# while loop\ncounter <- 1\nwhile (counter <= 5) {\n  print(paste(\"Counter:\", counter))\n  counter <- counter + 1\n}\n#> [1] \"Counter: 1\"\n#> [1] \"Counter: 2\"\n#> [1] \"Counter: 3\"\n#> [1] \"Counter: 4\"\n#> [1] \"Counter: 5\"\n\n# Loop with condition\nnumbers <- 1:10\nfor (num in numbers) {\n  if (num %% 2 == 0) {\n    print(paste(num, \"is even\"))\n  }\n}\n#> [1] \"2 is even\"\n#> [1] \"4 is even\"\n#> [1] \"6 is even\"\n#> [1] \"8 is even\"\n#> [1] \"10 is even\""},{"path":"day1.html","id":"functions","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.4.3 Functions","text":"","code":"\n# Basic function\ngreet <- function(name) {\n  message <- paste(\"Hello,\", name, \"!\")\n  return(message)\n}\n\ngreet(\"Alice\")\n#> [1] \"Hello, Alice !\"\n\n# Function with multiple parameters\ncalculate_fold_change <- function(treatment, control) {\n  fc <- treatment / control\n  log2_fc <- log2(fc)\n  return(log2_fc)\n}\n\ncalculate_fold_change(treatment = 200, control = 100)\n#> [1] 1\n\n# Function with default parameters\nnormalize_abundance <- function(abundance, method = \"median\") {\n  if (method == \"median\") {\n    normalized <- abundance / median(abundance, na.rm = TRUE)\n  } else if (method == \"mean\") {\n    normalized <- abundance / mean(abundance, na.rm = TRUE)\n  } else {\n    stop(\"Method must be 'median' or 'mean'\")\n  }\n  return(normalized)\n}\n\nvalues <- c(100, 200, 300, 400, 500)\nnormalize_abundance(values)\n#> [1] 0.3333333 0.6666667 1.0000000 1.3333333 1.6666667\nnormalize_abundance(values, method = \"mean\")\n#> [1] 0.3333333 0.6666667 1.0000000 1.3333333 1.6666667"},{"path":"day1.html","id":"apply-family-functions","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.4.4 Apply Family Functions","text":"","code":"\n# Create sample data\nprotein_matrix <- matrix(\n  c(100, 150, 200, 250, \n    110, 160, 210, 260,\n    120, 170, 220, 270),\n  nrow = 3, byrow = TRUE\n)\ncolnames(protein_matrix) <- c(\"Sample1\", \"Sample2\", \"Sample3\", \"Sample4\")\nrownames(protein_matrix) <- c(\"Protein1\", \"Protein2\", \"Protein3\")\n\nprint(protein_matrix)\n#>          Sample1 Sample2 Sample3 Sample4\n#> Protein1     100     150     200     250\n#> Protein2     110     160     210     260\n#> Protein3     120     170     220     270\n\n# apply: apply function to rows or columns\nrow_means <- apply(protein_matrix, 1, mean)  # 1 = rows\ncol_means <- apply(protein_matrix, 2, mean)  # 2 = columns\n\nprint(row_means)\n#> Protein1 Protein2 Protein3 \n#>      175      185      195\nprint(col_means)\n#> Sample1 Sample2 Sample3 Sample4 \n#>     110     160     210     260\n\n# lapply: apply function to list, returns list\nmy_list <- list(a = 1:5, b = 6:10, c = 11:15)\nlist_means <- lapply(my_list, mean)\nprint(list_means)\n#> $a\n#> [1] 3\n#> \n#> $b\n#> [1] 8\n#> \n#> $c\n#> [1] 13\n\n# sapply: simplified version of lapply\nvector_means <- sapply(my_list, mean)\nprint(vector_means)\n#>  a  b  c \n#>  3  8 13"},{"path":"day1.html","id":"exercise-1.3-functions-and-loops","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.4.5 Exercise 1.3: Functions and Loops","text":"Write function :Takes vector protein abundancesCalculates coefficient variation (CV = sd/mean * 100)Returns “Pass” CV < 20%, “Fail” otherwiseApply function multiple samples using loop.","code":"\n# Solution\ncalculate_cv_status <- function(abundances) {\n  cv <- (sd(abundances, na.rm = TRUE) / mean(abundances, na.rm = TRUE)) * 100\n  \n  if (cv < 20) {\n    status <- \"Pass\"\n  } else {\n    status <- \"Fail\"\n  }\n  \n  return(list(cv = round(cv, 2), status = status))\n}\n\n# Create sample data\nsample_data <- list(\n  sample1 = c(100, 105, 98, 102, 99),\n  sample2 = c(100, 150, 90, 200, 80),\n  sample3 = c(500, 505, 498, 502, 496)\n)\n\n# Apply function\nfor (sample_name in names(sample_data)) {\n  result <- calculate_cv_status(sample_data[[sample_name]])\n  cat(sample_name, \"- CV:\", result$cv, \"% - Status:\", result$status, \"\\n\")\n}\n#> sample1 - CV: 2.75 % - Status: Pass \n#> sample2 - CV: 40.56 % - Status: Fail \n#> sample3 - CV: 0.7 % - Status: Pass"},{"path":"day1.html","id":"importing-and-exploring-data","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.5 Importing and Exploring Data","text":"","code":""},{"path":"day1.html","id":"reading-csv-files","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.5.1 Reading CSV Files","text":"","code":"\n# Read CSV\ndata <- read.csv(\"data/proteins.csv\")\n\n# Read with tidyverse\nlibrary(readr)\ndata <- read_csv(\"data/proteins.csv\")\n\n# Read tab-delimited\ndata <- read.delim(\"data/proteins.txt\", sep = \"\\t\")"},{"path":"day1.html","id":"basic-data-exploration","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.5.2 Basic Data Exploration","text":"","code":"\n# Create example data\nset.seed(123)\nprotein_data <- data.frame(\n  protein_id = paste0(\"P\", 1:100),\n  abundance = rnorm(100, mean = 1000, sd = 200),\n  condition = rep(c(\"Control\", \"Treatment\"), each = 50)\n)\n\n# Dimensions\ndim(protein_data)\n#> [1] 100   3\nnrow(protein_data)\n#> [1] 100\nncol(protein_data)\n#> [1] 3\n\n# First and last rows\nhead(protein_data)\n#>   protein_id abundance condition\n#> 1         P1  887.9049   Control\n#> 2         P2  953.9645   Control\n#> 3         P3 1311.7417   Control\n#> 4         P4 1014.1017   Control\n#> 5         P5 1025.8575   Control\n#> 6         P6 1343.0130   Control\ntail(protein_data)\n#>     protein_id abundance condition\n#> 95         P95 1272.1305 Treatment\n#> 96         P96  879.9481 Treatment\n#> 97         P97 1437.4666 Treatment\n#> 98         P98 1306.5221 Treatment\n#> 99         P99  952.8599 Treatment\n#> 100       P100  794.7158 Treatment\n\n# Summary statistics\nsummary(protein_data)\n#>   protein_id          abundance       condition        \n#>  Length:100         Min.   : 538.2   Length:100        \n#>  Class :character   1st Qu.: 901.2   Class :character  \n#>  Mode  :character   Median :1012.4   Mode  :character  \n#>                     Mean   :1018.1                     \n#>                     3rd Qu.:1138.4                     \n#>                     Max.   :1437.5\n\n# Table for categorical data\ntable(protein_data$condition)\n#> \n#>   Control Treatment \n#>        50        50"},{"path":"day1.html","id":"day-1-summary","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.6 Day 1 Summary","text":"Today learned:✓ set R RStudio✓ Basic R operators syntax✓ Data structures: vectors, data frames, lists, factors✓ Indexing subsetting data✓ Control flow: /else, loops✓ Writing custom functions✓ Importing exploring data","code":""},{"path":"day1.html","id":"homework","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.6.1 Homework","text":"Install required packages Day 2Practice writing functions data manipulationExplore built-datasets R (use data() see available datasets)","code":"\n# Install packages for Day 2\ninstall.packages(c(\"ggplot2\", \"dplyr\", \"tidyr\", \"pheatmap\"))\n\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(c(\"limma\", \"vsn\"))"},{"path":"day1.html","id":"additional-resources","chapter":"Day - 1 Introduction to R and RStudio","heading":"1.7 Additional Resources","text":"R Data Science Hadley WickhamRStudio Cheat SheetsStack Overflow questions","code":""},{"path":"day2.html","id":"day2","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"Day - 2 Introduction to Proteomic Data & Quality Control","text":"","code":""},{"path":"day2.html","id":"learning-objectives-1","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.1 Learning Objectives","text":"end Day 2, able :Understand structure proteomic data matricesIdentify common data quality issuesPerform initial quality control checksVisualize data using PCA, boxplots, heatmapsConduct exploratory data analysis (EDA)","code":""},{"path":"day2.html","id":"day2-mod1","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.2 Module 1: Introduction to Proteomic Data","text":"","code":""},{"path":"day2.html","id":"from-mass-spectrometry-to-quantified-proteins","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.2.1 From Mass Spectrometry to Quantified Proteins","text":"Proteomics workflow:Sample Preparation: Protein extraction, digestion peptidesLC-MS/MS: Liquid chromatography coupled tandem mass spectrometryPeptide Identification: Match spectra peptide sequencesProtein Inference: Aggregate peptides proteinsQuantification: Measure protein abundance\nLabel-free quantification (LFQ)\nIsobaric labeling (TMT, iTRAQ)\nSILAC\nLabel-free quantification (LFQ)Isobaric labeling (TMT, iTRAQ)SILAC","code":""},{"path":"day2.html","id":"structure-of-proteomic-data-matrices","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.2.2 Structure of Proteomic Data Matrices","text":"Typical structure: Proteins × Samples","code":"\n# Example proteomic data structure\nset.seed(42)\n\nn_proteins <- 50\nn_samples <- 12\n\n# Create sample metadata\nsample_metadata <- data.frame(\n  sample_id = paste0(\"S\", 1:n_samples),\n  condition = rep(c(\"Control\", \"Treatment\"), each = 6),\n  batch = rep(c(\"Batch1\", \"Batch2\"), times = 6),\n  timepoint = rep(c(\"T0\", \"T1\", \"T2\"), each = 4)\n)\n\n# Create protein matrix\nprotein_ids <- paste0(\"P\", sprintf(\"%05d\", 1:n_proteins))\n\n# Simulate protein abundances with biological variation\nprotein_matrix <- matrix(\n  rnorm(n_proteins * n_samples, mean = 20, sd = 2),\n  nrow = n_proteins,\n  ncol = n_samples,\n  dimnames = list(protein_ids, sample_metadata$sample_id)\n)\n\n# Add treatment effect for some proteins\ntreatment_proteins <- 1:10\nprotein_matrix[treatment_proteins, 7:12] <- \n  protein_matrix[treatment_proteins, 7:12] + rnorm(10 * 6, mean = 2, sd = 0.5)\n\n# Add some missing values (realistic scenario)\nmissing_indices <- sample(1:length(protein_matrix), size = 50)\nprotein_matrix[missing_indices] <- NA\n\n# Display structure\ncat(\"Matrix dimensions:\", dim(protein_matrix), \"\\n\")\n#> Matrix dimensions: 50 12\ncat(\"Number of proteins:\", nrow(protein_matrix), \"\\n\")\n#> Number of proteins: 50\ncat(\"Number of samples:\", ncol(protein_matrix), \"\\n\")\n#> Number of samples: 12\ncat(\"Number of missing values:\", sum(is.na(protein_matrix)), \"\\n\")\n#> Number of missing values: 50\n\n# Show first few rows and columns\nhead(protein_matrix[, 1:6])\n#>              S1       S2       S3       S4       S5\n#> P00001 22.74192       NA       NA       NA 15.99814\n#> P00002 18.87060 18.43232 22.08950 16.89691 20.66755\n#> P00003 20.72626 23.15146 17.99358 22.33434 22.34265\n#> P00004 21.26573 21.28580 23.69696 19.45271 24.11908\n#> P00005 20.80854 20.17952 18.66645 19.06431 17.24628\n#> P00006       NA 20.55310 20.21103 17.52350 17.69829\n#>              S6\n#> P00001 17.80769\n#> P00002 20.09810\n#> P00003 17.60301\n#> P00004 20.38004\n#> P00005       NA\n#> P00006 17.93225"},{"path":"day2.html","id":"understanding-your-data","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.2.3 Understanding Your Data","text":"","code":"\n# Sample metadata\nprint(sample_metadata)\n#>    sample_id condition  batch timepoint\n#> 1         S1   Control Batch1        T0\n#> 2         S2   Control Batch2        T0\n#> 3         S3   Control Batch1        T0\n#> 4         S4   Control Batch2        T0\n#> 5         S5   Control Batch1        T1\n#> 6         S6   Control Batch2        T1\n#> 7         S7 Treatment Batch1        T1\n#> 8         S8 Treatment Batch2        T1\n#> 9         S9 Treatment Batch1        T2\n#> 10       S10 Treatment Batch2        T2\n#> 11       S11 Treatment Batch1        T2\n#> 12       S12 Treatment Batch2        T2\n\n# Data summary\nsummary_stats <- data.frame(\n  Sample = colnames(protein_matrix),\n  Mean = apply(protein_matrix, 2, mean, na.rm = TRUE),\n  Median = apply(protein_matrix, 2, median, na.rm = TRUE),\n  SD = apply(protein_matrix, 2, sd, na.rm = TRUE),\n  N_Missing = apply(protein_matrix, 2, function(x) sum(is.na(x)))\n)\n\nprint(summary_stats)\n#>     Sample     Mean   Median       SD N_Missing\n#> S1      S1 19.90361 19.77202 2.343037         2\n#> S2      S2 20.17817 20.51584 1.909604         7\n#> S3      S3 19.57170 19.17226 1.828050         3\n#> S4      S4 19.95178 20.21372 1.864843         6\n#> S5      S5 20.18763 19.83178 1.987539         5\n#> S6      S6 19.97424 20.09561 2.029430         2\n#> S7      S7 20.22084 19.99952 1.864873         5\n#> S8      S8 20.69754 20.46976 2.042691         4\n#> S9      S9 20.32477 20.30522 2.090413         5\n#> S10    S10 20.00961 19.98189 2.344816         5\n#> S11    S11 20.65275 20.44848 2.322889         1\n#> S12    S12 20.09191 19.97434 2.109793         5"},{"path":"day2.html","id":"exercise-2.1-explore-your-data","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.2.4 Exercise 2.1: Explore Your Data","text":"Given proteomic dataset, calculate:Total number proteins quantifiedAverage number missing values per proteinWhich sample missing values?","code":"\n# Solution\ncat(\"1. Total proteins:\", nrow(protein_matrix), \"\\n\")\n#> 1. Total proteins: 50\n\nmissing_per_protein <- apply(protein_matrix, 1, function(x) sum(is.na(x)))\ncat(\"2. Average missing per protein:\", \n    round(mean(missing_per_protein), 2), \"\\n\")\n#> 2. Average missing per protein: 1\n\nmissing_per_sample <- apply(protein_matrix, 2, function(x) sum(is.na(x)))\nworst_sample <- names(which.max(missing_per_sample))\ncat(\"3. Sample with most missing:\", worst_sample, \n    \"with\", max(missing_per_sample), \"missing values\\n\")\n#> 3. Sample with most missing: S2 with 7 missing values"},{"path":"day2.html","id":"day2-mod2","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.3 Module 2: Initial Quality Control","text":"","code":""},{"path":"day2.html","id":"missing-data-analysis","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.3.1 Missing Data Analysis","text":"Missing data common proteomics. Understanding pattern crucial.","code":"\n# Calculate missingness\nmissing_per_protein <- apply(protein_matrix, 1, function(x) sum(is.na(x)))\nmissing_per_sample <- apply(protein_matrix, 2, function(x) sum(is.na(x)))\n\n# Visualize missing data pattern\nlibrary(reshape2)\n\nmissing_df <- melt(is.na(protein_matrix))\ncolnames(missing_df) <- c(\"Protein\", \"Sample\", \"Missing\")\n\n# Plot missing data heatmap\nggplot(missing_df, aes(x = Sample, y = Protein, fill = Missing)) +\n  geom_tile() +\n  scale_fill_manual(values = c(\"TRUE\" = \"red\", \"FALSE\" = \"grey90\")) +\n  theme_minimal() +\n  theme(axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()) +\n  labs(title = \"Missing Data Pattern\",\n       subtitle = paste0(\"Red = Missing (\", \n                        round(mean(missing_df$Missing) * 100, 1), \"% total)\"))\n\n# Histogram of missing values per protein\nhist(missing_per_protein,\n     breaks = 20,\n     main = \"Distribution of Missing Values per Protein\",\n     xlab = \"Number of Missing Values\",\n     col = \"steelblue\")"},{"path":"day2.html","id":"detecting-outliers-and-extreme-values","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.3.2 Detecting Outliers and Extreme Values","text":"","code":"\n# Box plots for each sample\nprotein_df <- as.data.frame(protein_matrix)\nprotein_df$protein_id <- rownames(protein_df)\n\nprotein_long <- pivot_longer(protein_df, \n                             cols = -protein_id,\n                             names_to = \"sample_id\",\n                             values_to = \"abundance\")\n\n# Add condition information\nprotein_long <- merge(protein_long, sample_metadata, by = \"sample_id\")\n\n# Boxplot\nggplot(protein_long, aes(x = sample_id, y = abundance, fill = condition)) +\n  geom_boxplot(outlier.size = 0.5) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Abundance Distribution by Sample\",\n       x = \"Sample\", y = \"Log2 Abundance\") +\n  scale_fill_brewer(palette = \"Set2\")\n\n# Density plots\nggplot(protein_long, aes(x = abundance, color = sample_id)) +\n  geom_density() +\n  theme_minimal() +\n  labs(title = \"Density Plot of Protein Abundances\",\n       x = \"Log2 Abundance\", y = \"Density\") +\n  theme(legend.position = \"none\")"},{"path":"day2.html","id":"batch-effects-detection","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.3.3 Batch Effects Detection","text":"Batch effects systematic non-biological variations.","code":"\n# PCA colored by batch\npca_data <- t(na.omit(protein_matrix))\npca_result <- prcomp(pca_data, scale. = TRUE)\n\n# Create PCA data frame\npca_df <- data.frame(\n  PC1 = pca_result$x[, 1],\n  PC2 = pca_result$x[, 2],\n  sample_id = rownames(pca_result$x)\n)\n\npca_df <- merge(pca_df, sample_metadata, by = \"sample_id\")\n\n# Variance explained\nvar_explained <- summary(pca_result)$importance[2, 1:2] * 100\n\n# PCA plot by batch\nggplot(pca_df, aes(x = PC1, y = PC2, color = batch, shape = condition)) +\n  geom_point(size = 4) +\n  theme_minimal() +\n  labs(title = \"PCA Analysis - Batch Effect Detection\",\n       x = paste0(\"PC1 (\", round(var_explained[1], 1), \"%)\"),\n       y = paste0(\"PC2 (\", round(var_explained[2], 1), \"%)\")) +\n  scale_color_brewer(palette = \"Set1\")\n\n# PCA plot by condition\nggplot(pca_df, aes(x = PC1, y = PC2, color = condition, shape = batch)) +\n  geom_point(size = 4) +\n  theme_minimal() +\n  labs(title = \"PCA Analysis - Biological Conditions\",\n       x = paste0(\"PC1 (\", round(var_explained[1], 1), \"%)\"),\n       y = paste0(\"PC2 (\", round(var_explained[2], 1), \"%)\")) +\n  scale_color_brewer(palette = \"Dark2\")"},{"path":"day2.html","id":"sample-correlation-analysis","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.3.4 Sample Correlation Analysis","text":"","code":"\n# Calculate sample correlations\ncor_matrix <- cor(protein_matrix, use = \"pairwise.complete.obs\")\n\n# Heatmap\nrownames(sample_metadata) <- sample_metadata$sample_id\n\npheatmap(cor_matrix,\n         annotation_col = sample_metadata[, c(\"condition\", \"batch\"), drop = FALSE],\n         annotation_row = sample_metadata[, c(\"condition\", \"batch\"), drop = FALSE],\n         main = \"Sample-Sample Correlation\",\n         color = colorRampPalette(c(\"blue\", \"white\", \"red\"))(50),\n         breaks = seq(0.5, 1, length.out = 51))"},{"path":"day2.html","id":"exercise-2.2-quality-control-checks","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.3.5 Exercise 2.2: Quality Control Checks","text":"Perform QC provided dataset:Calculate percentage proteins >50% missing valuesIdentify outlier samples (median abundance far others)Check batch effects using PCA","code":"\n# Solution\n# 1. Proteins with >50% missing\nmissing_pct <- apply(protein_matrix, 1, function(x) sum(is.na(x)) / length(x))\nhigh_missing <- sum(missing_pct > 0.5)\ncat(\"Proteins with >50% missing:\", high_missing, \n    \"(\", round(high_missing / nrow(protein_matrix) * 100, 1), \"%)\\n\")\n#> Proteins with >50% missing: 0 ( 0 %)\n\n# 2. Outlier samples based on median\nsample_medians <- apply(protein_matrix, 2, median, na.rm = TRUE)\nmedian_overall <- median(sample_medians)\nmad_overall <- mad(sample_medians)\noutliers <- abs(sample_medians - median_overall) > 3 * mad_overall\n\nif (any(outliers)) {\n  cat(\"Outlier samples:\", names(sample_medians)[outliers], \"\\n\")\n} else {\n  cat(\"No outlier samples detected\\n\")\n}\n#> No outlier samples detected\n\n# 3. Batch effects - already shown in PCA above\ncat(\"Check PCA plot above for batch effect visualization\\n\")\n#> Check PCA plot above for batch effect visualization"},{"path":"day2.html","id":"day2-mod3","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.4 Module 3: Exploratory Data Analysis (EDA)","text":"","code":""},{"path":"day2.html","id":"distribution-of-intensities","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.4.1 Distribution of Intensities","text":"","code":"\n# Histogram of all values\nggplot(protein_long, aes(x = abundance)) +\n  geom_histogram(bins = 50, fill = \"steelblue\", color = \"black\", alpha = 0.7) +\n  theme_minimal() +\n  labs(title = \"Distribution of Protein Abundances\",\n       x = \"Log2 Abundance\", y = \"Frequency\")\n\n# Violin plots by condition\nggplot(protein_long, aes(x = condition, y = abundance, fill = condition)) +\n  geom_violin() +\n  geom_boxplot(width = 0.1, fill = \"white\", outlier.size = 0.5) +\n  theme_minimal() +\n  labs(title = \"Abundance Distribution by Condition\",\n       x = \"Condition\", y = \"Log2 Abundance\") +\n  scale_fill_brewer(palette = \"Set2\")"},{"path":"day2.html","id":"hierarchical-clustering","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.4.2 Hierarchical Clustering","text":"","code":"\n# Remove proteins with too many missing values\ncomplete_proteins <- rowSums(is.na(protein_matrix)) < ncol(protein_matrix) * 0.3\nfiltered_matrix <- protein_matrix[complete_proteins, ]\n\n# Impute remaining missing values with row means\nfor (i in 1:nrow(filtered_matrix)) {\n  missing_idx <- is.na(filtered_matrix[i, ])\n  if (any(missing_idx)) {\n    filtered_matrix[i, missing_idx] <- mean(filtered_matrix[i, ], na.rm = TRUE)\n  }\n}\n\n# Hierarchical clustering heatmap\nannotation_col <- sample_metadata[, c(\"condition\", \"batch\", \"timepoint\")]\nrownames(annotation_col) <- sample_metadata$sample_id\n\npheatmap(filtered_matrix,\n         scale = \"row\",\n         clustering_distance_rows = \"euclidean\",\n         clustering_distance_cols = \"euclidean\",\n         annotation_col = annotation_col,\n         show_rownames = FALSE,\n         main = \"Hierarchical Clustering of Samples\",\n         color = colorRampPalette(c(\"blue\", \"white\", \"red\"))(50))"},{"path":"day2.html","id":"sample-similarity-analysis","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.4.3 Sample Similarity Analysis","text":"","code":"\n# Calculate Euclidean distances between samples\nsample_dist <- dist(t(filtered_matrix))\nsample_dist_matrix <- as.matrix(sample_dist)\n\n# Heatmap of distances\npheatmap(sample_dist_matrix,\n         annotation_col = annotation_col,\n         annotation_row = annotation_col,\n         main = \"Sample-Sample Distance Matrix\",\n         color = colorRampPalette(c(\"red\", \"white\"))(50))\n\n# MDS plot (alternative to PCA)\nmds_result <- cmdscale(sample_dist, k = 2)\nmds_df <- data.frame(\n  MDS1 = mds_result[, 1],\n  MDS2 = mds_result[, 2],\n  sample_id = colnames(filtered_matrix)\n)\nmds_df <- merge(mds_df, sample_metadata, by = \"sample_id\")\n\nggplot(mds_df, aes(x = MDS1, y = MDS2, color = condition, shape = batch)) +\n  geom_point(size = 4) +\n  theme_minimal() +\n  labs(title = \"MDS Plot of Sample Similarity\",\n       x = \"MDS Dimension 1\", y = \"MDS Dimension 2\") +\n  scale_color_brewer(palette = \"Dark2\")"},{"path":"day2.html","id":"coefficient-of-variation-analysis","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.4.4 Coefficient of Variation Analysis","text":"","code":"\n# Calculate CV for each protein\ncalculate_cv <- function(x) {\n  (sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)) * 100\n}\n\ncv_by_condition <- protein_long %>%\n  group_by(protein_id, condition) %>%\n  summarise(cv = calculate_cv(abundance), .groups = \"drop\")\n\n# Plot CV distribution\nggplot(cv_by_condition, aes(x = cv, fill = condition)) +\n  geom_histogram(bins = 30, alpha = 0.7, position = \"identity\") +\n  theme_minimal() +\n  labs(title = \"Coefficient of Variation Distribution\",\n       x = \"CV (%)\", y = \"Count\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  facet_wrap(~ condition, ncol = 1)\n\n# Summary statistics\ncv_summary <- cv_by_condition %>%\n  group_by(condition) %>%\n  summarise(\n    mean_cv = mean(cv, na.rm = TRUE),\n    median_cv = median(cv, na.rm = TRUE),\n    sd_cv = sd(cv, na.rm = TRUE)\n  )\n\nprint(cv_summary)\n#> # A tibble: 2 × 4\n#>   condition mean_cv median_cv sd_cv\n#>   <chr>       <dbl>     <dbl> <dbl>\n#> 1 Control      9.63      8.85  3.33\n#> 2 Treatment    8.93      8.64  3.37"},{"path":"day2.html","id":"exercise-2.3-complete-eda","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.4.5 Exercise 2.3: Complete EDA","text":"Perform complete exploratory analysis:Create report summarizing data qualityIdentify top 10 variable proteinsCheck samples cluster biological condition","code":"\n# Solution\n# 1. Data quality report\ncat(\"=== DATA QUALITY REPORT ===\\n\\n\")\n#> === DATA QUALITY REPORT ===\ncat(\"Dataset dimensions:\", nrow(protein_matrix), \"proteins x\", \n    ncol(protein_matrix), \"samples\\n\")\n#> Dataset dimensions: 50 proteins x 12 samples\ncat(\"Total missing values:\", sum(is.na(protein_matrix)), \n    \"(\", round(mean(is.na(protein_matrix)) * 100, 1), \"%)\\n\")\n#> Total missing values: 50 ( 8.3 %)\ncat(\"Samples:\", paste(sample_metadata$sample_id, collapse = \", \"), \"\\n\")\n#> Samples: S1, S2, S3, S4, S5, S6, S7, S8, S9, S10, S11, S12\ncat(\"Conditions:\", paste(unique(sample_metadata$condition), collapse = \", \"), \"\\n\")\n#> Conditions: Control, Treatment\ncat(\"Batches:\", paste(unique(sample_metadata$batch), collapse = \", \"), \"\\n\\n\")\n#> Batches: Batch1, Batch2\n\n# 2. Top 10 most variable proteins\nprotein_variance <- apply(filtered_matrix, 1, var, na.rm = TRUE)\ntop10_variable <- names(sort(protein_variance, decreasing = TRUE)[1:10])\ncat(\"Top 10 most variable proteins:\\n\")\n#> Top 10 most variable proteins:\nprint(top10_variable)\n#>  [1] \"P00009\" \"P00018\" \"P00001\" \"P00019\" \"P00024\" \"P00044\"\n#>  [7] \"P00016\" \"P00025\" \"P00017\" \"P00031\"\n\n# Plot top variable proteins\ntop10_data <- protein_long %>%\n  filter(protein_id %in% top10_variable)\n\nggplot(top10_data, aes(x = sample_id, y = abundance, color = condition, group = 1)) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~ protein_id, scales = \"free_y\", ncol = 2) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Top 10 Most Variable Proteins\", x = \"Sample\", y = \"Abundance\")\n\n# 3. Clustering by condition\ncat(\"\\n3. Checking sample clustering by condition:\\n\")\n#> \n#> 3. Checking sample clustering by condition:\ncat(\"Review the PCA and hierarchical clustering plots above.\\n\")\n#> Review the PCA and hierarchical clustering plots above.\ncat(\"Samples should cluster primarily by condition if biological signal is strong.\\n\")\n#> Samples should cluster primarily by condition if biological signal is strong."},{"path":"day2.html","id":"creating-quality-control-reports","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.5 Creating Quality Control Reports","text":"","code":"\n# Function to generate QC report\ngenerate_qc_report <- function(data_matrix, metadata) {\n  report <- list()\n  \n  # Basic statistics\n  report$n_proteins <- nrow(data_matrix)\n  report$n_samples <- ncol(data_matrix)\n  report$missing_pct <- mean(is.na(data_matrix)) * 100\n  \n  # Sample statistics\n  report$sample_stats <- data.frame(\n    Sample = colnames(data_matrix),\n    N_Quantified = colSums(!is.na(data_matrix)),\n    Median_Abundance = apply(data_matrix, 2, median, na.rm = TRUE),\n    Mean_Abundance = apply(data_matrix, 2, mean, na.rm = TRUE),\n    SD_Abundance = apply(data_matrix, 2, sd, na.rm = TRUE)\n  )\n  \n  # Protein statistics\n  report$protein_stats <- data.frame(\n    N_Complete = sum(rowSums(is.na(data_matrix)) == 0),\n    N_Partial = sum(rowSums(is.na(data_matrix)) > 0 & rowSums(is.na(data_matrix)) < ncol(data_matrix)),\n    N_Mostly_Missing = sum(rowSums(is.na(data_matrix)) > ncol(data_matrix) * 0.5)\n  )\n  \n  return(report)\n}\n\n# Generate report\nqc_report <- generate_qc_report(protein_matrix, sample_metadata)\n\n# Print report\ncat(\"=== QUALITY CONTROL SUMMARY ===\\n\\n\")\n#> === QUALITY CONTROL SUMMARY ===\ncat(\"Total Proteins:\", qc_report$n_proteins, \"\\n\")\n#> Total Proteins: 50\ncat(\"Total Samples:\", qc_report$n_samples, \"\\n\")\n#> Total Samples: 12\ncat(\"Missing Data:\", round(qc_report$missing_pct, 2), \"%\\n\\n\")\n#> Missing Data: 8.33 %\n\ncat(\"Protein Completeness:\\n\")\n#> Protein Completeness:\ncat(\"  Complete (no missing):\", qc_report$protein_stats$N_Complete, \"\\n\")\n#>   Complete (no missing): 12\ncat(\"  Partial missing:\", qc_report$protein_stats$N_Partial, \"\\n\")\n#>   Partial missing: 38\ncat(\"  Mostly missing (>50%):\", qc_report$protein_stats$N_Mostly_Missing, \"\\n\\n\")\n#>   Mostly missing (>50%): 0\n\nprint(qc_report$sample_stats)\n#>     Sample N_Quantified Median_Abundance Mean_Abundance\n#> S1      S1           48         19.77202       19.90361\n#> S2      S2           43         20.51584       20.17817\n#> S3      S3           47         19.17226       19.57170\n#> S4      S4           44         20.21372       19.95178\n#> S5      S5           45         19.83178       20.18763\n#> S6      S6           48         20.09561       19.97424\n#> S7      S7           45         19.99952       20.22084\n#> S8      S8           46         20.46976       20.69754\n#> S9      S9           45         20.30522       20.32477\n#> S10    S10           45         19.98189       20.00961\n#> S11    S11           49         20.44848       20.65275\n#> S12    S12           45         19.97434       20.09191\n#>     SD_Abundance\n#> S1      2.343037\n#> S2      1.909604\n#> S3      1.828050\n#> S4      1.864843\n#> S5      1.987539\n#> S6      2.029430\n#> S7      1.864873\n#> S8      2.042691\n#> S9      2.090413\n#> S10     2.344816\n#> S11     2.322889\n#> S12     2.109793"},{"path":"day2.html","id":"day-2-summary","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.6 Day 2 Summary","text":"Today learned:✓ Structure proteomic data matrices✓ Common data quality issues (missing values, outliers, batch effects)✓ Quality control visualization techniques✓ Exploratory data analysis methods✓ Sample correlation clustering","code":""},{"path":"day2.html","id":"key-takeaways","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.6.1 Key Takeaways","text":"Missing data common proteomics - understand pattern imputationBatch effects can confound biological signals - always check PCAQuality control performed statistical analysisVisualization essential understanding data","code":""},{"path":"day2.html","id":"homework-1","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.6.2 Homework","text":"Apply QC pipeline new datasetPractice identifying batch effectsCreate custom QC visualizations","code":"\n# Prepare for Day 3\ninstall.packages(c(\"preprocessCore\", \"matrixStats\"))\n\nBiocManager::install(c(\"limma\", \"vsn\", \"sva\"))"},{"path":"day2.html","id":"additional-resources-1","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.7 Additional Resources","text":"Proteomics Data Analysis Best PracticesUnderstanding PCA ProteomicsKammers et al. (2015) “Detecting Significant Changes Protein Abundance”","code":""},{"path":"day2.html","id":"case-study-real-proteomic-dataset","chapter":"Day - 2 Introduction to Proteomic Data & Quality Control","heading":"2.8 Case Study: Real Proteomic Dataset","text":"","code":"\n# Example workflow for your own data\n# 1. Load data\nmy_data <- read.csv(\"your_protein_data.csv\", row.names = 1)\n\n# 2. Load metadata\nmy_metadata <- read.csv(\"your_sample_metadata.csv\")\n\n# 3. Initial QC\nqc_report <- generate_qc_report(my_data, my_metadata)\n\n# 4. Visualizations\n# - PCA\n# - Correlation heatmap\n# - Missing data pattern\n# - Boxplots\n\n# 5. Document findings\n# - Any problematic samples?\n# - Batch effects present?\n# - Next steps for preprocessing"},{"path":"day3.html","id":"day3","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"Day - 3 Preprocessing and Differential Expression","text":"","code":""},{"path":"day3.html","id":"learning-objectives-2","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.1 Learning Objectives","text":"end Day 3, able :Apply different normalization methods proteomic dataPerform batch effect correctionConduct differential expression analysis using limmaInterpret visualize differential expression resultsCreate volcano plots MA plots","code":""},{"path":"day3.html","id":"day3-mod1","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2 Module 1: Data Preprocessing","text":"","code":""},{"path":"day3.html","id":"why-normalize","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.1 Why Normalize?","text":"Normalization removes systematic technical variation :Make samples comparableReduce technical noisePreserve biological signal","code":""},{"path":"day3.html","id":"loading-example-data","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.2 Loading Example Data","text":"","code":"\n# Create example proteomic dataset with technical variation\nset.seed(123)\n\nn_proteins <- 500\nn_samples <- 16\n\n# Sample metadata\nsample_metadata <- data.frame(\n  sample_id = paste0(\"S\", 1:n_samples),\n  condition = rep(c(\"Control\", \"Treatment\"), each = 8),\n  batch = rep(c(\"Batch1\", \"Batch2\"), times = 8),\n  replicate = rep(1:8, times = 2),\n  stringsAsFactors = FALSE\n)\n\n# Generate base protein abundances\nprotein_matrix_raw <- matrix(\n  rnorm(n_proteins * n_samples, mean = 20, sd = 3),\n  nrow = n_proteins,\n  ncol = n_samples\n)\n\nrownames(protein_matrix_raw) <- paste0(\"P\", sprintf(\"%05d\", 1:n_proteins))\ncolnames(protein_matrix_raw) <- sample_metadata$sample_id\n\n# Add biological effect (differential proteins)\nde_proteins <- 1:50\nprotein_matrix_raw[de_proteins, sample_metadata$condition == \"Treatment\"] <- \n  protein_matrix_raw[de_proteins, sample_metadata$condition == \"Treatment\"] + \n  rnorm(50 * 8, mean = 2, sd = 0.5)\n\n# Add batch effect\nbatch1_samples <- sample_metadata$batch == \"Batch1\"\nprotein_matrix_raw[, batch1_samples] <- protein_matrix_raw[, batch1_samples] + 1.5\n\n# Add some missing values\nmissing_idx <- sample(1:length(protein_matrix_raw), size = 500)\nprotein_matrix_raw[missing_idx] <- NA\n\ncat(\"Raw data dimensions:\", dim(protein_matrix_raw), \"\\n\")\n#> Raw data dimensions: 500 16\ncat(\"Missing values:\", sum(is.na(protein_matrix_raw)), \"\\n\")\n#> Missing values: 500"},{"path":"day3.html","id":"handling-missing-values","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.3 Handling Missing Values","text":"","code":"\n# Strategy 1: Remove proteins with too many missing values\nthreshold <- 0.3  # Remove if >30% missing\nmissing_per_protein <- rowSums(is.na(protein_matrix_raw)) / ncol(protein_matrix_raw)\nfiltered_proteins <- missing_per_protein <= threshold\n\nprotein_matrix_filtered <- protein_matrix_raw[filtered_proteins, ]\n\ncat(\"Proteins after filtering:\", nrow(protein_matrix_filtered), \"\\n\")\n#> Proteins after filtering: 499\n\n# Strategy 2: Imputation (simple mean imputation)\nprotein_matrix_imputed <- protein_matrix_filtered\n\nfor (i in 1:nrow(protein_matrix_imputed)) {\n  missing_idx <- is.na(protein_matrix_imputed[i, ])\n  if (any(missing_idx)) {\n    protein_matrix_imputed[i, missing_idx] <- mean(protein_matrix_imputed[i, ], na.rm = TRUE)\n  }\n}\n\ncat(\"Missing values after imputation:\", sum(is.na(protein_matrix_imputed)), \"\\n\")\n#> Missing values after imputation: 0"},{"path":"day3.html","id":"normalization-methods","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.4 Normalization Methods","text":"","code":""},{"path":"day3.html","id":"median-normalization","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.4.1 1. Median Normalization","text":"","code":"\n# Calculate median for each sample\nsample_medians <- apply(protein_matrix_imputed, 2, median, na.rm = TRUE)\nglobal_median <- median(sample_medians)\n\n# Normalize\nprotein_matrix_median <- protein_matrix_imputed\nfor (i in 1:ncol(protein_matrix_median)) {\n  protein_matrix_median[, i] <- protein_matrix_median[, i] - \n    sample_medians[i] + global_median\n}\n\n# Visualize before and after\npar(mfrow = c(1, 2))\nboxplot(protein_matrix_imputed, main = \"Before Median Normalization\",\n        las = 2, cex.axis = 0.7, ylab = \"Abundance\")\nboxplot(protein_matrix_median, main = \"After Median Normalization\",\n        las = 2, cex.axis = 0.7, ylab = \"Abundance\")"},{"path":"day3.html","id":"quantile-normalization","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.4.2 2. Quantile Normalization","text":"","code":"\n# Quantile normalization\nprotein_matrix_quantile <- limma::normalizeBetweenArrays(protein_matrix_imputed, \n                                                          method = \"quantile\")\n\n# Visualize\npar(mfrow = c(1, 2))\nboxplot(protein_matrix_imputed, main = \"Before Quantile Normalization\",\n        las = 2, cex.axis = 0.7, ylab = \"Abundance\")\nboxplot(protein_matrix_quantile, main = \"After Quantile Normalization\",\n        las = 2, cex.axis = 0.7, ylab = \"Abundance\")"},{"path":"day3.html","id":"vsn-variance-stabilizing-normalization","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.4.3 3. VSN (Variance Stabilizing Normalization)","text":"","code":"\n# VSN normalization\nvsn_fit <- vsn::vsn2(protein_matrix_imputed)\nprotein_matrix_vsn <- vsn::predict(vsn_fit, protein_matrix_imputed)\n\n# Visualize mean-sd relationship\npar(mfrow = c(1, 2))\nvsn::meanSdPlot(protein_matrix_imputed, main = \"Before VSN\")\nvsn::meanSdPlot(protein_matrix_vsn, main = \"After VSN\")"},{"path":"day3.html","id":"comparing-normalization-methods","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.5 Comparing Normalization Methods","text":"","code":"\n# PCA comparison\nplot_pca <- function(data, title, metadata) {\n  pca_result <- prcomp(t(data), scale. = FALSE)\n  var_exp <- summary(pca_result)$importance[2, 1:2] * 100\n  \n  pca_df <- data.frame(\n    PC1 = pca_result$x[, 1],\n    PC2 = pca_result$x[, 2],\n    condition = metadata$condition,\n    batch = metadata$batch\n  )\n  \n  ggplot(pca_df, aes(x = PC1, y = PC2, color = condition, shape = batch)) +\n    geom_point(size = 3) +\n    theme_minimal() +\n    labs(title = title,\n         x = paste0(\"PC1 (\", round(var_exp[1], 1), \"%)\"),\n         y = paste0(\"PC2 (\", round(var_exp[2], 1), \"%)\")) +\n    scale_color_brewer(palette = \"Set1\")\n}\n\n# Compare all methods\np1 <- plot_pca(protein_matrix_imputed, \"Raw Data\", sample_metadata)\np2 <- plot_pca(protein_matrix_median, \"Median Normalized\", sample_metadata)\np3 <- plot_pca(protein_matrix_quantile, \"Quantile Normalized\", sample_metadata)\np4 <- plot_pca(protein_matrix_vsn, \"VSN Normalized\", sample_metadata)\n\nlibrary(gridExtra)\ngrid.arrange(p1, p2, p3, p4, ncol = 2)"},{"path":"day3.html","id":"exercise-3.1-apply-normalization","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.2.6 Exercise 3.1: Apply Normalization","text":"Apply three normalization methods :Calculate CV methodCompare sample correlationsChoose best method data","code":"\n# Solution\ncalculate_mean_cv <- function(data) {\n  cvs <- apply(data, 1, function(x) sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE) * 100)\n  mean(cvs, na.rm = TRUE)\n}\n\ncat(\"Mean CV - Raw:\", round(calculate_mean_cv(protein_matrix_imputed), 2), \"%\\n\")\n#> Mean CV - Raw: 14.1 %\ncat(\"Mean CV - Median:\", round(calculate_mean_cv(protein_matrix_median), 2), \"%\\n\")\n#> Mean CV - Median: 13.64 %\ncat(\"Mean CV - Quantile:\", round(calculate_mean_cv(protein_matrix_quantile), 2), \"%\\n\")\n#> Mean CV - Quantile: 13.67 %\ncat(\"Mean CV - VSN:\", round(calculate_mean_cv(protein_matrix_vsn), 2), \"%\\n\")\n#> Mean CV - VSN: 0.01 %\n\n# Sample correlations\ncor_raw <- mean(cor(protein_matrix_imputed)[upper.tri(cor(protein_matrix_imputed))])\ncor_median <- mean(cor(protein_matrix_median)[upper.tri(cor(protein_matrix_median))])\ncor_quantile <- mean(cor(protein_matrix_quantile)[upper.tri(cor(protein_matrix_quantile))])\n\ncat(\"\\nMean sample correlation - Raw:\", round(cor_raw, 3), \"\\n\")\n#> \n#> Mean sample correlation - Raw: 0.024\ncat(\"Mean sample correlation - Median:\", round(cor_median, 3), \"\\n\")\n#> Mean sample correlation - Median: 0.024\ncat(\"Mean sample correlation - Quantile:\", round(cor_quantile, 3), \"\\n\")\n#> Mean sample correlation - Quantile: 0.024"},{"path":"day3.html","id":"day3-mod2","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.3 Module 2: Batch Effect Correction","text":"","code":""},{"path":"day3.html","id":"detecting-batch-effects","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.3.1 Detecting Batch Effects","text":"","code":"\n# PCA colored by batch\npca_result <- prcomp(t(protein_matrix_quantile), scale. = TRUE)\nvar_exp <- summary(pca_result)$importance[2, 1:2] * 100\n\npca_df <- data.frame(\n  PC1 = pca_result$x[, 1],\n  PC2 = pca_result$x[, 2],\n  sample_id = colnames(protein_matrix_quantile)\n)\npca_df <- merge(pca_df, sample_metadata, by = \"sample_id\")\n\n# Plot by batch\np_batch <- ggplot(pca_df, aes(x = PC1, y = PC2, color = batch, shape = condition)) +\n  geom_point(size = 4) +\n  theme_minimal() +\n  labs(title = \"PCA - Batch Effect Visible\",\n       x = paste0(\"PC1 (\", round(var_exp[1], 1), \"%)\"),\n       y = paste0(\"PC2 (\", round(var_exp[2], 1), \"%)\")) +\n  scale_color_manual(values = c(\"Batch1\" = \"red\", \"Batch2\" = \"blue\"))\n\nprint(p_batch)"},{"path":"day3.html","id":"combat-batch-correction","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.3.2 ComBat Batch Correction","text":"","code":"\n# Prepare for ComBat\nbatch_vector <- sample_metadata$batch\ncondition_matrix <- model.matrix(~condition, data = sample_metadata)\n\n# Apply ComBat\nprotein_matrix_combat <- sva::ComBat(\n  dat = protein_matrix_quantile,\n  batch = batch_vector,\n  mod = condition_matrix,\n  par.prior = TRUE,\n  prior.plots = FALSE\n)\n\n# Compare before and after\npca_combat <- prcomp(t(protein_matrix_combat), scale. = TRUE)\nvar_exp_combat <- summary(pca_combat)$importance[2, 1:2] * 100\n\npca_df_combat <- data.frame(\n  PC1 = pca_combat$x[, 1],\n  PC2 = pca_combat$x[, 2],\n  sample_id = colnames(protein_matrix_combat)\n)\npca_df_combat <- merge(pca_df_combat, sample_metadata, by = \"sample_id\")\n\np_combat <- ggplot(pca_df_combat, aes(x = PC1, y = PC2, color = batch, shape = condition)) +\n  geom_point(size = 4) +\n  theme_minimal() +\n  labs(title = \"PCA - After ComBat Correction\",\n       x = paste0(\"PC1 (\", round(var_exp_combat[1], 1), \"%)\"),\n       y = paste0(\"PC2 (\", round(var_exp_combat[2], 1), \"%)\")) +\n  scale_color_manual(values = c(\"Batch1\" = \"red\", \"Batch2\" = \"blue\"))\n\nlibrary(gridExtra)\ngrid.arrange(p_batch, p_combat, ncol = 2)"},{"path":"day3.html","id":"scaling-methods","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.3.3 Scaling Methods","text":"","code":"\n# Z-score scaling (by protein)\nprotein_matrix_scaled <- t(scale(t(protein_matrix_combat)))\n\n# Pareto scaling\nprotein_matrix_pareto <- t(scale(t(protein_matrix_combat))) / sqrt(apply(protein_matrix_combat, 1, sd, na.rm = TRUE))\n\nrownames(sample_metadata) <- sample_metadata$sample_id\n\n# Visualize effect of scaling\npheatmap(protein_matrix_combat[1:50, ],\n         scale = \"row\",\n         main = \"Heatmap with Row Scaling\",\n         show_rownames = FALSE,\n         annotation_col = sample_metadata[, c(\"condition\", \"batch\"), drop = FALSE])"},{"path":"day3.html","id":"exercise-3.2-complete-preprocessing-pipeline","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.3.4 Exercise 3.2: Complete Preprocessing Pipeline","text":"Create complete preprocessing function :Filters proteins >30% missingImputes missing valuesApplies normalizationCorrects batch effects","code":"\n# Solution\npreprocess_proteomics <- function(raw_data, metadata, \n                                   missing_threshold = 0.3,\n                                   norm_method = \"quantile\") {\n  # Step 1: Filter\n  missing_per_protein <- rowSums(is.na(raw_data)) / ncol(raw_data)\n  filtered_data <- raw_data[missing_per_protein <= missing_threshold, ]\n  cat(\"Filtered to\", nrow(filtered_data), \"proteins\\n\")\n  \n  # Step 2: Impute\n  imputed_data <- filtered_data\n  for (i in 1:nrow(imputed_data)) {\n    missing_idx <- is.na(imputed_data[i, ])\n    if (any(missing_idx)) {\n      imputed_data[i, missing_idx] <- mean(imputed_data[i, ], na.rm = TRUE)\n    }\n  }\n  cat(\"Imputed\", sum(is.na(filtered_data)), \"missing values\\n\")\n  \n  # Step 3: Normalize\n  if (norm_method == \"quantile\") {\n    normalized_data <- limma::normalizeBetweenArrays(imputed_data, method = \"quantile\")\n  } else if (norm_method == \"median\") {\n    sample_medians <- apply(imputed_data, 2, median)\n    global_median <- median(sample_medians)\n    normalized_data <- sweep(imputed_data, 2, sample_medians - global_median)\n  }\n  cat(\"Applied\", norm_method, \"normalization\\n\")\n  \n  # Step 4: Batch correction\n  if (\"batch\" %in% colnames(metadata)) {\n    condition_matrix <- model.matrix(~condition, data = metadata)\n    corrected_data <- sva::ComBat(\n      dat = normalized_data,\n      batch = metadata$batch,\n      mod = condition_matrix,\n      par.prior = TRUE,\n      prior.plots = FALSE\n    )\n    cat(\"Applied ComBat batch correction\\n\")\n  } else {\n    corrected_data <- normalized_data\n  }\n  \n  return(corrected_data)\n}\n\n# Apply pipeline\nprocessed_data <- preprocess_proteomics(protein_matrix_raw, sample_metadata)\n#> Filtered to 499 proteins\n#> Imputed 495 missing values\n#> Applied quantile normalization\n#> Applied ComBat batch correction"},{"path":"day3.html","id":"day3-mod3","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.4 Module 3: Differential Expression Analysis","text":"","code":""},{"path":"day3.html","id":"introduction-to-limma","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.4.1 Introduction to limma","text":"limma (Linear Models Microarray Data) widely used differential expression.Key advantages:\n- Empirical Bayes moderation\n- Handles complex designs\n- Works well small sample sizes","code":""},{"path":"day3.html","id":"basic-differential-expression","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.4.2 Basic Differential Expression","text":"","code":"\n# Design matrix\ndesign <- model.matrix(~0 + condition, data = sample_metadata)\ncolnames(design) <- c(\"Control\", \"Treatment\")\n\n# Fit linear model\nfit <- lmFit(processed_data, design)\n\n# Define contrast\ncontrast_matrix <- makeContrasts(\n  TreatmentVsControl = Treatment - Control,\n  levels = design\n)\n\n# Fit contrasts\nfit2 <- contrasts.fit(fit, contrast_matrix)\n\n# Empirical Bayes moderation\nfit2 <- eBayes(fit2)\n\n# Extract results\nresults <- topTable(fit2, coef = \"TreatmentVsControl\", number = Inf)\n\n# Add protein IDs\nresults$protein_id <- rownames(results)\n\n# View top results\nhead(results, 10)\n#>            logFC  AveExpr         t      P.Value  adj.P.Val\n#> P00043  5.029106 21.80541  3.895339 0.0001918769 0.06177827\n#> P00026  5.054234 21.53741  3.730775 0.0003393640 0.06177827\n#> P00439  5.116733 19.94913  3.704324 0.0003714124 0.06177827\n#> P00041  4.754682 21.88690  3.521085 0.0006863510 0.07551792\n#> P00050  4.458502 20.12443  3.472990 0.0008037582 0.07551792\n#> P00448 -4.602952 20.09167 -3.435547 0.0009080311 0.07551792\n#> P00204 -4.367604 20.06731 -3.373940 0.0011077982 0.07897018\n#> P00037  4.021590 22.72349  3.151759 0.0022255595 0.13881927\n#> P00326 -4.055987 20.17611 -3.083566 0.0027397386 0.15190329\n#> P00025  3.882010 20.47140  2.992742 0.0035966903 0.17947484\n#>                  B protein_id\n#> P00043  0.51632573     P00043\n#> P00026  0.04550759     P00026\n#> P00439 -0.02887366     P00439\n#> P00041 -0.53393668     P00041\n#> P00050 -0.66346841     P00050\n#> P00448 -0.76341971     P00448\n#> P00204 -0.92614479     P00204\n#> P00037 -1.49463286     P00037\n#> P00326 -1.66317428     P00326\n#> P00025 -1.88317691     P00025\n\n# Summary\ncat(\"\\nDifferential Expression Summary:\\n\")\n#> \n#> Differential Expression Summary:\ncat(\"Significant proteins (FDR < 0.05):\", sum(results$adj.P.Val < 0.05), \"\\n\")\n#> Significant proteins (FDR < 0.05): 0\ncat(\"Upregulated (FC > 1.5, FDR < 0.05):\", \n    sum(results$adj.P.Val < 0.05 & results$logFC > log2(1.5)), \"\\n\")\n#> Upregulated (FC > 1.5, FDR < 0.05): 0\ncat(\"Downregulated (FC < -1.5, FDR < 0.05):\", \n    sum(results$adj.P.Val < 0.05 & results$logFC < -log2(1.5)), \"\\n\")\n#> Downregulated (FC < -1.5, FDR < 0.05): 0"},{"path":"day3.html","id":"volcano-plot","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.4.3 Volcano Plot","text":"","code":"\n# Prepare data for volcano plot\nvolcano_data <- results\nvolcano_data$significance <- \"NS\"\nvolcano_data$significance[volcano_data$adj.P.Val < 0.05 & volcano_data$logFC > log2(1.5)] <- \"Up\"\nvolcano_data$significance[volcano_data$adj.P.Val < 0.05 & volcano_data$logFC < -log2(1.5)] <- \"Down\"\n\n# Volcano plot\nggplot(volcano_data, aes(x = logFC, y = -log10(adj.P.Val), color = significance)) +\n  geom_point(alpha = 0.6, size = 2) +\n  scale_color_manual(values = c(\"Up\" = \"red\", \"Down\" = \"blue\", \"NS\" = \"grey\")) +\n  geom_hline(yintercept = -log10(0.05), linetype = \"dashed\") +\n  geom_vline(xintercept = c(-log2(1.5), log2(1.5)), linetype = \"dashed\") +\n  theme_minimal() +\n  labs(title = \"Volcano Plot: Treatment vs Control\",\n       x = \"log2 Fold Change\",\n       y = \"-log10 Adjusted P-value\") +\n  theme(legend.title = element_blank())"},{"path":"day3.html","id":"ma-plot","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.4.4 MA Plot","text":"","code":"\n# MA plot\nvolcano_data$AveExpr <- results$AveExpr\n\nggplot(volcano_data, aes(x = AveExpr, y = logFC, color = significance)) +\n  geom_point(alpha = 0.6, size = 2) +\n  scale_color_manual(values = c(\"Up\" = \"red\", \"Down\" = \"blue\", \"NS\" = \"grey\")) +\n  geom_hline(yintercept = 0, linetype = \"solid\") +\n  geom_hline(yintercept = c(-log2(1.5), log2(1.5)), linetype = \"dashed\") +\n  theme_minimal() +\n  labs(title = \"MA Plot: Treatment vs Control\",\n       x = \"Average Expression\",\n       y = \"log2 Fold Change\") +\n  theme(legend.title = element_blank())"},{"path":"day3.html","id":"heatmap-of-de-proteins","chapter":"Day - 3 Preprocessing and Differential Expression","heading":"3.4.5 Heatmap of DE Proteins","text":"","code":"\n# Select significant proteins\nsig_proteins <- rownames(results[results$adj.P.Val < 0.05, ])\n\n# Plot heatmap if there are significant proteins\nif (length(sig_proteins) > 1) {\n  pheatmap(processed_data[sig_proteins, ],\n           scale = \"row\",\n           clustering_distance_rows = \"correlation\",\n           clustering_distance_cols = \"euclidean\",\n           annotation_col = sample_metadata[, c(\"condition\")],\n           show_rownames = FALSE,\n           show_colnames = TRUE,\n           fontsize_col = 10,\n           main = \"Heatmap of Significantly Differentially Expressed Proteins\")\n} else {\n  cat(\"Not enough significant proteins to generate a heatmap.\\n\")\n}\n#> Not enough significant proteins to generate a heatmap."},{"path":"day4.html","id":"day4","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"Day - 4 Functional Analysis, Longitudinal & Public Data","text":"","code":""},{"path":"day4.html","id":"objectives","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.1 Objectives","text":"Interpret DE results biologicallyExplore longitudinal trajectoriesWork public datasets","code":""},{"path":"day4.html","id":"module-1-functional-enrichment-gsea","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.2 Module 1: Functional Enrichment & GSEA","text":"Introduce enrichment (GO, KEGG, Reactome).\nGSEA principles visualization.","code":"\n# example with clusterProfiler\nlibrary(clusterProfiler)\nlibrary(org.Hs.eg.db)\n# Suppose `de_genes` is a vector of gene IDs with statistics\nego <- enrichGO(de_genes, OrgDb = org.Hs.eg.db, keyType = \"ENSEMBL\", ont = \"BP\")\ndotplot(ego)\nlibrary(lme4)\n#> Loading required package: Matrix\ndf_long <- data.frame(\n  sample = rep(1:10, each = 3),\n  time = rep(c(0,1,2), times = 10),\n  intensity = rnorm(30)\n)\nm <- lmer(intensity ~ time + (1 + time | sample), data = df_long)\n#> boundary (singular) fit: see help('isSingular')\nsummary(m)\n#> Linear mixed model fit by REML ['lmerMod']\n#> Formula: intensity ~ time + (1 + time | sample)\n#>    Data: df_long\n#> \n#> REML criterion at convergence: 84.8\n#> \n#> Scaled residuals: \n#>      Min       1Q   Median       3Q      Max \n#> -2.54442 -0.47295  0.00704  0.75598  1.33428 \n#> \n#> Random effects:\n#>  Groups   Name        Variance Std.Dev. Corr \n#>  sample   (Intercept) 0.23219  0.4819        \n#>           time        0.06152  0.2480   -1.00\n#>  Residual             0.88093  0.9386        \n#> Number of obs: 30, groups:  sample, 10\n#> \n#> Fixed effects:\n#>             Estimate Std. Error t value\n#> (Intercept)  -0.3296     0.3109  -1.060\n#> time          0.2320     0.2241   1.036\n#> \n#> Correlation of Fixed Effects:\n#>      (Intr)\n#> time -0.804\n#> optimizer (nloptwrap) convergence code: 0 (OK)\n#> boundary (singular) fit: see help('isSingular')"},{"path":"day4.html","id":"exercise","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.2.1 Exercise","text":"longitudinal proteomics dataset, plot trajectories per protein per cluster, fit simple linear/mixed model.","code":""},{"path":"day4.html","id":"module-2-public-data-integration","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.3 Module 2: Public Data Integration","text":"Demonstrate downloading, cleaning, integrating public proteomics expression dataset (e.g. PRIDE, GEO). Run pipeline: QC → normalization → DE → enrichment.","code":""},{"path":"day4.html","id":"exercise-1","chapter":"Day - 4 Functional Analysis, Longitudinal & Public Data","heading":"4.3.1 Exercise","text":"Pick public dataset, import R, preprocess, analyze, interpret results.","code":""},{"path":"day5.html","id":"day5","chapter":"Day - 5 Application on Real Data","heading":"Day - 5 Application on Real Data","text":"","code":""},{"path":"day5.html","id":"objectives-1","chapter":"Day - 5 Application on Real Data","heading":"5.1 Objectives","text":"Apply full workflow real internal datasetInterpret results biological contextTroubleshoot discuss","code":""},{"path":"day5.html","id":"modules","chapter":"Day - 5 Application on Real Data","heading":"5.2 Modules","text":"","code":""},{"path":"day5.html","id":"full-analysis-pipeline","chapter":"Day - 5 Application on Real Data","heading":"5.2.1 1. Full Analysis Pipeline","text":"QC → normalization → DE → functional → longitudinal (relevant).\nRun steps provided dataset (participants’ data).","code":""},{"path":"day5.html","id":"group-discussion-interpretation","chapter":"Day - 5 Application on Real Data","heading":"5.2.2 2. Group Discussion & Interpretation","text":"Interpret results, compare across participants, discuss limitations, challenges, possible variations.","code":""},{"path":"day5.html","id":"presentation-reporting","chapter":"Day - 5 Application on Real Data","heading":"5.2.3 3. Presentation & Reporting","text":"Generate basic report/graphics (ggplot2), integrate R Markdown / html / PDF.\nProvide guidance next steps.","code":""},{"path":"day5.html","id":"conclusion","chapter":"Day - 5 Application on Real Data","heading":"5.3 Conclusion","text":"Recap entire week.\nSuggest reading, resources, packages, courses.","code":""}]
